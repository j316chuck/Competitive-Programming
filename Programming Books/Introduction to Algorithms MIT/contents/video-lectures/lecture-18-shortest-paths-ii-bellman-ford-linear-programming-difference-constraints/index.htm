<!DOCTYPE html><html lang="en">
<head>
<meta charset="utf-8">
<meta name="format-detection" content="telephone=no">
<title>Lecture 18: Shortest Paths II: Bellman-Ford, Linear Programming, Difference Constraints | Video Lectures | Introduction to Algorithms (SMA 5503) | Electrical Engineering and Computer Science | MIT OpenCourseWare</title>
<!-- Begin Automatic Metadata Insertion --><meta content="6-046j-introduction-to-algorithms-sma-5503-fall-2005" name="WT.cg_n">
<meta content="Lecture 18: Shortest Paths II: Bellman-Ford, Linear Programming, Difference Constraints" name="WT.cg_s">
<meta content="" name="Description">
<meta content="Leiserson, Charles" name="Author">
<meta content="Demaine, Erik" name="Author">
<meta content="algorithms,efficient algorithms,sorting,search trees,heaps,hashing,divide-and-conquer,dynamic programming,amortized analysis,graph algorithms,shortest paths,network flow,computational geometry,number-theoretic algorithms,polynomial and matrix calculations,caching,parallel computing,Algorithms and Data Structures" name="keywords">
<meta content="6.046J Introduction to Algorithms (SMA 5503) | Lecture 18: Shortest Paths II: Bellman-Ford, Linear Programming, Difference Constraints" name="Search_Display">
<meta content="Algorithms and Data Structures" itemprop="about">
<!-- End Automatic Metadata Insertion --><link title="default" rel="stylesheet" type="text/css" href="../../../common/styles/grid.css">
<link title="default" rel="stylesheet" type="text/css" href="../../../common/styles/base.css">
<link title="default" rel="stylesheet" type="text/css" href="../../../common/styles/menu.css">
<link title="default" rel="stylesheet" type="text/css" href="../../../common/styles/jquery.bubblepopup.css">
<link title="default" rel="stylesheet" type="text/css" href="../../../common/styles/courses.css">
<link title="default" rel="stylesheet" type="text/css" href="../../../common/styles/courses_new.css">
<link title="default" rel="stylesheet" type="text/css" href="../../../common/styles/jquery.jscrollpane.css">
<link title="default" rel="stylesheet" type="text/css" href="../../../common/styles/media_tabs.css">
<link href="http://ocw.mit.edu/xml/ocwcc.rdf" type="application/rdf+xml" rel="metadata">
<link rel="canonical" href="http://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-046j-introduction-to-algorithms-sma-5503-fall-2005/video-lectures/lecture-18-shortest-paths-ii-bellman-ford-linear-programming-difference-constraints">
<link rel="apple-touch-icon" href="../../../common/images/apple-touch-icon.png">
<script type="text/javascript" src="../../../common/scripts/jquery.js"></script><script type="text/javascript" src="../../../common/scripts/ocw-media-utils-offline.js"></script><script type="text/javascript" src="../../../common/scripts/ocw-offline.js"></script><script type="text/javascript" src="../../../common/scripts/jquery.bubblepopup.min.js"></script><script type="text/javascript" src="../../../common/scripts/jquery-ui.min.js"></script><script type="text/javascript" src="../../../common/scripts/jquery.jscrollpane.min.js"></script><script type="text/javascript" src="../../../common/scripts/bubble-popup-offline.js"></script><script type="text/javascript">
      $(document).ready(function() {
        $("#tabs").tabs();
        IpadScroller();
      });
    </script>
</head>
<body itemscope itemtype="http://schema.org/WebPage">
        
	

        <div id="top">
			<div id="grid">
				
				
					
<div id="portletwrapper-6f63772e746f70706f72746c65746d616e616765720a636f6e746578740a2f506c6f6e650a736974652d686561646572" class="portletWrapper kssattr-portlethash-6f63772e746f70706f72746c65746d616e616765720a636f6e746578740a2f506c6f6e650a736974652d686561646572">
<div class="portletStaticText portlet-static-site-header">
<!--googleoff: index-->
<div class="grid_6 alpha" role="banner" id="banner"><a href="http://ocw.mit.edu/"><img class="logo" alt="MIT OpenCourseWare, Massachusetts Institute of Technology" src="../../../common/images/ocw_mast.png"></a></div>
<div class="grid_6 omega" role="form toolbar" id="subscribe">
<div class="module">
<table class="social"><tbody><tr>
<td class="socialbutton"><a href="http://ocw.mit.edu/subscribe/index.htm?utm_source=header"><img src="../../../common/images/trans.gif" alt="An icon depicting an envelope.">Subscribe to the OCW Newsletter</a></td>
            <td>
<a href="https://plus.google.com/104567381989352550847/posts"><img alt="Click to visit our Google+ page." src="../../../common/images/icon_gp.png"></a><a href="https://www.pinterest.com/mitocw/pins/"><img alt="Click to visit our Pinterest page." src="../../../common/images/icon_pin.png"></a><a href="http://facebook.com/mitocw"><img alt="Click to visit our Facebook page." src="../../../common/images/icon_fb.png"></a><a href="http://twitter.com/mitocw"><img alt="Click to visit our Twitter feed." src="../../../common/images/icon_tw.png"></a>
</td>
        </tr></tbody></table>
</div>
<p class="helplinks"><a href="http://ocw.mit.edu/help">Help</a>   |   <a href="../../../common/jsp/feedback.htm">Contact Us</a></p>
</div>
<div class="clear"> </div>
<!--googleon: index-->
</div>

</div>





<!--googleoff: index-->
<div id="mega" role="navigation" class="grid_8 alpha">        
	<ul id="menu">
<li id="menu_home">
            <a href="http://ocw.mit.edu/"><img src="../../../common/images/top-nav_home.png" class="home_icon" alt="Click for site home page."></a><!-- Begin Home Item -->
        </li>
<!-- End Home Item -->        
        <li class="selected">
            <a href="#" class="drop">Find Courses</a><!-- Begin 5 columns Item -->
            <div class="dropdown_5columns-a mega-courses">                    
                <div class="col_1a">
                    <div class="row_1a">
                        <div class="quart">
                            <h2 class="nav">Find courses by:</h2>
                            <ul class="nav-bullet find_by">
<li><a href="http://ocw.mit.edu/courses/find-by-topic/">Topic</a></li>
                                <li><a href="http://ocw.mit.edu/courses/find-by-number/">MIT Course Number</a></li>
                                <li><a href="http://ocw.mit.edu/courses/find-by-department/">Department</a></li>
                            </ul>
<ul style="margin-top: 88px;" class="nav-bullet find_by">
<li style="font-weight: normal; font-size: 1em;"><a href="http://ocw.mit.edu/courses/">View All Courses</a></li>
							</ul>
</div>
                        <div class="quart">
                            <h2 class="nav">Collections</h2>
                            <ul class="nav-bullet">
<li><a href="http://ocw.mit.edu/courses/audio-video-courses/">Audio/Video Lectures</a></li>
                                <li><a href="http://ocw.mit.edu/courses/online-textbooks/">Online Textbooks</a></li>
                                <li><a href="http://ocw.mit.edu/courses/new-courses/">New Courses</a></li>
                                <li><a href="http://ocw.mit.edu/courses/most-visited-courses/">Most Visited Courses</a></li>
                                <li><a href="http://ocw.mit.edu/courses/ocw-scholar/">OCW Scholar Courses</a></li>
                                <li><a href="http://ocw.mit.edu/courses/this-course-at-mit/">This Course at MIT</a></li>
                                <li><a href="http://ocw.mit.edu/resources/">Supplemental Resources</a></li>
                            </ul>
</div>
                        <div class="clear"> </div>
                    </div>
                    <div class="row_1b">
                        <h2 class="nav">Cross-Disciplinary Topic Lists</h2>
                        <div class="quart">
                        <ul class="nav-bullet">
<li><a href="http://ocw.mit.edu/courses/energy-courses">Energy</a></li>
                            <li><a href="http://ocw.mit.edu/courses/entrepreneurship">Entrepreneurship</a></li>
                            <li><a href="http://ocw.mit.edu/courses/environment-courses">Environment</a></li>
                        </ul>
</div>    
                        <div class="quart">
                        <ul class="nav-bullet">
<li><a href="http://ocw.mit.edu/courses/intro-programming">Introductory Programming</a></li>
                            <li><a href="http://ocw.mit.edu/courses/life-sciences">Life Sciences</a></li>
                            <li><a href="http://ocw.mit.edu/courses/transportation-courses">Transportation</a></li>
                        </ul>
</div>
                        <div class="clear"> </div>
                    </div>
                    <div class="clear"> </div>
                </div>
                <div class="col_1b">
                    <h2 class="nav">Translated Courses</h2>
                    <ul class="nav-bullet">
<li><a href="http://ocw.mit.edu/courses/translated-courses/traditional-chinese">繁體字 / Traditional Chinese</a></li>
                        <li><a href="http://ocw.mit.edu/courses/translated-courses/spanish">Español / Spanish</a></li>
                        <li><a href="http://ocw.mit.edu/courses/translated-courses/portuguese">Português / Portuguese</a></li>
                        <li><a href="http://ocw.mit.edu/courses/translated-courses/persian">فارسی / Persian</a></li>
                        <li><a href="http://ocw.mit.edu/courses/translated-courses/turkish">Türkçe / Turkish</a></li>
                        <li><a href="http://ocw.mit.edu/courses/translated-courses/korean">(비디오)한국 / Korean</a></li>
                        <li><a href="http://ocw.mit.edu/courses/translated-courses">More...</a></li>
                    </ul>
</div>
            </div>
        </li>
        <li>
            <a href="" class="drop">About</a>
            <div class="dropdown_1column-a">
                <div class="col_1">
                    <ul class="nav-bullet mega-div-bottom">
<li><a href="http://ocw.mit.edu/about/">About MIT OpenCourseWare</a></li>
                    </ul>
<ul class="nav-bullet mega-div-bottom">
<li><a href="http://ocw.mit.edu/about/site-statistics/">Site Stats</a></li>
                        <li><a href="http://ocw.mit.edu/about/ocw-stories/">OCW Stories</a></li>                        
                    </ul>
<ul class="nav-bullet">
<li><a href="http://ocw.mit.edu/about/media-coverage/">Media Coverage</a></li>
                        <li><a href="http://ocw.mit.edu/about/newsletter/">Newsletter</a></li>                        
                    </ul>
</div>
            </div>  
        </li>    
        <li>
            <a href="" class="drop">Donate</a>        
            <div class="dropdown_1column-a">
                    <div class="col_1">
                        <ul class="nav-bullet mega-div-bottom">
<li><a href="http://ocw.mit.edu/donate/">Make a Donation</a></li>
                            <li><a href="http://ocw.mit.edu/donate/why-donate/">Why Donate?</a></li>
                            <li><a href="http://ocw.mit.edu/donate/our-supporters/">Our Supporters</a></li>
                            <li><a href="http://ocw.mit.edu/donate/other-ways-to-contribute/">Other Ways to Contribute</a></li>
                            <li><a href="http://ocw.mit.edu/donate/shop-ocw">Shop OCW</a></li>
                        </ul>
<ul class="nav-bullet">
<li><a href="http://ocw.mit.edu/support/">Become a Corporate Sponsor</a></li>
                        </ul>
</div>
            </div>            
        </li>        
        <li>
            <a href="" class="drop">Featured Sites</a>        
            <div class="dropdown_1column-a">
                <div class="col_1">
                    <ul class="nav-bullet mega-div-bottom">
<li><a href="http://ocw.mit.edu/high-school/">Highlights for High School</a></li>
                        <li><a href="http://ocw.mit.edu/educator/">OCW Educator</a></li>
                        <li><a href="http://ocw.mit.edu/courses/crosslinks/">MIT Crosslinks and OCW</a></li>                        
                    </ul>
<ul class="nav-bullet mega-div-top">
<li><a href="http://ocw.mit.edu/ans7870/featured/mitx-courses-on-edx.htm">MITx Courses on edX</a></li>
                        <li><a href="http://teachingexcellence.mit.edu/">Teaching Excellence at MIT</a></li>
						<li><a href="http://www.oeconsortium.org/">Open Education Consortium</a></li>
                    </ul>
</div>
            </div>            
        </li>
    </ul>
</div>
<div id="search" role="search" class="grid_4 omega">
    
    <form method="get" action="../../../common/search/AdvancedSearch.htm">
     	 <table class="search"><tbody><tr>
<td class="black"><input type="text" onblur="fillSearchBox()" onfocus="clearSearchBox()" maxlength="255" value="Search" name="q" class="greytext searchField" id="terms"></td> 			 
                    <td class="black"><input type="image" src="../../../common/images/button_search.png" name="btnG" class="sub_button"></td>			 
                    <td class="text2"><a href="../../../common/search/AdvancedSearch.htm">Advanced<br>Search</a></td>
                </tr></tbody></table>
</form>
</div>
<div class="clear"></div>
<!--googleon: index-->
<!-- *end header* -->  

				
				
			</div>
<!-- top grid end -->
		</div>
<!-- top end -->
			
		<div id="center_media">
      	<div id="grid">
      		<div id="left">
        		<div id="breadcrumb_media">
                	<p>

    <a href="http://ocw.mit.edu/">Home</a>
    
        »
        
    
    
        
            <a href="http://ocw.mit.edu/courses">Courses</a>
            
                »
                
            
            
         
    
    
        
            <a href="http://ocw.mit.edu/courses/electrical-engineering-and-computer-science">Electrical Engineering and Computer Science</a>
            
                »
                
            
            
         
    
    
        
            <a href="../../../contents/index.htm">Introduction to Algorithms (SMA 5503)</a>
            
                »
                
            
            
         
    
    
        
            <a href="../../../contents/video-lectures/index.htm">Video Lectures</a>
            
                »
                
            
            
         
    
    
        
            
            
            Lecture 18: Shortest Paths II: Bellman-Ford, Linear Programming, 
         
    
</p>

            	</div>
            	<div class="clear"></div>
        		<div id="media_title">
        		<h1 class="title" itemprop="name" property="dct:title">
        <span class="" id="parent-fieldname-title">
            Lecture 18: Shortest Paths II: Bellman-Ford, Linear Programming, Difference Constraints
        </span>
    </h1>
        		</div>
           		<div class="clear"></div>
           		<div id="course_wrapper_media">
           			<div id="course_nav">
           				<script language="javascript" type="text/javascript">
function toggleMenu(objID) {
  if (!document.getElementById) return;
  var ob = document.getElementById(objID);
  ob.className = (ob.className == 'selected')?'': 'selected';
}
function toggleClass(id)
{
  var divtoggleClass= document.getElementById(id);
  divtoggleClass.className = (divtoggleClass.className == 'mO')?'mC': 'mO';
  return false;
}
function changeAlt(id)
{
  id.alt = (id.alt == 'Expand Menu')?'Collapse Menu' : 'Expand Menu';
  id.title = (id.title == 'Expand Menu')?'Collapse Menu' : 'Expand Menu';
}
</script><!--Left Nav Starts --><ul>
<li class="">
			   			<a href="../../../contents/index.htm">
		                  Course Home  			                
	                    </a>
		        </li>
		    
         	
	
	
	    	
	    	    <li class="">
			   			<a href="../../../contents/syllabus/index.htm">
		                  Syllabus  			                
	                    </a>
		        </li>
		    
         	
	
	
	    	
	    	    <li class="">
			   			<a href="../../../contents/calendar/index.htm">
		                  Calendar  			                
	                    </a>
		        </li>
		    
         	
	
	
	    	
	    	    <li class="">
			   			<a href="../../../contents/readings/index.htm">
		                  Readings  			                
	                    </a>
		        </li>
		    
         	
	
	
	    	
	    	    <li class="">
			   			<a href="../../../contents/assignments/index.htm">
		                  Assignments  			                
	                    </a>
		        </li>
		    
         	
	
	
	    	
	    	    <li class="">
			   			<a href="../../../contents/exams/index.htm">
		                  Exams  			                
	                    </a>
		        </li>
		    
         	
	
	
	    	
	    	    <li class="selected">
			   			<a href="../../../contents/video-lectures/index.htm">
		                  Video Lectures  			                
	                    </a>
		        </li>
		    
         	
	
	
	    	
	    	    
		    
         	
	<!--second tal block close-->  
	
</ul>
<!--Left Nav Ends -->
</div>
           			<div id="course_inner_media">
      					 
        <div class="" id="parent-fieldname-text">
            
            
        </div>
    
      					 

<script type="text/javascript">var caption_embed_1 ={'English - US': '/courses/electrical-engineering-and-computer-science/6-046j-introduction-to-algorithms-sma-5503-fall-2005/video-lectures/lecture-18-shortest-paths-ii-bellman-ford-linear-programming-difference-constraints/Ttezuzs39nk.srt'}</script><div id="media-embed">
         <div class="attention_message" id="embed_1">
<p>Flash and JavaScript are required for this feature.</p>
<p>Download the video from <a href="http://itunes.apple.com/gb/podcast/lecture-18-shortest-paths/id341597754?i=63738846">iTunes U</a> or the <a href="http://www.archive.org/download/MIT6.046JF05MPEG4/ocw-6.046-16nov2005-220k.mp4">Internet Archive</a>.</p>
</div>
     </div>
    
     <script type="text/javascript">ocw_embed_chapter_media('embed_1', 'http://www.youtube.com/v/Ttezuzs39nk', 'youtube', '/courses/electrical-engineering-and-computer-science/6-046j-introduction-to-algorithms-sma-5503-fall-2005/video-lectures/lecture-18-shortest-paths-ii-bellman-ford-linear-programming-difference-constraints', 'http://img.youtube.com/vi/Ttezuzs39nk/0.jpg',0,0, 'http://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-046j-introduction-to-algorithms-sma-5503-fall-2005/video-lectures/lecture-18-shortest-paths-ii-bellman-ford-linear-programming-difference-constraints/Ttezuzs39nk.srt')</script><div id="transcript1"></div>
				 <script type="text/javascript">setThreePlayTranscriptPlugin(2, 703407)</script><script type="text/javascript" src="http://p3.3playmedia.com/p3.js"></script><div id="media_resource_next_prev_nav" style="margin-top: 1em;">
        <p>
        
            <a href="../../../contents/video-lectures/lecture-17-shortest-paths-i-properties-dijkstras-algorithm-breadth-first-search/index.htm">
                <img src="../../../common/images/btn_previous_resource.png" style="margin: 0 30px 0 50px;" alt="Previous track" title="Previous track"></a>
     	
     	
        
            <a href="../../../contents/video-lectures/lecture-19-shortest-paths-iii-all-pairs-shortest-paths-matrix-multiplication-floyd-warshall-johnson/index.htm"> 
                <img src="../../../common/images/btn_next_resource.png" alt="Next track" title="Next track"></a>
       
       </p>
     </div>
 


<script type="text/javascript">
		window.onload=function(){
		init();
		
		}
		var tabLinks = new Array();
		var contentDivs = new Array();
		function init() {
		  // Grab the tab links and content divs from the page
		  var tabListItems = document.getElementById('tabs').childNodes;
		  for ( var i = 0; i < tabListItems.length; i++ ) {
			if ( tabListItems[i].nodeName == "LI" ) {
			  var tabLink = getFirstChildWithTagName( tabListItems[i], 'A' );
			  var id = getHash( tabLink.getAttribute('href') );
			  tabLinks[id] = tabLink;
			  contentDivs[id] = document.getElementById( id );
			}
		  }
		  // Assign onclick events to the tab links, and
		  // highlight the first tab
		  var i = 0;
		  for ( var id in tabLinks ) {
			tabLinks[id].onclick = showTab;
			tabLinks[id].onfocus = function() { this.blur() };
			if ( i == 0 ) tabLinks[id].className = 'selected';
			i++;
		  }
		  // Hide all content divs except the first
		  var i = 0;
		  for ( var id in contentDivs ) {
			if ( i != 0 ) contentDivs[id].className = 'tabContent hide';
			i++;
		  }
		}
		function showTab() {
		  var selectedId = getHash( this.getAttribute('href') );
		  // Highlight the selected tab, and dim all others.
		  // Also show the selected content div, and hide all others.
		  for ( var id in contentDivs ) {
			if ( id == selectedId ) {
			  tabLinks[id].className = 'selected';
			  contentDivs[id].className = 'tabContent';
			} else {
			  tabLinks[id].className = '';
			  contentDivs[id].className = 'tabContent hide';
			}
		  }
		  // Stop the browser following the link
		  return false;
		}
		function getFirstChildWithTagName( element, tagName ) {
		  for ( var i = 0; i < element.childNodes.length; i++ ) {
			if ( element.childNodes[i].nodeName == tagName ) return element.childNodes[i];
		  }
		}
		function getHash( url ) {
		  var hashPos = url.lastIndexOf ( '#' );
		  return url.substring( hashPos + 1 );
		}
 </script><div id="media_tabs">
     
        <ul id="tabs">
<li class="first">
                <a href="#vid_about" class="selected">About this Video</a>
            </li>
            <li class="">
                <a href="#vid_index" class="">Playlist</a>
            </li>
            <li class="">
                <a href="#vid_playlist" class="">Related Resources</a>
            </li>
            <li class="">
                <a href="#vid_related" class="">Transcript</a>
            </li>
            <li class="">
                <a href="#vid_transcript" class="">Download this Video</a>
            </li>
        </ul>
<div id="vid_about" itemprop="description" class="tabContent">
<p><strong>Topics covered:</strong> Shortest Paths II: Bellman-Ford, Linear Programming, Difference Constraints</p>
<p><strong>Instructors:</strong> Prof. Erik Demaine, Prof. Charles Leiserson</p>
</div>
        <div id="vid_index" itemprop="description" class="tabContent hide">
<div class="related-media-thumbnail">
<a href="../../../contents/video-lectures/lecture-1-administrivia-introduction-analysis-of-algorithms-insertion-sort-mergesort/index.htm">
<img src="../../../contents/video-lectures/lecture-1-administrivia-introduction-analysis-of-algorithms-insertion-sort-mergesort/6_046J_lec01_th.jpg" title="Lecture 1: Administrivia; Introduction; Analysis of Algorithms, Insertion Sort, Mergesort" alt="Lecture 1: Administrivia; Introduction; Analysis of Algorithms, Insertion Sort, Mergesort"><p>Lecture 1: Administrivia; I...</p></a>
</div>
<div class="related-media-thumbnail">
<a href="../../../contents/video-lectures/lecture-2-asymptotic-notation-recurrences-substitution-master-method/index.htm">
<img src="../../../contents/video-lectures/lecture-2-asymptotic-notation-recurrences-substitution-master-method/6_046J_lec02_th.jpg" title="Lecture 2: Asymptotic Notation; Recurrences; Substitution, Master Method" alt="Lecture 2: Asymptotic Notation; Recurrences; Substitution, Master Method"><p>Lecture 2: Asymptotic Notat...</p></a>
</div>
<div class="related-media-thumbnail">
<a href="../../../contents/video-lectures/lecture-3-divide-and-conquer-strassen-fibonacci-polynomial-multiplication/index.htm">
<img src="../../../contents/video-lectures/lecture-3-divide-and-conquer-strassen-fibonacci-polynomial-multiplication/6_046J_lec03_th.jpg" title="Lecture 3: Divide-and-Conquer: Strassen, Fibonacci, Polynomial Multiplication" alt="Lecture 3: Divide-and-Conquer: Strassen, Fibonacci, Polynomial Multiplication"><p>Lecture 3: Divide-and-Conqu...</p></a>
</div>
<div class="related-media-thumbnail">
<a href="../../../contents/video-lectures/lecture-4-quicksort-randomized-algorithms/index.htm">
<img src="../../../contents/video-lectures/lecture-4-quicksort-randomized-algorithms/6_046J_lec04_th.jpg" title="Lecture 4: Quicksort, Randomized Algorithms" alt="Lecture 4: Quicksort, Randomized Algorithms"><p>Lecture 4: Quicksort, Rando...</p></a>
</div>
<div class="related-media-thumbnail">
<a href="../../../contents/video-lectures/lecture-5-linear-time-sorting-lower-bounds-counting-sort-radix-sort/index.htm">
<img src="../../../contents/video-lectures/lecture-5-linear-time-sorting-lower-bounds-counting-sort-radix-sort/6_046J_lec05_th.jpg" title="Lecture 5: Linear-time Sorting: Lower Bounds, Counting Sort, Radix Sort" alt="Lecture 5: Linear-time Sorting: Lower Bounds, Counting Sort, Radix Sort"><p>Lecture 5: Linear-time Sort...</p></a>
</div>
<div class="related-media-thumbnail">
<a href="../../../contents/video-lectures/lecture-6-order-statistics-median/index.htm">
<img src="../../../contents/video-lectures/lecture-6-order-statistics-median/6_046J_lec06_th.jpg" title="Lecture 6: Order Statistics, Median" alt="Lecture 6: Order Statistics, Median"><p>Lecture 6: Order Statistics...</p></a>
</div>
<div class="related-media-thumbnail">
<a href="../../../contents/video-lectures/lecture-7-hashing-hash-functions/index.htm">
<img src="../../../contents/video-lectures/lecture-7-hashing-hash-functions/6_046J_lec07_th.jpg" title="Lecture 7: Hashing, Hash Functions" alt="Lecture 7: Hashing, Hash Functions"><p>Lecture 7: Hashing, Hash Fu...</p></a>
</div>
<div class="related-media-thumbnail">
<a href="../../../contents/video-lectures/lecture-8-universal-hashing-perfect-hashing/index.htm">
<img src="../../../contents/video-lectures/lecture-8-universal-hashing-perfect-hashing/6_046J_lec08_th.jpg" title="Lecture 8: Universal Hashing, Perfect Hashing" alt="Lecture 8: Universal Hashing, Perfect Hashing"><p>Lecture 8: Universal Hashin...</p></a>
</div>
<div class="related-media-thumbnail">
<a href="../../../contents/video-lectures/lecture-9-relation-of-bsts-to-quicksort-analysis-of-random-bst/index.htm">
<img src="../../../contents/video-lectures/lecture-9-relation-of-bsts-to-quicksort-analysis-of-random-bst/6_046J_lec09_th.jpg" title="Lecture 9: Relation of BSTs to Quicksort - Analysis of Random BST" alt="Lecture 9: Relation of BSTs to Quicksort - Analysis of Random BST"><p>Lecture 9: Relation of BSTs...</p></a>
</div>
<div class="related-media-thumbnail">
<a href="../../../contents/video-lectures/lecture-10-red-black-trees-rotations-insertions-deletions/index.htm">
<img src="../../../contents/video-lectures/lecture-10-red-black-trees-rotations-insertions-deletions/6_046J_lec10_th.jpg" title="Lecture 10: Red-black Trees, Rotations, Insertions, Deletions" alt="Lecture 10: Red-black Trees, Rotations, Insertions, Deletions"><p>Lecture 10: Red-black Trees...</p></a>
</div>
<div class="related-media-thumbnail">
<a href="../../../contents/video-lectures/lecture-11-augmenting-data-structures-dynamic-order-statistics-interval-trees/index.htm">
<img src="../../../contents/video-lectures/lecture-11-augmenting-data-structures-dynamic-order-statistics-interval-trees/6_046J_lec11_th.jpg" title="Lecture 11: Augmenting Data Structures, Dynamic Order Statistics, Interval Trees" alt="Lecture 11: Augmenting Data Structures, Dynamic Order Statistics, Interval Trees"><p>Lecture 11: Augmenting Data...</p></a>
</div>
<div class="related-media-thumbnail">
<a href="../../../contents/video-lectures/lecture-12-skip-lists/index.htm">
<img src="../../../contents/video-lectures/lecture-12-skip-lists/6_046J_lec12_th.jpg" title="Lecture 12: Skip Lists" alt="Lecture 12: Skip Lists"><p>Lecture 12: Skip Lists</p></a>
</div>
<div class="related-media-thumbnail">
<a href="../../../contents/video-lectures/lecture-13-amortized-algorithms-table-doubling-potential-method/index.htm">
<img src="../../../contents/video-lectures/lecture-13-amortized-algorithms-table-doubling-potential-method/6_046J_lec13_th.jpg" title="Lecture 13: Amortized Algorithms, Table Doubling, Potential Method" alt="Lecture 13: Amortized Algorithms, Table Doubling, Potential Method"><p>Lecture 13: Amortized Algor...</p></a>
</div>
<div class="related-media-thumbnail">
<a href="../../../contents/video-lectures/lecture-14-competitive-analysis-self-organizing-lists/index.htm">
<img src="../../../contents/video-lectures/lecture-14-competitive-analysis-self-organizing-lists/6_046J_lec14_th.jpg" title="Lecture 14: Competitive Analysis: Self-organizing Lists" alt="Lecture 14: Competitive Analysis: Self-organizing Lists"><p>Lecture 14: Competitive Ana...</p></a>
</div>
<div class="related-media-thumbnail">
<a href="../../../contents/video-lectures/lecture-15-dynamic-programming-longest-common-subsequence/index.htm">
<img src="../../../contents/video-lectures/lecture-15-dynamic-programming-longest-common-subsequence/6_046J_lec15_th.jpg" title="Lecture 15: Dynamic Programming, Longest Common Subsequence" alt="Lecture 15: Dynamic Programming, Longest Common Subsequence"><p>Lecture 15: Dynamic Program...</p></a>
</div>
<div class="related-media-thumbnail">
<a href="../../../contents/video-lectures/lecture-16-greedy-algorithms-minimum-spanning-trees/index.htm">
<img src="../../../contents/video-lectures/lecture-16-greedy-algorithms-minimum-spanning-trees/6_046J_lec16_th.jpg" title="Lecture 16: Greedy Algorithms, Minimum Spanning Trees" alt="Lecture 16: Greedy Algorithms, Minimum Spanning Trees"><p>Lecture 16: Greedy Algorith...</p></a>
</div>
<div class="related-media-thumbnail">
<a href="../../../contents/video-lectures/lecture-17-shortest-paths-i-properties-dijkstras-algorithm-breadth-first-search/index.htm">
<img src="../../../contents/video-lectures/lecture-17-shortest-paths-i-properties-dijkstras-algorithm-breadth-first-search/6_046J_lec17_th.jpg" title="Lecture 17: Shortest Paths I: Properties, Dijkstra's Algorithm, Breadth-first Search" alt="Lecture 17: Shortest Paths I: Properties, Dijkstra's Algorithm, Breadth-first Search"><p>Lecture 17: Shortest Paths ...</p></a>
</div>
<div class="related-media-thumbnail-nolink">
<div class="now-playing-resource">Now Playing</div>
<img src="../../../contents/video-lectures/lecture-18-shortest-paths-ii-bellman-ford-linear-programming-difference-constraints/6_046J_lec18_th.jpg" title="Lecture 18: Shortest Paths II: Bellman-Ford, Linear Programming, Difference Constraints" alt="Lecture 18: Shortest Paths II: Bellman-Ford, Linear Programming, Difference Constraints"><p>Lecture 18: Shortest Paths ...</p>
</div>
<div class="related-media-thumbnail">
<a href="../../../contents/video-lectures/lecture-19-shortest-paths-iii-all-pairs-shortest-paths-matrix-multiplication-floyd-warshall-johnson/index.htm">
<img src="../../../contents/video-lectures/lecture-19-shortest-paths-iii-all-pairs-shortest-paths-matrix-multiplication-floyd-warshall-johnson/6_046J_lec19_th.jpg" title="Lecture 19: Shortest Paths III: All-pairs Shortest Paths, Matrix Multiplication, Floyd-Warshall, Johnson" alt="Lecture 19: Shortest Paths III: All-pairs Shortest Paths, Matrix Multiplication, Floyd-Warshall, Johnson"><p>Lecture 19: Shortest Paths ...</p></a>
</div>
<div class="related-media-thumbnail">
<a href="../../../contents/video-lectures/lecture-22-advanced-topics/index.htm">
<img src="../../../contents/video-lectures/lecture-22-advanced-topics/6_046J_lec22_th.jpg" title="Lecture 22: Advanced Topics" alt="Lecture 22: Advanced Topics"><p>Lecture 22: Advanced Topics</p></a>
</div>
<div class="related-media-thumbnail">
<a href="../../../contents/video-lectures/lecture-23-advanced-topics-cont./index.htm">
<img src="../../../contents/video-lectures/lecture-23-advanced-topics-cont./6_046J_lec23_th.jpg" title="Lecture 23: Advanced Topics (cont.)" alt="Lecture 23: Advanced Topics (cont.)"><p>Lecture 23: Advanced Topics...</p></a>
</div>
<div class="related-media-thumbnail">
<a href="../../../contents/video-lectures/lecture-24-advanced-topics-cont./index.htm">
<img src="../../../contents/video-lectures/lecture-24-advanced-topics-cont./6_046J_lec24_th.jpg" title="Lecture 24: Advanced Topics (cont.)" alt="Lecture 24: Advanced Topics (cont.)"><p>Lecture 24: Advanced Topics...</p></a>
</div>
<div class="related-media-thumbnail">
<a href="../../../contents/video-lectures/lecture-25-advanced-topics-cont.-discussion-of-follow-on-classes/index.htm">
<img src="../../../contents/video-lectures/lecture-25-advanced-topics-cont.-discussion-of-follow-on-classes/6_046J_lec25_th.jpg" title="Lecture 25: Advanced Topics (cont.) - Discussion of Follow-on Classes" alt="Lecture 25: Advanced Topics (cont.) - Discussion of Follow-on Classes"><p>Lecture 25: Advanced Topics...</p></a>
</div>
</div>
        <div id="vid_playlist" itemprop="description" class="tabContent hide">
<h2 class="subhead">Related Resources</h2>
<p>Lecture Notes (<a target="_blank" href="../../../contents/video-lectures/lecture-18-shortest-paths-ii-bellman-ford-linear-programming-difference-constraints/lec18.pdf">PDF</a>)<br><a target="_blank" href="../../../contents/assignments/index.htm">Assignments</a><br><a target="_blank" href="../../../contents/exams/index.htm">Exams</a></p>
</div>
        <div id="vid_related" itemprop="description" class="tabContent hide">
<ul><li><a class="transcript-link" title="Open in a new window." alt="Open in a new window." style="text-decoration: none; font-size: 1.0em;" target="_blank" text-decoration: none font-size: href="../../../contents/video-lectures/lecture-18-shortest-paths-ii-bellman-ford-linear-programming-difference-constraints/Ttezuzs39nk.pdf"> Download this transcript - PDF (English - US)</a></li></ul>
<p><span m="7000">Good morning, everyone.</span> </p>
<p><span m="9000">Glad you are all here bright and early.</span> </p>
<p><span m="14000">I'm counting the days till the TA's outnumber the students.</span> </p>
<p><span m="20000">They'll show up. We return to a familiar story.</span> </p>
<p><span m="26000">This is part two, the Empire Strikes Back.</span> </p>
<p><span m="32000">So last time, our adversary,</span> <span m="33000">the graph, came to us with a problem.</span> </p>
<p><span m="36000">We have a source, and we had a directed graph,</span> <span m="39000">and we had weights on the edges, and they were all</span> <span m="43000">nonnegative. And there was happiness.</span> </p>
<p><span m="46000">And we triumphed over the Empire by designing Dijkstra's</span> <span m="50000">algorithm, and very efficiently finding single source shortest</span> <span m="54000">paths, shortest path weight from s to every other vertex.</span> </p>
<p><span m="60000">Today, however, the Death Star has a new trick</span> <span m="62000">up its sleeve, and we have negative weights,</span> <span m="65000">potentially. And we're going to have to</span> <span m="67000">somehow deal with, in particular,</span> <span m="69000">negative weight cycles. And we saw that when we have a</span> <span m="73000">negative weight cycle, we can just keep going around,</span> <span m="76000">and around, and around, and go back in time farther,</span> <span m="79000">and farther, and farther.</span> </p>
<p><span m="81000">And we can get to be arbitrarily far back in the</span> <span m="84000">past. And so there's no shortest</span> <span m="86000">path, because whatever path you take you can get a shorter one.</span> </p>
<p><span m="89000">So we want to address that issue today, and we're going to</span> <span m="93000">come up with a new algorithm actually simpler than Dijkstra,</span> <span m="97000">but not as fast, called the Bellman-Ford</span> <span m="99000">algorithm. And, it's going to allow</span> <span m="104000">negative weights, and in some sense allow</span> <span m="108000">negative weight cycles, although maybe not as much as</span> <span m="114000">you might hope. We have to leave room for a</span> <span m="119000">sequel, of course. OK, so the Bellman-Ford</span> <span m="124000">algorithm, invented by two guys, as you might expect,</span> <span m="129000">it computes the shortest path weights.</span> </p>
<p><span m="133000">So, it makes no assumption about the weights.</span> </p>
<p><span m="137000">Weights are arbitrary, and it's going to compute the</span> <span m="142000">shortest path weights. So, remember this notation:</span> <span m="147000">delta of s, v is the weight of the shortest path from s to v.</span> </p>
<p><span m="153000">s was called a source vertex. And, we want to compute these</span> <span m="160000">weights for all vertices, little v.</span> </p>
<p><span m="163000">The claim is that computing from s to everywhere is no</span> <span m="167000">harder than computing s to a particular location.</span> </p>
<p><span m="171000">So, we're going to do for all them.</span> </p>
<p><span m="173000">It's still going to be the case here.</span> </p>
<p><span m="176000">And, it allows negative weights.</span> </p>
<p><span m="179000">And this is the good case, but there's an alternative,</span> <span m="183000">which is that Bellman-Ford may just say, oops,</span> <span m="187000">there's a negative weight cycle.</span> </p>
<p><span m="191000">And in that case it will just say so.</span> </p>
<p><span m="194000">So, they say a negative weight cycle exists.</span> </p>
<p><span m="198000">Therefore, some of these deltas are minus infinity.</span> </p>
<p><span m="203000">And that seems weird. So, Bellman-Ford as we'll</span> <span m="207000">present it today is intended for the case, but there are no</span> <span m="213000">negative weights cycles, which is more intuitive.</span> </p>
<p><span m="219000">It sort of allows them, but it will just report them.</span> </p>
<p><span m="222000">In that case, it will not give you delta</span> <span m="225000">values. You can change the algorithm to</span> <span m="228000">give you delta values in that case, but we are not going to</span> <span m="232000">see it here. So, in exercise,</span> <span m="234000">after you see the algorithm, exercise is:</span> <span m="237000">compute these deltas in all cases.</span> </p>
<p><span m="252000">So, it's not hard to do. But we don't have time for it</span> <span m="259000">here. So, here's the algorithm.</span> </p>
<p><span m="264000">It's pretty straightforward. As I said, it's easier than</span> <span m="272000">Dijkstra. It's a relaxation algorithm.</span> </p>
<p><span m="276000">So the main thing that it does is relax edges just like</span> <span m="280000">Dijkstra. So, we'll be able to use a lot</span> <span m="283000">of dilemmas from Dijkstra. And proof of correctness will</span> <span m="287000">be three times shorter because the first two thirds we already</span> <span m="291000">have from Dijkstra. But I'm jumping ahead a bit.</span> </p>
<p><span m="295000">So, the first part is initialization.</span> </p>
<p><span m="297000">Again, d of v will represent the estimated distance from s to</span> <span m="301000">v. And we're going to be updating</span> <span m="305000">those estimates as the algorithm goes along.</span> </p>
<p><span m="308000">And initially, d of s is zero,</span> <span m="310000">which now may not be the right answer conceivably.</span> </p>
<p><span m="314000">Everyone else is infinity, which is certainly an upper</span> <span m="317000">bound. OK, these are both upper bounds</span> <span m="320000">on the true distance. So that's fine.</span> </p>
<p><span m="323000">That's initialization just like before.</span> </p>
<p><span m="336000">And now we have a main loop which happens v minus one times.</span> </p>
<p><span m="339000">We're not actually going to use the index i.</span> </p>
<p><span m="341000">It's just a counter.</span> </p>
<p><span m="362000">And we're just going to look at every edge and relax it.</span> </p>
<p><span m="367000">It's a very simple idea. If you learn about relaxation,</span> <span m="373000">this is the first thing you might try.</span> </p>
<p><span m="376000">The question is when do you stop.</span> </p>
<p><span m="380000">It's sort of like I have this friend to what he was like six</span> <span m="385000">years old he would claim, oh, I know how to spell banana.</span> </p>
<p><span m="391000">I just don't know when to stop. OK, same thing with relaxation.</span> </p>
<p><span m="397000">This is our relaxation step just as before.</span> </p>
<p><span m="400000">We look at the edge; we see whether it violates the</span> <span m="403000">triangle inequality according to our current estimates we know</span> <span m="407000">the distance from s to v should be at most distance from s to</span> <span m="411000">plus the weight of that edge from u to v.</span> </p>
<p><span m="414000">If it isn't, we set it equal.</span> </p>
<p><span m="415000">We've proved that this is always an OK thing to do.</span> </p>
<p><span m="420000">We never violate, I mean, these d of v's never</span> <span m="423000">get too small if we do a bunch of relaxations.</span> </p>
<p><span m="427000">So, the idea is you take every edge.</span> </p>
<p><span m="429000">You relax it. I don't care which order.</span> </p>
<p><span m="432000">Just relax every edge, one each.</span> </p>
<p><span m="435000">And that do that V minus one times.</span> </p>
<p><span m="437000">The claim is that that should be enough if you have no</span> <span m="441000">negative weights cycles. So, if there's a negative</span> <span m="445000">weight cycle, we need to figure it out.</span> </p>
<p><span m="450000">And, we'll do that in a fairly straightforward way,</span> <span m="455000">which is we're going to do exactly the same thing.</span> </p>
<p><span m="460000">So this is outside before loop here.</span> </p>
<p><span m="464000">We'll have the same four loops for each edge in our graph.</span> </p>
<p><span m="470000">We'll try to relax it. And if you can relax it,</span> <span m="474000">the claim is that there has to be a negative weight cycle.</span> </p>
<p><span m="482000">So this is the main thing that needs proof.</span> </p>
<p><span m="508000">OK, and that's the algorithm. So the claim is that at the</span> <span m="511000">ends we should have d of v, let's see, L's so to speak.</span> </p>
<p><span m="515000">d of v equals delta of s comma v for every vertex,</span> <span m="518000">v. If we don't find a negative</span> <span m="520000">weight cycle according to this rule, that we should have all</span> <span m="524000">the shortest path weights. That's the claim.</span> </p>
<p><span m="527000">Now, the first question is, in here, the running time is</span> <span m="530000">very easy to analyze. So let's start with the running</span> <span m="534000">time. We can compare it to Dijkstra,</span> <span m="536000">which is over here. What is the running time of</span> <span m="542000">this algorithm? V times E, exactly.</span> </p>
<p><span m="546000">OK, I'm going to assume, because it's pretty reasonable,</span> <span m="552000">that V and E are both positive. Then it's V times E.</span> </p>
<p><span m="559000">So, this is a little bit slower, or a fair amount slower,</span> <span m="565000">than Dijkstra's algorithm. There it is:</span> <span m="570000">E plus V log V is essentially, ignoring the logs is pretty</span> <span m="575000">much linear time. Here we have something that's</span> <span m="579000">at least quadratic in V, assuming your graph is</span> <span m="583000">connected. So, it's slower,</span> <span m="585000">but it's going to handle these negative weights.</span> </p>
<p><span m="588000">Dijkstra can't handle negative weights at all.</span> </p>
<p><span m="592000">So, let's do an example, make it clear why you might</span> <span m="596000">hope this algorithm works. And then we'll prove that it</span> <span m="603000">works, of course. But the proof will be pretty</span> <span m="608000">easy. So, I'm going to draw a graph</span> <span m="612000">that has negative weights, but no negative weight cycles</span> <span m="618000">so that I get an interesting answer.</span> </p>
<p><span m="655000">Good. The other thing I need in order</span> <span m="657000">to make the output of this algorithm well defined,</span> <span m="660000">it depends in which order you visit the edges.</span> </p>
<p><span m="663000">So I'm going to assign an arbitrary order to these edges.</span> </p>
<p><span m="667000">I could just ask you for an order, but to be consistent with</span> <span m="671000">the notes, I'll put an ordering on it.</span> </p>
<p><span m="673000">Let's say I put number four, say that's the fourth edge I'll</span> <span m="677000">visit. It doesn't matter.</span> </p>
<p><span m="678000">But it will affect what happens during the algorithm for a</span> <span m="682000">particular graph.</span> </p>
<p><span m="703000">Do they get them all? One, two, three,</span> <span m="706000">four, five, six, seven, eight,</span> <span m="708000">OK. And my source is going to be A.</span> </p>
<p><span m="711000">And, that's it. So, I want to run this</span> <span m="714000">algorithm. I'm just going to initialize</span> <span m="717000">everything. So, I set the estimates for s</span> <span m="721000">to be zero, and everyone else to be infinity.</span> </p>
<p><span m="726000">And to give me some notion of time, over here I'm going to</span> <span m="730000">draw or write down what all of these d values are as the</span> <span m="735000">algorithm proceeds because I'm going to start crossing them out</span> <span m="740000">and rewriting them that the figure will get a little bit</span> <span m="745000">messier. But we can keep track of it</span> <span m="748000">over here. It's initially zero and</span> <span m="751000">infinities. Yeah?</span> </p>
<p><span m="754000">It doesn't matter. So, for the algorithm you can</span> <span m="756000">go to the edges in a different order every time if you want.</span> </p>
<p><span m="760000">We'll prove that, but here I'm going to go</span> <span m="762000">through the same order every time.</span> </p>
<p><span m="764000">Good question. It turns out it doesn't matter</span> <span m="767000">here. OK, so here's the starting</span> <span m="769000">point. Now I'm going to relax every</span> <span m="771000">edge. So, there's going to be a lot</span> <span m="773000">of edges here that don't do anything.</span> </p>
<p><span m="775000">I try to relax n minus one. I'd say, well,</span> <span m="777000">I know how to get from s to B with weight infinity.</span> </p>
<p><span m="782000">Infinity plus two I can get to from s to E.</span> </p>
<p><span m="784000">Well, infinity plus two is not much better than infinity.</span> </p>
<p><span m="788000">OK, so I don't do anything, don't update this to infinity.</span> </p>
<p><span m="791000">I mean, infinity plus two sounds even worse.</span> </p>
<p><span m="794000">But infinity plus two is infinity.</span> </p>
<p><span m="796000">OK, that's the edge number one. So, no relaxation edge number</span> <span m="800000">two, same deal as number three, same deal, edge number four we</span> <span m="804000">start to get something interesting because I have a</span> <span m="807000">finite value here that says I can get from A to B using a</span> <span m="811000">total weight of minus one. So that seems good.</span> </p>
<p><span m="815000">I'll write down minus one here, and update B to minus one.</span> </p>
<p><span m="821000">The rest stay the same. So, I'm just going to keep</span> <span m="825000">doing this over and over. That was edge number four.</span> </p>
<p><span m="830000">Number five, we also get a relaxation.</span> </p>
<p><span m="833000">Four is better than infinity. So, c gets a number of four.</span> </p>
<p><span m="840000">Then we get to edge number six. That's infinity plus five is</span> <span m="844000">worse than four. OK, so no relaxation there.</span> </p>
<p><span m="847000">Edge number seven is interesting because I have a</span> <span m="851000">finite value here minus one plus the weight of this edge,</span> <span m="855000">which is three. That's a total of two,</span> <span m="858000">which is actually better than four.</span> </p>
<p><span m="860000">So, this route, A, B, c is actually better than</span> <span m="864000">the route I just found a second ago.</span> </p>
<p><span m="866000">So, this is now a two. This is all happening in one</span> <span m="870000">iteration of the main loop. We actually found two good</span> <span m="875000">paths to c. We found one better than the</span> <span m="878000">other. OK, and that was edge number</span> <span m="881000">seven, and edge number eight is over here.</span> </p>
<p><span m="884000">It doesn't matter. OK, so that was round one of</span> <span m="887000">this outer loop, so, the first value of i.</span> </p>
<p><span m="890000">i equals one. OK, now we continue.</span> </p>
<p><span m="892000">Just keep going. So, we start with edge number</span> <span m="896000">one. Now, minus one plus two is one.</span> </p>
<p><span m="900000">That's better than infinity. It'll start speeding up.</span> </p>
<p><span m="904000">It's repetitive. It's actually not too much</span> <span m="908000">longer until we're done. Number two, this is an infinity</span> <span m="914000">so we don't do anything. Number three:</span> <span m="917000">minus one plus two is one; better than infinity.</span> </p>
<p><span m="922000">This is vertex d, and it's number three.</span> </p>
<p><span m="925000">Number four we've already done. Nothing changed.</span> </p>
<p><span m="931000">Number five: this is where we see the path</span> <span m="935000">four again, but that's worse than two.</span> </p>
<p><span m="938000">So, we don't update anything. Number six: one plus five is</span> <span m="943000">six, which is bigger than two, so no good.</span> </p>
<p><span m="947000">Go around this way. Number seven:</span> <span m="949000">same deal. Number eight is interesting.</span> </p>
<p><span m="953000">So, we have a weight of one here, a weight of minus three</span> <span m="958000">here. So, the total is minus two,</span> <span m="962000">which is better than one. So, that was d.</span> </p>
<p><span m="967000">And, I believe that's it. So that was definitely the end</span> <span m="973000">of that round. So, it's I plus two because we</span> <span m="978000">just looked at the eighth edge. And, I'll cheat and check.</span> </p>
<p><span m="984000">Indeed, that is the last thing that happens.</span> </p>
<p><span m="990000">We can check the couple of outgoing edges from d because</span> <span m="993000">that's the only one whose value just changed.</span> </p>
<p><span m="996000">And, there are no more relaxations possible.</span> </p>
<p><span m="999000">So, that was in two rounds. The claim is we got all the</span> <span m="1003000">shortest path weights. The algorithm would actually</span> <span m="1007000">loop four times to guarantee correctness because we have five</span> <span m="1011000">vertices here and one less than that.</span> </p>
<p><span m="1013000">So, in fact, in the execution here there are</span> <span m="1016000">two more blank rounds at the bottom.</span> </p>
<p><span m="1019000">Nothing happens. But, what the hell?</span> </p>
<p><span m="1023000">OK, so that is Bellman-Ford. I mean, it's certainly not</span> <span m="1026000">doing anything wrong. The question is,</span> <span m="1028000">why is it guaranteed to converge in V minus one steps</span> <span m="1031000">unless there is a negative weight cycle?</span> </p>
<p><span m="1033000">Question?</span> </p>
<p><span m="1044000">Right, so that's an optimization.</span> </p>
<p><span m="1045000">If you discover a whole round, and nothing happens,</span> <span m="1048000">so you can keep track of that in the algorithm thing,</span> <span m="1051000">you can stop. In the worst case,</span> <span m="1053000">it won't make a difference. But in practice,</span> <span m="1055000">you probably want to do that. Yeah?</span> </p>
<p><span m="1057000">Good question. All right, so some simple</span> <span m="1060000">observations, I mean, we're only doing</span> <span m="1062000">relaxation. So, we can use a lot of our</span> <span m="1064000">analysis from before. In particular,</span> <span m="1066000">the d values are only decreasing monotonically.</span> </p>
<p><span m="1069000">As we cross out values here, we are always making it</span> <span m="1071000">smaller, which is good. Another nifty thing about this</span> <span m="1074000">algorithm is that you can run it even in a distributed system.</span> </p>
<p><span m="1080000">If this is some actual network, some computer network,</span> <span m="1082000">and these are machines, and they're communicating by</span> <span m="1085000">these links, I mean, it's a purely local thing.</span> </p>
<p><span m="1087000">Relaxation is a local thing. You don't need any global</span> <span m="1089000">strategy, and you're asking about, can we do a different</span> <span m="1092000">order in each step? Well, yeah, you could just keep</span> <span m="1095000">relaxing edges, and keep relaxing edges,</span> <span m="1096000">and just keep going for the entire lifetime of the network.</span> </p>
<p><span m="1099000">And eventually, you will find shortest paths.</span> </p>
<p><span m="1101000">So, this algorithm is guaranteed to finish in V rounds</span> <span m="1104000">in a distributed system. It might be more asynchronous.</span> </p>
<p><span m="1107000">And, it's a little harder to analyze.</span> </p>
<p><span m="1110000">But it will still work eventually.</span> </p>
<p><span m="1114000">It's guaranteed to converge. And so, Bellman-Ford is used in</span> <span m="1121000">the Internet for finding shortest paths.</span> </p>
<p><span m="1126000">OK, so let's finally prove that it works.</span> </p>
<p><span m="1131000">This should only take a couple of boards.</span> </p>
<p><span m="1136000">So let's suppose we have a graph and some edge weights that</span> <span m="1143000">have no negative weight cycles. Then the claim is that we</span> <span m="1153000">terminate with the correct answer.</span> </p>
<p><span m="1159000">So, Bellman-Ford terminates with all of these d of v values</span> <span m="1169000">set to the delta values for every vertex.</span> </p>
<p><span m="1178000">OK, the proof is going to be pretty immediate using the</span> <span m="1182000">lemmas that we had from before if you remember them.</span> </p>
<p><span m="1185000">So, we're just going to look at every vertex separately.</span> </p>
<p><span m="1190000">So, I'll call the vertex v. The claim is that this holds by</span> <span m="1194000">the end of the algorithm. So, remember what we need to</span> <span m="1198000">prove is that at some point, d of v equals delta of s comma</span> <span m="1202000">v because we know it decreases monotonically,</span> <span m="1206000">and we know that it never gets any smaller than the correct</span> <span m="1210000">value because relaxations are always safe.</span> </p>
<p><span m="1215000">So, we just need to show at some point this holds,</span> <span m="1224000">and that it will hold at the end.</span> </p>
<p><span m="1232000">So, by monotonicity of the d values, and by correctness part</span> <span m="1241000">one, which was that the d of v's are always greater than or equal</span> <span m="1251000">to the deltas, we only need to show that at</span> <span m="1258000">some point we have equality.</span> </p>
<p><span m="1278000">So that's our goal. So what we're going to do is</span> <span m="1281000">just look at v, and the shortest path to v,</span> <span m="1284000">and see what happens to the algorithm relative to that path.</span> </p>
<p><span m="1290000">So, I'm going to name the path. Let's call it p.</span> </p>
<p><span m="1295000">It starts at vertex v_0 and goes to v_1, v_2,</span> <span m="1300000">whatever, and ends at v_k. And, this is not just any</span> <span m="1306000">shortest path, but it's one that starts at s.</span> </p>
<p><span m="1311000">So, v_0's s, and it ends at v.</span> </p>
<p><span m="1314000">So, I'm going to give a couple of names to s and v so I can</span> <span m="1321000">talk about the path more uniformly.</span> </p>
<p><span m="1324000">So, this is a shortest path from s to v.</span> </p>
<p><span m="1331000">Now, I also want it to be not just any shortest path from s to</span> <span m="1335000">v, but among all shortest paths from s to v I want it to be one</span> <span m="1340000">with the fewest possible edges.</span> </p>
<p><span m="1352000">OK, so shortest here means in terms of the total weight of the</span> <span m="1356000">path. Subject to being shortest in</span> <span m="1358000">weight, I wanted to also be shortest in the number of edges.</span> </p>
<p><span m="1362000">And, the reason I want that is to be able to conclude that p is</span> <span m="1366000">a simple path, meaning that it doesn't repeat</span> <span m="1370000">any vertices. Now, can anyone tell me why I</span> <span m="1372000">need to assume that the number of edges is the smallest</span> <span m="1376000">possible in order to guarantee that p is simple?</span> </p>
<p><span m="1381000">The claim is that not all shortest paths are necessarily</span> <span m="1384000">simple. Yeah?</span> </p>
<p><span m="1385000">Right, I can have a zero weight cycle, exactly.</span> </p>
<p><span m="1387000">So, we are hoping, I mean, in fact in the theorem</span> <span m="1390000">here, we're assuming that there are no negative weight cycles.</span> </p>
<p><span m="1394000">But there might be zero weight cycles still.</span> </p>
<p><span m="1397000">As a zero weight cycle, you can put that in the middle</span> <span m="1400000">of any shortest path to make it arbitrarily long,</span> <span m="1403000">repeat vertices over and over. That's going to be annoying.</span> </p>
<p><span m="1406000">What I want is that p is simple.</span> </p>
<p><span m="1410000">And, I can guarantee that essentially by shortcutting.</span> </p>
<p><span m="1413000">If ever I take a zero weight cycle, I throw it away.</span> </p>
<p><span m="1416000">And this is one mathematical way of doing that.</span> </p>
<p><span m="1419000">OK, now what else do we know about this shortest path?</span> </p>
<p><span m="1423000">Well, we know that subpaths are shortest paths are shortest</span> <span m="1427000">paths. That's optimal substructure.</span> </p>
<p><span m="1429000">So, we know what the shortest path from s to v_i is sort of</span> <span m="1433000">inductively. It's the shortest path,</span> <span m="1435000">I mean, it's the weight of that path, which is,</span> <span m="1438000">in particular, the shortest path from s to v</span> <span m="1441000">minus one plus the weight of the last edge, v minus one to v_i.</span> </p>
<p><span m="1447000">So, this is by optimal substructure as we proved last</span> <span m="1457000">time. OK, and I think that's pretty</span> <span m="1463000">much the warm-up. So, I want to sort of do this</span> <span m="1470000">inductively in I, start out with v zero,</span> <span m="1473000">and go up to v_k. So, the first question is,</span> <span m="1477000">what is d of v_0, which is s?</span> </p>
<p><span m="1480000">What is d of the source? Well, certainly at the</span> <span m="1484000">beginning of the algorithm, it's zero.</span> </p>
<p><span m="1487000">So, let's say equals zero initially because that's what we</span> <span m="1492000">set it to. And it only goes down from</span> <span m="1495000">there. So, it certainly,</span> <span m="1497000">at most, zero. The real question is,</span> <span m="1501000">what is delta of s comma v_0. What is the shortest path</span> <span m="1506000">weight from s to s? It has to be zero,</span> <span m="1509000">otherwise you have a negative weight cycle,</span> <span m="1513000">exactly. My favorite answer,</span> <span m="1515000">zero. So, if we had another path from</span> <span m="1519000">s to s, I mean, that is a cycle.</span> </p>
<p><span m="1521000">So, it's got to be zero. So, these are actually equal at</span> <span m="1526000">the beginning of the algorithm, which is great.</span> </p>
<p><span m="1532000">That means they will be for all time because we just argued up</span> <span m="1537000">here, only goes down, never can get too small.</span> </p>
<p><span m="1541000">So, we have d of v_0 set to the right thing.</span> </p>
<p><span m="1545000">Great: good for the base case of the induction.</span> </p>
<p><span m="1549000">Of course, what we really care about is v_k,</span> <span m="1553000">which is v. So, let's talk about the v_i</span> <span m="1556000">inductively, and then we will get v_k as a result.</span> </p>
<p><span m="1571000">So, yeah, let's do it by induction.</span> </p>
<p><span m="1574000">That's more fun.</span> </p>
<p><span m="1587000">Let's say that d of v_i is equal to delta of s v_i after I</span> <span m="1592000">rounds of the algorithm. So, this is actually referring</span> <span m="1598000">to the I that is in the algorithm here.</span> </p>
<p><span m="1602000">These are rounds. So, one round is an entire</span> <span m="1606000">execution of all the edges, relaxation of all the edges.</span> </p>
<p><span m="1612000">So, this is certainly true for I equals zero.</span> </p>
<p><span m="1616000">We just proved that. After zero rounds,</span> <span m="1620000">at the beginning of the algorithm, d of v_0 equals delta</span> <span m="1626000">of s, v_0. OK, so now, that's not really</span> <span m="1631000">what I wanted, but OK, fine.</span> </p>
<p><span m="1633000">Now we'll prove it for d of v_i plus one.</span> </p>
<p><span m="1636000">Generally, I recommend you assume something.</span> </p>
<p><span m="1640000">In fact, why don't I follow my own advice and change it?</span> </p>
<p><span m="1644000">It's usually nicer to think of induction as recursion.</span> </p>
<p><span m="1649000">So, you assume that this is true, let's say,</span> <span m="1652000">for j less than the i that you care about, and then you prove</span> <span m="1657000">it for d of v_i. It's usually a lot easier to</span> <span m="1662000">think about it that way. In particular,</span> <span m="1664000">you can use strong induction for all less than i.</span> </p>
<p><span m="1668000">Here, we're only going to need it for one less.</span> </p>
<p><span m="1671000">We have some relation between I and I minus one here in terms of</span> <span m="1676000">the deltas. And so, we want to argue</span> <span m="1679000">something about the d values. OK, well, let's think about</span> <span m="1685000">what's going on here. We know that,</span> <span m="1688000">let's say, after I minus one rounds, we have this inductive</span> <span m="1695000">hypothesis, d of v_i minus one equals delta of s v_i minus one.</span> </p>
<p><span m="1702000">And, we want to conclude that after i rounds,</span> <span m="1707000">so we have one more round to do this.</span> </p>
<p><span m="1711000">We want to conclude that d of v_i has the right answer,</span> <span m="1718000">delta of s comma v_i. Does that look familiar at all?</span> </p>
<p><span m="1724000">So we want to relax every edge in this round.</span> </p>
<p><span m="1727000">In particular, at some point,</span> <span m="1729000">we have to relax the edge from v_i minus one to v_i.</span> </p>
<p><span m="1733000">We know that this path consists of edges.</span> </p>
<p><span m="1736000">That's the definition of a path.</span> </p>
<p><span m="1740000">So, during the i'th round, we relax every edge.</span> </p>
<p><span m="1750000">So, we better relax v_i minus one v_i.</span> </p>
<p><span m="1758000">And, what happens then? It's a test of memory.</span> </p>
<p><span m="1783000">Quick, the Death Star is approaching.</span> </p>
<p><span m="1786000">So, if we have the correct value for v_i minus one,</span> <span m="1791000">that we relax an outgoing edge from there, and that edge is an</span> <span m="1797000">edge of the shortest path from s to v_i.</span> </p>
<p><span m="1801000">What do we know? d of v_i becomes the correct</span> <span m="1807000">value, delta of s comma v_i. This was called correctness</span> <span m="1813000">lemma last time. One of the things we proved</span> <span m="1818000">about Dijkstra's algorithm, but it was really just a fact</span> <span m="1824000">about relaxation. And it was a pretty simple</span> <span m="1829000">proof. And it comes from this fact.</span> </p>
<p><span m="1832000">We know the shortest path weight is this.</span> </p>
<p><span m="1835000">So, certainly d of v_i was at least this big,</span> <span m="1838000">and let's suppose it's greater, or otherwise we were done.</span> </p>
<p><span m="1842000">We know d of v_i minus one is set to this.</span> </p>
<p><span m="1844000">And so, this is exactly the condition that's being checked</span> <span m="1848000">in the relaxation step. And, the d of v_i value will be</span> <span m="1852000">greater than this, let's suppose.</span> </p>
<p><span m="1854000">And then, we'll set it equal to this.</span> </p>
<p><span m="1856000">And that's exactly d of s v_i. So, when we relax that edge,</span> <span m="1861000">we've got to set it to the right value.</span> </p>
<p><span m="1864000">So, this is the end of the proof, right?</span> </p>
<p><span m="1866000">It's very simple. The point is,</span> <span m="1868000">you look at your shortest path. Here it is.</span> </p>
<p><span m="1871000">And if we assume there's no negative weight cycles,</span> <span m="1874000">this has the correct value initially.</span> </p>
<p><span m="1877000">d of s is going to be zero. After the first round,</span> <span m="1880000">you've got to relax this edge. And then you get the right</span> <span m="1883000">value for that vertex. After the second round,</span> <span m="1886000">you've got to relax this edge, which gets you the right d</span> <span m="1890000">value for this vertex and so on. And so, no matter which</span> <span m="1896000">shortest path you take, you can apply this analysis.</span> </p>
<p><span m="1900000">And you know that by, if the length of this path,</span> <span m="1904000">here we assumed it was k edges, then after k rounds you've got</span> <span m="1910000">to be done. OK, so this was not actually</span> <span m="1913000">the end of the proof. Sorry.</span> </p>
<p><span m="1917000">So this means after k rounds, we have the right answer for</span> <span m="1923000">v_k, which is v. So, the only question is how</span> <span m="1928000">big could k be? And, it better be the right</span> <span m="1932000">answer, at most, v minus one is the claim by the</span> <span m="1938000">algorithm that you only need to do v minus one steps.</span> </p>
<p><span m="1944000">And indeed, the number of edges in a simple path in a graph is,</span> <span m="1950000">at most, the number of vertices minus one.</span> </p>
<p><span m="1957000">k is, at most, v minus one because p is</span> <span m="1960000">simple. So, that's why we had to assume</span> <span m="1963000">that it wasn't just any shortest path.</span> </p>
<p><span m="1967000">It had to be a simple one so it didn't repeat any vertices.</span> </p>
<p><span m="1972000">So there are, at most, V vertices in the</span> <span m="1975000">path, so at most, V minus one edges in the path.</span> </p>
<p><span m="1981000">OK, and that's all there is to Bellman-Ford.</span> </p>
<p><span m="1985000">So: pretty simple in correctness.</span> </p>
<p><span m="1988000">Of course, we're using a lot of the lemmas that we proved last</span> <span m="1995000">time, which makes it easier. OK, a consequence of this</span> <span m="2001000">theorem, or of this proof is that if Bellman-Ford fails to</span> <span m="2007000">converge, and that's what the algorithm is checking is whether</span> <span m="2013000">this relaxation still requires work after these d minus one</span> <span m="2019000">steps. Right, the end of this</span> <span m="2024000">algorithm is run another round, a V'th round,</span> <span m="2028000">see whether anything changes. So, we'll say that the</span> <span m="2033000">algorithm fails to converge after V minus one steps or</span> <span m="2038000">rounds. Then, there has to be a</span> <span m="2041000">negative weight cycle. OK, this is just a</span> <span m="2044000">contrapositive of what we proved.</span> </p>
<p><span m="2046000">We proved that if you assume there's no negative weight</span> <span m="2050000">cycle, then we know that d of s is zero, and then all this</span> <span m="2054000">argument says is you've got to converge after v minus one</span> <span m="2058000">rounds. There can't be anything left to</span> <span m="2061000">do once you've reached the shortest path weights because</span> <span m="2064000">you're going monotonically; you can never hit the bottom.</span> </p>
<p><span m="2070000">You can never go to the floor. So, if you fail to converge</span> <span m="2073000">somehow after V minus one rounds, you've got to have</span> <span m="2077000">violated the assumption. The only assumption we made was</span> <span m="2080000">there's no negative weight cycle.</span> </p>
<p><span m="2082000">So, this tells us that Bellman-Ford is actually</span> <span m="2085000">correct. When it says that there is a</span> <span m="2088000">negative weight cycle, it indeed means it.</span> </p>
<p><span m="2091000">It's true. OK, and you can modify</span> <span m="2093000">Bellman-Ford in that case to sort of run a little longer,</span> <span m="2096000">and find where all the minus infinities are.</span> </p>
<p><span m="2101000">And that is, in some sense,</span> <span m="2102000">one of the things you have to do in your problem set,</span> <span m="2105000">I believe. So, I won't cover it here.</span> </p>
<p><span m="2108000">But, it's a good exercise in any case to figure out how you</span> <span m="2111000">would find where the minus infinities are.</span> </p>
<p><span m="2114000">What are all the vertices reachable from negative weight</span> <span m="2118000">cycle? Those are the ones that have</span> <span m="2120000">minus infinities. OK, so you might say,</span> <span m="2122000">well, that was awfully fast. Actually, it's not over yet.</span> </p>
<p><span m="2126000">The episode is not yet ended. We're going to use Bellman-Ford</span> <span m="2129000">to solve the even bigger and greater shortest path problems.</span> </p>
<p><span m="2135000">And in the remainder of today's lecture, we will see it applied</span> <span m="2139000">to a more general problem, in some sense,</span> <span m="2142000">called linear programming. And the next lecture,</span> <span m="2145000">we'll really use it to do some amazing stuff with all pairs</span> <span m="2149000">shortest paths. Let's go over here.</span> </p>
<p><span m="2152000">So, our goal, although it won't be obvious</span> <span m="2155000">today, is to be able to compute the shortest paths between every</span> <span m="2159000">pair of vertices, which we could certainly do at</span> <span m="2163000">this point just by running Bellman-Ford v times.</span> </p>
<p><span m="2168000">OK, but we want to do better than that, of course.</span> </p>
<p><span m="2175000">And, that will be the climax of the trilogy.</span> </p>
<p><span m="2181000">OK, today we just discovered who Luke's father is.</span> </p>
<p><span m="2190000">So, it turns out the father of shortest paths is linear</span> <span m="2197000">programming. Actually, simultaneously the</span> <span m="2202000">father and the mother because programs do not have gender.</span> </p>
<p><span m="2210000">OK, my father likes to say, we both took improv comedy</span> <span m="2217000">lessons so we have degrees in improvisation.</span> </p>
<p><span m="2225000">And he said, you know, we went to improv</span> <span m="2227000">classes in order to learn how to make our humor better.</span> </p>
<p><span m="2230000">And, the problem is, it didn't actually make our</span> <span m="2233000">humor better. It just made us less afraid to</span> <span m="2236000">use it. [LAUGHTER] So,</span> <span m="2237000">you are subjected to all this improv humor.</span> </p>
<p><span m="2240000">I didn't see the connection of Luke's father,</span> <span m="2242000">but there you go. OK, so, linear programming is a</span> <span m="2245000">very general problem, a very big tool.</span> </p>
<p><span m="2249000">Has anyone seen linear programming before?</span> </p>
<p><span m="2252000">OK, one person. And, I'm sure you will,</span> <span m="2256000">at some time in your life, do anything vaguely computing</span> <span m="2260000">optimization related, linear programming comes up at</span> <span m="2265000">some point. It's a very useful tool.</span> </p>
<p><span m="2268000">You're given a matrix and two vectors: not too exciting yet.</span> </p>
<p><span m="2273000">What you want to do is find a vector.</span> </p>
<p><span m="2277000">This is a very dry description. We'll see what makes it so</span> <span m="2282000">interesting in a moment.</span> </p>
<p><span m="2297000">So, you want to maximize some objective, and you have some</span> <span m="2301000">constraints. And they're all linear.</span> </p>
<p><span m="2304000">So, the objective is a linear function in the variables x,</span> <span m="2308000">and your constraints are a bunch of linear constraints,</span> <span m="2312000">inequality constraints, that's one makes an</span> <span m="2316000">interesting. It's not just solving a linear</span> <span m="2319000">system as you've seen in linear algebra, or whatever.</span> </p>
<p><span m="2323000">Or, of course, it could be that there is no</span> <span m="2326000">such x. OK: vaguely familiar you might</span> <span m="2329000">think to the theorem about Bellman-Ford.</span> </p>
<p><span m="2332000">And, we'll show that there's some kind of connection here</span> <span m="2336000">that either you want to find something, or show that it</span> <span m="2341000">doesn't exist. Well, that's still a pretty</span> <span m="2346000">vague connection, but I also want to maximize</span> <span m="2349000">something, or are sort of minimize the shortest paths,</span> <span m="2353000">OK, somewhat similar. We have these constraints.</span> </p>
<p><span m="2357000">So, yeah. This may be intuitive to you,</span> <span m="2359000">I don't know. I prefer a more geometric</span> <span m="2362000">picture, and I will try to draw such a geometric picture,</span> <span m="2367000">and I've never tried to do this on a blackboard,</span> <span m="2370000">so it should be interesting. I think I'm going to fail</span> <span m="2376000">miserably. It sort of looks like a</span> <span m="2379000">dodecahedron, right?</span> </p>
<p><span m="2381000">Sort of, kind of, not really.</span> </p>
<p><span m="2384000">A bit rough on the bottom, OK.</span> </p>
<p><span m="2387000">So, if you have a bunch of linear constraints,</span> <span m="2391000">this is supposed to be in 3-D. Now I labeled it.</span> </p>
<p><span m="2396000">It's now in 3-D. Good.</span> </p>
<p><span m="2400000">So, you have these linear constraints.</span> </p>
<p><span m="2402000">That turns out to define hyperplanes in n dimensions.</span> </p>
<p><span m="2406000">OK, so you have this base here that's three-dimensional space.</span> </p>
<p><span m="2411000">So, n equals three. And, these hyperplanes,</span> <span m="2414000">if you're looking at one side of the hyperplane,</span> <span m="2417000">that's the less than or equal to, if you take the</span> <span m="2421000">intersection, you get some convex polytope or</span> <span m="2424000">polyhedron. In 3-D, you might get a</span> <span m="2427000">dodecahedron or whatever. And, your goal,</span> <span m="2429000">you have some objective vector c, let's say,</span> <span m="2433000">up. Suppose that's the c vector.</span> </p>
<p><span m="2437000">Your goal is to find the highest point in this polytope.</span> </p>
<p><span m="2442000">So here, it's maybe this one. OK, this is the target.</span> </p>
<p><span m="2447000">This is the optimal, x.</span> </p>
<p><span m="2449000">That is the geometric view. If you prefer the algebraic</span> <span m="2454000">view, you want to maximize the c transpose times x.</span> </p>
<p><span m="2460000">So, this is m. This is n.</span> </p>
<p><span m="2461000">Check out the dimensions work out.</span> </p>
<p><span m="2464000">So that's saying you want to maximize the dot product.</span> </p>
<p><span m="2468000">You want to maximize the extent to which x is in the direction</span> <span m="2473000">c. And, you want to maximize that</span> <span m="2476000">subject to some constraints, which looks something like</span> <span m="2480000">this, maybe. So, this is A,</span> <span m="2482000">and it's m by n. You want to multiply it by,</span> <span m="2485000">it should be something of height n.</span> </p>
<p><span m="2490000">That's x. Let me put x down here,</span> <span m="2492000">n by one. And, it should be less than or</span> <span m="2496000">equal to something of this height, which is B,</span> <span m="2499000">the right hand side. OK, that's the algebraic view,</span> <span m="2504000">which is to check out all the dimensions are working out.</span> </p>
<p><span m="2508000">But, you can read these off in each row here,</span> <span m="2512000">when multiplied by this column, gives you one value here.</span> </p>
<p><span m="2517000">And as just a linear constraints on all the x sides.</span> </p>
<p><span m="2523000">So, you want to maximize this linear function of x_1 up to x_n</span> <span m="2528000">subject to these constraints, OK?</span> </p>
<p><span m="2531000">Pretty simple, but pretty powerful in general.</span> </p>
<p><span m="2536000">So, it turns out that with, you can formulate a huge number</span> <span m="2541000">of problems such as shortest paths as a linear program.</span> </p>
<p><span m="2546000">So, it's a general tool. And in this class,</span> <span m="2551000">we will not cover any algorithms for solving linear</span> <span m="2557000">programming. It's a bit tricky.</span> </p>
<p><span m="2560000">I'll just mention that they are out there.</span> </p>
<p><span m="2564000">So, there's many efficient algorithms, and lots of code</span> <span m="2570000">that does this. It's a very practical setup.</span> </p>
<p><span m="2575000">So, lots of algorithms to solve LP's, linear programs.</span> </p>
<p><span m="2582000">Linear programming is usually called LP.</span> </p>
<p><span m="2585000">And, I'll mention a few of them.</span> </p>
<p><span m="2588000">There's the simplex algorithm. This is one of the first.</span> </p>
<p><span m="2594000">I think it is the first, the ellipsoid algorithm.</span> </p>
<p><span m="2598000">There's interior point methods, and there's random sampling.</span> </p>
<p><span m="2604000">I'll just say a little bit about each of these because</span> <span m="2609000">we're not going to talk about any of them in depth.</span> </p>
<p><span m="2616000">The simplex algorithm, this is, I mean,</span> <span m="2618000">one of the first algorithms in the world in some sense,</span> <span m="2621000">certainly one of the most popular.</span> </p>
<p><span m="2623000">It's still used today. Almost all linear programming</span> <span m="2627000">code uses the simplex algorithm. It happens to run an</span> <span m="2630000">exponential time in the worst-case, so it's actually</span> <span m="2633000">pretty bad theoretically. But in practice,</span> <span m="2636000">it works really well. And there is some recent work</span> <span m="2639000">that tries to understand this. It's still exponential in the</span> <span m="2643000">worst case. But, it's practical.</span> </p>
<p><span m="2646000">There's actually an open problem whether there exists a</span> <span m="2650000">variation of simplex that runs in polynomial time.</span> </p>
<p><span m="2653000">But, I won't go into that. That's a major open problem in</span> <span m="2657000">this area of linear programming. The ellipsoid algorithm was the</span> <span m="2662000">first algorithm to solve linear programming in polynomial time.</span> </p>
<p><span m="2666000">So, for a long time, people didn't know.</span> </p>
<p><span m="2670000">Around this time, people started realizing</span> <span m="2672000">polynomial time is a good thing. That happened around the late</span> <span m="2676000">60s. Polynomial time is good.</span> </p>
<p><span m="2677000">And, the ellipsoid algorithm is the first one to do it.</span> </p>
<p><span m="2681000">It's a very general algorithm, and very powerful,</span> <span m="2684000">theoretically: completely impractical.</span> </p>
<p><span m="2686000">But, it's cool. It lets you do things like you</span> <span m="2689000">can solve a linear program that has exponentially many</span> <span m="2692000">constraints in polynomial time. You've got all sorts of crazy</span> <span m="2696000">things. So, I'll just say it's</span> <span m="2697000">polynomial time. I can't say something nice</span> <span m="2701000">about it; don't say it at all. It's impractical.</span> </p>
<p><span m="2704000">Interior point methods are sort of the mixture.</span> </p>
<p><span m="2707000">They run in polynomial time. You can guarantee that.</span> </p>
<p><span m="2711000">And, they are also pretty practical, and there's sort of</span> <span m="2714000">this competition these days about whether simplex or</span> <span m="2718000">interior point is better. And, I don't know what it is</span> <span m="2721000">today but a few years ago they were neck and neck.</span> </p>
<p><span m="2724000">And, random sampling is a brand new approach.</span> </p>
<p><span m="2727000">This is just from a couple years ago by two MIT professors,</span> <span m="2731000">Dimitris Bertsimas and Santosh Vempala, I guess the other is in</span> <span m="2735000">applied math. So, just to show you,</span> <span m="2739000">there's active work in this area.</span> </p>
<p><span m="2741000">People are still finding new ways to solve linear programs.</span> </p>
<p><span m="2744000">This is completely randomized, and very simple,</span> <span m="2747000">and very general. It hasn't been implemented,</span> <span m="2750000">so we don't know how practical it is yet.</span> </p>
<p><span m="2752000">But, it has potential. OK: pretty neat.</span> </p>
<p><span m="2754000">OK, we're going to look at a somewhat simpler version of</span> <span m="2757000">linear programming. The first restriction we are</span> <span m="2762000">going to make is actually not much of a restriction.</span> </p>
<p><span m="2765000">But, nonetheless we will consider it, it's a little bit</span> <span m="2769000">easier to think about. So here, we had some polytope</span> <span m="2773000">we wanted to maximize some objective.</span> </p>
<p><span m="2776000">In a feasibility problem, I just want to know,</span> <span m="2779000">is the polytope empty? Can you find any point in that</span> <span m="2783000">polytope? Can you find any set of values,</span> <span m="2786000">x, that satisfy these constraints?</span> </p>
<p><span m="2790000">OK, so there's no objective. c, just find x such that AX is</span> <span m="2794000">less than or equal to B. OK, it turns out you can prove</span> <span m="2799000">a very general theorem that if you can solve linear</span> <span m="2803000">feasibility, you can also solve linear programming.</span> </p>
<p><span m="2807000">We won't prove that here, but this is actually no easier</span> <span m="2812000">than the original problem even though it feels easier,</span> <span m="2816000">and it's easier to think about. I was just saying actually no</span> <span m="2823000">easier than LP. OK, the next restriction we're</span> <span m="2828000">going to make is a real restriction.</span> </p>
<p><span m="2831000">And it simplifies the problem quite a bit.</span> </p>
<p><span m="2850000">And that's to look at different constraints.</span> </p>
<p><span m="2855000">And, if all this seemed a bit abstract so far,</span> <span m="2860000">we will now ground ourselves little bit.</span> </p>
<p><span m="2865000">A system of different constraints is a linear</span> <span m="2871000">feasibility problem. So, it's an LP where there's no</span> <span m="2877000">objective. And, it's with a restriction,</span> <span m="2886000">so, where each row of the matrix, so, the matrix,</span> <span m="2897000">A, has one one, and it has one minus one,</span> <span m="2906000">and everything else in the row is zero.</span> </p>
<p><span m="2916000">OK, in other words, each constraint has its very</span> <span m="2920000">simple form. It involves two variables and</span> <span m="2925000">some number. So, we have something like x_j</span> <span m="2929000">minus x_i is less than or equal to w_ij.</span> </p>
<p><span m="2933000">So, this is just a number. These are two variables.</span> </p>
<p><span m="2940000">There's a minus sign, no values up here,</span> <span m="2942000">no coefficients, no other of the X_k's appear,</span> <span m="2946000">just two of them. And, you have a bunch of</span> <span m="2949000">constraints of this form, one per row of the matrix.</span> </p>
<p><span m="2953000">Geometrically, I haven't thought about what</span> <span m="2956000">this means. I think it means the</span> <span m="2958000">hyperplanes are pretty simple. Sorry I can't do better than</span> <span m="2962000">that. It's a little hard to see this</span> <span m="2965000">in high dimensions. But, it will start to</span> <span m="2970000">correspond to something we've seen, namely the board that its</span> <span m="2978000">next to, very shortly. OK, so let's do a very quick</span> <span m="2985000">example mainly to have something to point at.</span> </p>
<p><span m="2990000">Here's a very simple system of difference constraints --</span> <span m="3011000">-- OK, and a solution. Why not?</span> </p>
<p><span m="3013000">It's not totally trivial to solve this, but here's a</span> <span m="3018000">solution. And the only thing to check is</span> <span m="3021000">that each of these constraints is satisfied.</span> </p>
<p><span m="3025000">x_1 minus x_2 is three, which is less than or equal to</span> <span m="3029000">three, and so on. There could be negative values.</span> </p>
<p><span m="3035000">There could be positive values. It doesn't matter.</span> </p>
<p><span m="3042000">I'd like to transform this system of difference constraints</span> <span m="3049000">into a graph because we know a lot about graphs.</span> </p>
<p><span m="3055000">So, we're going to call this the constraint graph.</span> </p>
<p><span m="3063000">And, it's going to represent these constraints.</span> </p>
<p><span m="3068000">How'd I do it? Well, I take every constraint,</span> <span m="3073000">which in general looks like this, and I convert it into an</span> <span m="3080000">edge. OK, so if I write it as x_j</span> <span m="3084000">minus x_i is less than or equal to some w_ij,</span> <span m="3089000">w seems suggestive of weights. That's exactly why I called it</span> <span m="3096000">w. I'm going to make that an edge</span> <span m="3098000">from v_i to v_j. So, the order flips a little</span> <span m="3101000">bit. And, the weight of that edge is</span> <span m="3104000">w_ij. So, just do that.</span> </p>
<p><span m="3106000">Make n vertices. So, you have the number of</span> <span m="3109000">vertices equals n. The number of edges equals the</span> <span m="3113000">number of constraints, which is m, the height of the</span> <span m="3116000">matrix, and just transform. So, for example,</span> <span m="3121000">here we have three variables. So, we have three vertices,</span> <span m="3126000">v_1, v_2, v_3. We have x_1 minus x_2.</span> </p>
<p><span m="3129000">So, we have an edge from v_2 to v_1 of weight three.</span> </p>
<p><span m="3134000">We have x_2 minus x_3. So, we have an edge from v_3 to</span> <span m="3138000">v_2 of weight minus two. And, we have x_1 minus x_3.</span> </p>
<p><span m="3143000">So, we have an edge from v_3 to v_1 of weight two.</span> </p>
<p><span m="3147000">I hope I got the directions right.</span> </p>
<p><span m="3152000">Yep. So, there it is,</span> <span m="3154000">a graph: currently no obvious connection to shortest paths,</span> <span m="3160000">right? But in fact,</span> <span m="3162000">this constraint is closely related to shortest paths.</span> </p>
<p><span m="3167000">So let me just rewrite it. You could say,</span> <span m="3172000">well, an x_j is less than or equal to x_i plus w_ij.</span> </p>
<p><span m="3179000">Or, you could think of it as d[j] less than or equal to d[i]</span> <span m="3183000">plus w_ij. This is a conceptual balloon.</span> </p>
<p><span m="3187000">Look awfully familiar? A lot like the triangle</span> <span m="3190000">inequality, a lot like relaxation.</span> </p>
<p><span m="3193000">So, there's a very close connection between these two</span> <span m="3197000">problems as we will now prove.</span> </p>
<p><span m="3223000">So, we're going to have two theorems.</span> </p>
<p><span m="3225000">And, they're going to look similar to the correctness of</span> <span m="3229000">Bellman-Ford in that they talk about negative weight cycles.</span> </p>
<p><span m="3233000">Here we go. It turns out,</span> <span m="3234000">I mean, we have this constraint graph.</span> </p>
<p><span m="3237000">It can have negative weights. It can have positive weights.</span> </p>
<p><span m="3242000">It turns out what matters is if you have a negative weight</span> <span m="3245000">cycle. So, the first thing to prove is</span> <span m="3247000">that if you have a negative weight cycle that something bad</span> <span m="3251000">happens. OK, what could happen bad?</span> </p>
<p><span m="3253000">Well, we're just trying to satisfy this system of</span> <span m="3256000">constraints. So, the bad thing is that there</span> <span m="3259000">might not be any solution. These constraints may be</span> <span m="3262000">infeasible. And that's the claim.</span> </p>
<p><span m="3264000">The claim is that this is actually an if and only if.</span> </p>
<p><span m="3269000">But first we'll proved the if. If you have a negative weight</span> <span m="3273000">cycle, you're doomed. The difference constraints are</span> <span m="3278000">unsatisfiable. That's a more intuitive way to</span> <span m="3281000">say it. In the LP world,</span> <span m="3283000">they call it infeasible. But unsatisfiable makes a lot</span> <span m="3288000">more sense. There's no way to assign the</span> <span m="3291000">x_i's in order to satisfy all the constraints simultaneously.</span> </p>
<p><span m="3296000">So, let's just take a look. Consider a negative weight</span> <span m="3301000">cycle. It starts at some vertex,</span> <span m="3303000">goes through some vertices, and at some point comes back.</span> </p>
<p><span m="3307000">I don't care whether it repeats vertices, just as long as this</span> <span m="3311000">cycle, from v_1 to v_1 is a negative weight cycle strictly</span> <span m="3315000">negative weight.</span> </p>
<p><span m="3326000">OK, and what I'm going to do is just write down all the</span> <span m="3330000">constraints. Each of these edges corresponds</span> <span m="3334000">to a constraint, which must be in the set of</span> <span m="3337000">constraints because we had that graph.</span> </p>
<p><span m="3340000">So, these are all edges. Let's look at what they give</span> <span m="3345000">us. So, we have an edge from v_1 to</span> <span m="3348000">v_2. That corresponds to x_2 minus</span> <span m="3350000">x_1 is, at most, something, w_12.</span> </p>
<p><span m="3353000">Then we have x_3 minus x_2. That's the weight w_23,</span> <span m="3357000">and so on. And eventually we get up to</span> <span m="3364000">something like x_k minus x_(k-1).</span> </p>
<p><span m="3368000">That's this edge: w_(k-1),k , and lastly we have</span> <span m="3375000">this edge, which wraps around. So, it's x_1 minus x_k,</span> <span m="3383000">w_k1 if I've got the signs right.</span> </p>
<p><span m="3390000">Good, so here's a bunch of constraints.</span> </p>
<p><span m="3395000">What do you suggest I do with them?</span> </p>
<p><span m="3400000">Anything interesting about these constraints,</span> <span m="3407000">say, the left hand sides? Sorry?</span> </p>
<p><span m="3412000">It sounded like the right word. What was it?</span> </p>
<p><span m="3420000">Telescopes, yes, good.</span> </p>
<p><span m="3421000">Everything cancels. If I added these up,</span> <span m="3424000">there's an x_2 and a minus x_2. There's a minus x_1 and an x_1.</span> </p>
<p><span m="3428000">There's a minus XK and an XK. Everything here cancels if I</span> <span m="3432000">add up the left hand sides. So, what happens if I add up</span> <span m="3435000">the right hand sides? Over here I get zero,</span> <span m="3438000">my favorite answer. And over here,</span> <span m="3440000">we get all the weights of all the edges in the negative weight</span> <span m="3444000">cycle, which is the weight of the cycle, which is negative.</span> </p>
<p><span m="3450000">So, zero is strictly less than zero: contradiction.</span> </p>
<p><span m="3453000">Contradiction: wait a minute,</span> <span m="3455000">we didn't assume anything that was false.</span> </p>
<p><span m="3457000">So, it's not really a contradiction in the</span> <span m="3460000">mathematical sense. We didn't contradict the world.</span> </p>
<p><span m="3463000">We just said that these constraints are contradictory.</span> </p>
<p><span m="3467000">In other words, if you pick any values of the</span> <span m="3470000">x_i's, there is no way that these can all be true because</span> <span m="3473000">that you would get a contradiction.</span> </p>
<p><span m="3475000">So, it's impossible for these things to be satisfied by some</span> <span m="3479000">real x_i's. So, these must be</span> <span m="3481000">unsatisfiable. Let's say there's no satisfying</span> <span m="3487000">assignment, a little more precise, x_1 up to x_m,</span> <span m="3491000">no weights. Can we satisfy those</span> <span m="3494000">constraints? Because they add up to zero on</span> <span m="3498000">the left-hand side, and negative on the right-hand</span> <span m="3503000">side. OK, so that's an easy proof.</span> </p>
<p><span m="3506000">The reverse direction will be only slightly harder.</span> </p>
<p><span m="3513000">OK, so, cool. We have this connection.</span> </p>
<p><span m="3514000">So motivation is, suppose you'd want to solve</span> <span m="3517000">these difference constraints. And we'll see one such</span> <span m="3520000">application. I Googled around for difference</span> <span m="3522000">constraints. There is a fair number of</span> <span m="3524000">papers that care about difference constraints.</span> </p>
<p><span m="3526000">And, they all use shortest paths to solve them.</span> </p>
<p><span m="3529000">So, if we can prove a connection between shortest</span> <span m="3531000">paths, which we know how to compute, and difference</span> <span m="3534000">constraints, then we'll have something cool.</span> </p>
<p><span m="3536000">And, next class will see even more applications of difference</span> <span m="3540000">constraints. It turns out they're really</span> <span m="3545000">useful for all pairs shortest paths.</span> </p>
<p><span m="3549000">OK, but for now let's just prove this equivalence and</span> <span m="3556000">finish it off. So, the reverse direction is if</span> <span m="3561000">there's no negative weight cycle in this constraint graph,</span> <span m="3569000">then the system better be satisfiable.</span> </p>
<p><span m="3575000">The claim is that these negative weight cycles are the</span> <span m="3582000">only barriers for finding a solution to these difference</span> <span m="3589000">constraints. I have this feeling somewhere</span> <span m="3594000">here. I had to talk about the</span> <span m="3598000">constraint graph. Good.</span> </p>
<p><span m="3613000">Satisfied, good. So, here we're going to see a</span> <span m="3619830">technique that is very useful when thinking about shortest</span> <span m="3628482">paths. And, it's a bit hard to guess,</span> <span m="3632788">especially if you haven't seen it before.</span> </p>
<p><span m="3636505">This is useful in problem sets, and in quizzes,</span> <span m="3640780">and finals, and everything. So, keep this in mind.</span> </p>
<p><span m="3645334">I mean, I'm using it to prove this rather simple theorem,</span> <span m="3650539">but the idea of changing the graph, so I'm going to call this</span> <span m="3656115">constraint graph G. Changing the graph is a very</span> <span m="3660483">powerful idea. So, we're going to add a new</span> <span m="3664386">vertex, s, or source, use the source,</span> <span m="3667732">Luke, and we're going to add a bunch of edges from s because</span> <span m="3673215">being a source, it better be connected to some</span> <span m="3677397">things. So, we are going to add a zero</span> <span m="3683529">weight edge, or weight zero edge from s to everywhere,</span> <span m="3689764">so, to every other vertex in the constraint graph.</span> </p>
<p><span m="3696000">Those vertices are called v_i, v_1 up to v_n.</span> </p>
<p><span m="3700121">So, I have my constraint graph. But I'll copy this one so I can</span> <span m="3705928">change it. It's always good to backup your</span> <span m="3709768">work before you make changes, right?</span> </p>
<p><span m="3713046">So now, I want to add a new vertex, s, over here,</span> <span m="3717542">my new source. I just take my constraint</span> <span m="3721195">graph, whatever it looks like, add in weight zero edges to all</span> <span m="3726909">the other vertices. Simple enough.</span> </p>
<p><span m="3731171">Now, what did I do? What did you do?</span> </p>
<p><span m="3734100">Well, I have a candidate source now which can reach all the</span> <span m="3738953">vertices. So, shortest path from s,</span> <span m="3741799">hopefully, well, paths from s exist.</span> </p>
<p><span m="3744728">I can get from s to everywhere in weight at most zero.</span> </p>
<p><span m="3750000">OK, maybe less. Could it be less?</span> </p>
<p><span m="3751851">Well, you know, like v_2, I can get to it by</span> <span m="3754338">zero minus two. So, that's less than zero.</span> </p>
<p><span m="3756710">So I've got to be a little careful.</span> </p>
<p><span m="3758677">What if there's a negative weight cycle?</span> </p>
<p><span m="3760933">Oh no? Then there wouldn't be any</span> <span m="3762785">shortest paths. Fortunately,</span> <span m="3764347">we assume that there's no negative weight cycle in the</span> <span m="3767413">original graph. And if you think about it,</span> <span m="3769785">if there's no negative weight cycle in the original graph,</span> <span m="3773082">we add an edge from s to everywhere else.</span> </p>
<p><span m="3775396">We're not making any new negative weight cycles because</span> <span m="3778520">you can start at s and go somewhere at a cost of zero,</span> <span m="3781586">which doesn't affect any weights.</span> </p>
<p><span m="3785000">And then, you are forced to stay in the old graph.</span> </p>
<p><span m="3788920">So, there can't be any new negative weight cycles.</span> </p>
<p><span m="3792840">So, the modified graph has no negative weight cycles.</span> </p>
<p><span m="3797000">That's good because it also has paths from s,</span> <span m="3800519">and therefore it also has shortest paths from s.</span> </p>
<p><span m="3805000">The modified graph has no negative weight because it</span> <span m="3810376">didn't before. And, it has paths from s.</span> </p>
<p><span m="3814487">There's a path from s to every vertex.</span> </p>
<p><span m="3818387">There may not have been before. Before, I couldn't get from v_2</span> <span m="3824923">to v_3, for example. Well, that's still true.</span> </p>
<p><span m="3829561">But from s I can get to everywhere.</span> </p>
<p><span m="3833145">So, that means that this graph, this modified graph,</span> <span m="3838521">has shortest paths. Shortest paths exist from s.</span> </p>
<p><span m="3844974">In other words, if I took all the shortest path</span> <span m="3849860">weights, like I ran Bellman-Ford from s, then,</span> <span m="3854641">I would get a bunch of finite numbers, d of v,</span> <span m="3859421">for every value, for every vertex.</span> </p>
<p><span m="3862926">That seems like a good idea. Let's do it.</span> </p>
<p><span m="3867175">So, shortest paths exist. Let's just assign x_i to be the</span> <span m="3873757">shortest path weight from s to v_i.</span> </p>
<p><span m="3876782">Why not? That's a good choice for a</span> <span m="3879806">number, the shortest path weight from s to v_i.</span> </p>
<p><span m="3883898">This is finite because it's less than infinity,</span> <span m="3887990">and it's greater than minus infinity, so,</span> <span m="3891549">some finite number. That's what we need to do in</span> <span m="3895730">order to satisfy these constraints.</span> </p>
<p><span m="3900000">The claim is that this is a satisfying assignment.</span> </p>
<p><span m="3903933">Why? Triangle inequality.</span> </p>
<p><span m="3905860">Somewhere here we wrote triangle inequality.</span> </p>
<p><span m="3909311">This looks a lot like the triangle inequality.</span> </p>
<p><span m="3912924">In fact, I think that's the end of the proof.</span> </p>
<p><span m="3916456">Let's see here. What we want to be true with</span> <span m="3919908">this assignment is that x_j minus x_i is less than or equal</span> <span m="3924564">to w_ij whenever ij is an edge. Or, let's say v_i,</span> <span m="3928497">v_j, for every such constraint, so, for v_i,</span> <span m="3931949">v_j in the edge set. OK, so what is this true?</span> </p>
<p><span m="3937313">Well, let's just expand it out. So, x_i is this delta,</span> <span m="3942217">and x_j is some other delta. So, we have delta of s,</span> <span m="3946935">vj minus delta of s_vi. And, on the right-hand side,</span> <span m="3951654">well, w_ij, that was the weight of the edge from I to J.</span> </p>
<p><span m="3956743">So, this is the weight of v_i to v_j.</span> </p>
<p><span m="3961000">OK, I will rewrite this slightly.</span> </p>
<p><span m="3963659">Delta s, vj is less than or equal to delta s,</span> <span m="3967315">vi plus w of v_i, v_j.</span> </p>
<p><span m="3969060">And that's the triangle inequality more or less.</span> </p>
<p><span m="3972965">The shortest path from s to v_j is, at most, shortest path from</span> <span m="3978117">s to v_i plus a particular path from v_i to v_j,</span> <span m="3982022">namely the single edge v_i to v_j.</span> </p>
<p><span m="3984765">This could only be longer than the shortest path.</span> </p>
<p><span m="3990000">And so, that makes the right-hand side bigger,</span> <span m="3993372">which makes this inequality more true, meaning it was true</span> <span m="3997644">before. And now it's still true.</span> </p>
<p><span m="3999967">And, that proves it. This is true.</span> </p>
<p><span m="4002441">And, these were all equivalent statements.</span> </p>
<p><span m="4005513">This we know to be true by triangle inequality.</span> </p>
<p><span m="4008961">Therefore, these constraints are all satisfied.</span> </p>
<p><span m="4012408">Magic. I'm so excited here.</span> </p>
<p><span m="4014357">So, we've proved that having a negative weight cycle is exactly</span> <span m="4019004">when these system of difference constraints are unsatisfiable.</span> </p>
<p><span m="4025000">So, if we want to satisfy them, if we want to find the right</span> <span m="4028241">answer to x, we run Bellman-Ford.</span> </p>
<p><span m="4030000">Either it says, oh, no negative weight cycle.</span> </p>
<p><span m="4032417">Then you are hosed. Then, there is no solution.</span> </p>
<p><span m="4034945">But that's the best you could hope to know.</span> </p>
<p><span m="4037252">Otherwise, it says, oh, there was no negative</span> <span m="4039670">weight cycle, and here are your shortest path</span> <span m="4042087">weights. You just plug them in,</span> <span m="4043736">and bam, you have your x_i's that satisfy the constraints.</span> </p>
<p><span m="4046868">Awesome. Now, it wasn't just any graph.</span> </p>
<p><span m="4050000">I mean, we started with constraints, algebra,</span> <span m="4052877">we converted it into a graph by this transform.</span> </p>
<p><span m="4055886">Then we added a source vertex, s.</span> </p>
<p><span m="4057978">So, I mean, we had to build a graph to solve our problem,</span> <span m="4061641">very powerful idea. Cool.</span> </p>
<p><span m="4063210">This is the idea of reduction. You can reduce the problem you</span> <span m="4067135">want to solve into some problem you know how to solve.</span> </p>
<p><span m="4070601">You know how to solve shortest paths when there are no negative</span> <span m="4074656">weight cycles, or find out that there is a</span> <span m="4077337">negative weight cycle by Bellman-Ford.</span> </p>
<p><span m="4081000">So, now we know how to solve difference constraints.</span> </p>
<p><span m="4086099">It turns out you can do even more.</span> </p>
<p><span m="4089400">Bellman-Ford does a little bit more than just solve these</span> <span m="4095000">constraints. But first let me write down</span> <span m="4098899">what I've been jumping up and down about.</span> </p>
<p><span m="4102899">The corollary is you can use Bellman-Ford.</span> </p>
<p><span m="4107000">I mean, you make this graph. Then you apply Bellman-Ford,</span> <span m="4114484">and it will solve your system of difference constraints.</span> </p>
<p><span m="4121330">So, let me put in some numbers here.</span> </p>
<p><span m="4125685">You have m difference constraints.</span> </p>
<p><span m="4129792">And, you have n variables. And, it will solve them in</span> <span m="4136265">order m times n time. Actually, these numbers go up</span> <span m="4142416">slightly because we are adding n edges, and we're adding one</span> <span m="4147332">vertex, but assuming all of these numbers are nontrivial,</span> <span m="4152000">m is at least n. It's order MN time.</span> </p>
<p><span m="4154916">OK, trying to avoid cases where some of them are close to zero.</span> </p>
<p><span m="4160082">Good. So, some other facts,</span> <span m="4162250">that's what I just said. And we'll leave these as</span> <span m="4166250">exercises because they're not too essential.</span> </p>
<p><span m="4171000">The main thing we need is this. But, some other cool facts is</span> <span m="4175627">that Bellman-Ford actually optimizes some objective</span> <span m="4179484">functions. So, we are saying it's just a</span> <span m="4182492">feasibility problem. We just want to know whether</span> <span m="4186193">these constraints are satisfiable.</span> </p>
<p><span m="4188738">In fact, you can add a particular objective function.</span> </p>
<p><span m="4192750">So, you can't give it an arbitrary objective function,</span> <span m="4196837">but here's one of interest. x_1 plus x_2 plus x_n,</span> <span m="4204647">OK, but not just that. We have some constraints.</span> </p>
<p><span m="4224000">OK, this is a linear program. I want to maximize the sum of</span> <span m="4227395">the x_i's subject to all the x_i's being nonpositive and the</span> <span m="4230849">difference constraints. So, this we had before.</span> </p>
<p><span m="4233542">This is fine. We noticed at some point you</span> <span m="4235943">could get from s to everywhere with cost, at most,</span> <span m="4238811">zero. So, we know that in this</span> <span m="4240509">assignment all of the x_i's are negative.</span> </p>
<p><span m="4242851">That's not necessary, but it's true when you run</span> <span m="4245602">Bellman-Ford. So if you solve your system</span> <span m="4247943">using Bellman-Ford, which is no less general than</span> <span m="4250754">anything else, you happen to get nonpositive</span> <span m="4253272">x_i's. And so, subject to that</span> <span m="4254969">constraint, it actually makes them is close to zero as</span> <span m="4258072">possible in the L1 norm. In the sum of these values,</span> <span m="4264009">it tries to make the sum as close to zero,</span> <span m="4268577">it tries to make the values as small as possible in absolute</span> <span m="4275154">value in this sense. OK, it does more than that.</span> </p>
<p><span m="4280393">It cooks, it cleans, it finds shortest paths.</span> </p>
<p><span m="4285297">It also minimizes the spread, the maximum over all i of x_i</span> <span m="4291761">minus the minimum over all i of x_i.</span> </p>
<p><span m="4297000">So, I mean, if you have your real line, and here are the</span> <span m="4300840">x_i's wherever they are. It minimizes this distance.</span> </p>
<p><span m="4304402">And zero is somewhere over here.</span> </p>
<p><span m="4306567">So, it tries to make the x_i's as compact as possible.</span> </p>
<p><span m="4310268">This is actually the L infinity norm, if you know stuff about</span> <span m="4314458">norms from your linear algebra class.</span> </p>
<p><span m="4316972">OK, this is the L1 norm. I think it minimizes every LP</span> <span m="4320673">norm. Good, so let's use this for</span> <span m="4325170">something. Yeah, let's solve a real</span> <span m="4329163">problem, and then we'll be done for today.</span> </p>
<p><span m="4333978">Next class we'll see the really cool stuff, the really cool</span> <span m="4340790">application of all of this. For now, and we'll see a cool</span> <span m="4347366">but relatively simple application, which is VLSI</span> <span m="4352886">layout. We talked a little bit about</span> <span m="4357528">VLSI way back and divide and conquer.</span> </p>
<p><span m="4360779">You have a bunch of chips, or you want to arrange them,</span> <span m="4365655">and minimize some objectives. So, here's a particular,</span> <span m="4370441">tons of problems that come out of VLSI layout.</span> </p>
<p><span m="4374505">Here's one of them. You have a bunch of features of</span> <span m="4379020">an integrated circuit. You want to somehow arrange</span> <span m="4384583">them on your circuit without putting any two of them too</span> <span m="4389845">close to each other. You have some minimum</span> <span m="4393768">separation like at least they should not get top of each</span> <span m="4399030">other. Probably, you also need some</span> <span m="4402283">separation to put wires in between, and so on,</span> <span m="4406589">so, without putting any two features too close together.</span> </p>
<p><span m="4413000">OK, so just to give you an idea, so I have some objects and</span> <span m="4417152">I'm going to be a little bit vague about how this works.</span> </p>
<p><span m="4421089">You have some features. This is stuff,</span> <span m="4423738">some chips, whatever. We don't really care what their</span> <span m="4427460">shapes look like. I just want to be able to move</span> <span m="4430825">them around so that the gap at any point, so let me just think</span> <span m="4435192">about this gap. This gap should be at least</span> <span m="4438199">some delta. Or, I don't want to use delta.</span> </p>
<p><span m="4441134">Let's say epsilon, good, small number.</span> </p>
<p><span m="4445000">So, I just need some separation between all of my parts.</span> </p>
<p><span m="4448827">And for this problem, I'm going to be pretty simple,</span> <span m="4452378">just say that the parts are only allowed to slide</span> <span m="4455719">horizontally. So, it's a one-dimensional</span> <span m="4458433">problem. These objects are in 2-d,</span> <span m="4460730">or whatever, but I can only slide them an x</span> <span m="4463654">coordinate. So, to model that,</span> <span m="4465672">I'm going to look at the left edge of every part and say,</span> <span m="4469570">well, these two left edges should be at least some</span> <span m="4472981">separation. So, I think of it as whatever</span> <span m="4476848">the distance is plus some epsilon.</span> </p>
<p><span m="4478952">But, you know, if you have some funky 2-d</span> <span m="4481501">shapes you have to compute, well, this is a little bit too</span> <span m="4485135">close because these come into alignment.</span> </p>
<p><span m="4487621">But, there's some constraint, well, for any two pieces,</span> <span m="4491063">I could figure out how close they can get.</span> </p>
<p><span m="4493677">They should get no closer. So, I'm going to call this x_1.</span> </p>
<p><span m="4497309">I'll call this x_2. So, we have some constraint</span> <span m="4500243">like x_2 minus x_1 is at least d plus epsilon,</span> <span m="4503111">or whatever you compute that weight to be.</span> </p>
<p><span m="4507000">OK, so for every pair of pieces, I can do this,</span> <span m="4509735">compute some constraint on how far apart they have to be.</span> </p>
<p><span m="4513066">And, now I'd like to assign these x coordinates.</span> </p>
<p><span m="4515861">Right now, I'm assuming they're just variables.</span> </p>
<p><span m="4518596">I want to slide these pieces around horizontally in order to</span> <span m="4522105">compactify them as much as possible so they fit in the</span> <span m="4525257">smallest chip that I can make because it costs money,</span> <span m="4528350">and time, and everything, and power, everything.</span> </p>
<p><span m="4531145">You always want your chip small.</span> </p>
<p><span m="4534000">So, Bellman-Ford does that. All right, so Bellman-Ford</span> <span m="4540225">solves these constraints because it's just a bunch of difference</span> <span m="4547626">constraints. And we know that they are</span> <span m="4551972">solvable because you could spread all the pieces out</span> <span m="4557963">arbitrarily far. And, it minimizes the spread,</span> <span m="4563250">minimizes the size of the chip I need, a max of x_i minus the</span> <span m="4570298">min of x_i. So, this is it maximizes</span> <span m="4574879">compactness, or minimizes size of the chip.</span> </p>
<p><span m="4578167">OK, this is a one-dimensional problem, so it may seem a little</span> <span m="4582943">artificial, but the two dimensional problem is really</span> <span m="4587014">hard to solve. And this is,</span> <span m="4589049">in fact, the best you can do with a nice polynomial time</span> <span m="4593355">algorithm. There are other applications if</span> <span m="4597419">you're scheduling events in, like, a multimedia environment,</span> <span m="4602024">and you want to guarantee that this audio plays at least two</span> <span m="4606629">seconds after this video, but then there are things that</span> <span m="4610922">are playing at the same time, and they have to be within some</span> <span m="4615605">gap of each other, so, lots of papers about using</span> <span m="4619351">Bellman-Ford, solve difference constraints to</span> <span m="4622786">enable multimedia environments. OK, so there you go.</span> </p>
<p><span m="4626766">And next class we'll see more applications of Bellman-Ford to</span> <span m="4631449">all pairs shortest paths. Questions?</span> </p>
<p><span m="4634181">Great.</span> </p>
</div>
        <div id="vid_transcript" itemprop="description" class="tabContent hide">
<h2 class="subhead">Free Downloads</h2>
<h3 class="subsubhead">Video</h3>
<ul>
<li>iTunes U (<a href="http://itunes.apple.com/gb/podcast/lecture-18-shortest-paths/id341597754?i=63738846">MP4 - 160MB</a>)</li>
<li>Internet Archive (<a href="http://www.archive.org/download/MIT6.046JF05MPEG4/ocw-6.046-16nov2005-220k.mp4">MP4 - 316MB</a>)</li>
</ul>
<br><h3 class="subsubhead">Free Streaming</h3>
<ul><li><a href="http://videolectures.net/mit6046jf05_introduction_algorithms/">VideoLectures.net</a></li></ul>
<br><h3 class="subsubhead">Subtitle</h3>
<ul><li>English - US (<a href="../../../contents/video-lectures/lecture-18-shortest-paths-ii-bellman-ford-linear-programming-difference-constraints/Ttezuzs39nk.srt">SRT</a>)</li></ul>
</div>
    
   </div>  




      					 
        <div class="" id="parent-fieldname-bottom_html_area">
            
            
        </div>
    
                    </div>
<!--Course_inner_chip tag close -->
           		</div>
<!--Course_wrapper tag close --> 
            </div>
<!--left tag close -->
            <div id="right">
                <!--Begin Right Portion -->
                    <div>
    
<div id="portletwrapper-6f63772e7269676874746f70706f72746c65746d616e616765720a636f6e746578740a2f506c6f6e650a646f6e617465" class="portletWrapper kssattr-portlethash-6f63772e7269676874746f70706f72746c65746d616e616765720a636f6e746578740a2f506c6f6e650a646f6e617465">
<div class="portletStaticText portlet-static-donate"><p class="zero"><a href="http://ocw.mit.edu/donate"><img src="../../../common/images/button_donate-now.png" alt="Donate Now." class="donate"></a></p></div>

</div>




</div>

                	<div>
    



</div>


        <div class="" id="parent-fieldname-rsi_top_html_area">
            
            
        </div>
    

<!-- RSI google ad space-->


<div id="google_ads">    
    <script type="text/javascript" src="http://partner.googleadservices.com/gampad/google_service.js"></script><script type="text/javascript">GS_googleAddAdSenseService("ca-pub-6588555046597237");GS_googleEnableAllServices();</script><script type="text/javascript">GA_googleAddSlot("ca-pub-6588555046597237", "VIDEO_INDIVIDUAL_SLOT_A_DL");GA_googleAddSlot("ca-pub-6588555046597237", "VIDEO_INDIVIDUAL_SLOT_B_DL");GA_googleAddSlot("ca-pub-6588555046597237", "VIDEO_INDIVIDUAL_SLOT_C_DL");</script><script type="text/javascript">GA_googleFetchAds();</script><script language="javascript" type="text/javascript">
GA_googleAddAttr("TYPE","HOUSE");
GA_googleAddAttr("DEPARTMENT","6");
GA_googleAddAttr("CRS_BEG2","04");
GA_googleAddAttr("CRS_END","6J");
GA_googleAddAttr("SESSION","F");
GA_googleAddAttr("YEAR","05");
</script><script type="text/javascript">GA_googleFillSlot("VIDEO_INDIVIDUAL_SLOT_A_DL");</script><script type="text/javascript">GA_googleFillSlot("VIDEO_INDIVIDUAL_SLOT_B_DL");</script><script type="text/javascript">GA_googleFillSlot("VIDEO_INDIVIDUAL_SLOT_C_DL");</script>
</div>

<!-- End RSI ads--> 

<div>
    



</div>

            </div>
<!--Right div close -->
            <div class="clear"></div> 
        </div>
<!--grid tag close --> 
      </div>
		
		<div id="bottom">
			<div id="grid">
				
<div id="portletwrapper-6f63772e626f74746f6d706f72746c65746d616e616765720a636f6e746578740a2f506c6f6e650a736974652d666f6f746572" class="portletWrapper kssattr-portlethash-6f63772e626f74746f6d706f72746c65746d616e616765720a636f6e746578740a2f506c6f6e650a736974652d666f6f746572">
<div class="portletStaticText portlet-static-site-footer">
<!--googleoff: index--> <div id="bottom"><div id="grid">
<!-- *begin footer* --> <div role="navigation sitemap" id="footer">
<div class="grid_2 alpha" id="foot-c1">
<h4 class="footer">Find Courses</h4> <ul class="foot-bullet">
<li><a href="http://ocw.mit.edu/courses/find-by-topic/">Find by Topic</a></li>     <li><a href="http://ocw.mit.edu/courses/find-by-number/">Find by Course Number</a></li>     <li><a href="http://ocw.mit.edu/courses/find-by-department/">Find by Department</a></li>     <li><a href="http://ocw.mit.edu/courses/audio-video-courses/">Audio/Video Courses</a></li>     <li><a href="http://ocw.mit.edu/courses/subtitled/">Courses with Subtitles</a></li>     <li><a href="http://ocw.mit.edu/courses/online-textbooks/">Online Textbooks</a></li>     <li><a href="http://ocw.mit.edu/courses/new-courses/">New Courses</a></li>     <li><a href="http://ocw.mit.edu/courses/most-visited-courses/">Most Visited Courses</a></li>     <li><a href="http://ocw.mit.edu/courses/ocw-scholar/">OCW Scholar Courses</a></li>     <li><a href="http://ocw.mit.edu/courses/this-course-at-mit/">This Course at MIT</a></li>     <li><a href="http://ocw.mit.edu/resources/">Supplemental Resources</a></li>     <li><a href="http://ocw.mit.edu/courses/translated-courses/">Translated Courses</a></li>     <li><a href="http://ocw.mit.edu/courses/">View All Courses</a></li> </ul>
</div> <div class="grid_2" id="foot-c2">
<h4 class="footer">About</h4> <ul class="foot-bullet">
<li><a href="http://ocw.mit.edu/about/">About OpenCourseWare</a></li>     <li><a href="http://ocw.mit.edu/about/site-statistics/">Site Stats</a></li>     <li><a href="http://ocw.mit.edu/about/ocw-stories/">OCW Stories</a></li>     <li><a href="http://ocw.mit.edu/about/media-coverage/">Media Coverage</a></li>     <li><a href="http://ocw.mit.edu/about/newsletter/">Newsletter</a></li>     <li><a href="http://ocw.mit.edu/about/media-coverage/press-releases/">Press Releases</a></li> </ul>
</div> <div class="grid_2" id="foot-c3">
<h4 class="footer">Donate</h4> <ul class="foot-bullet">
<li><a href="http://ocw.mit.edu/donate">Make a Donation</a></li>     <li><a href="http://ocw.mit.edu/donate/why-donate/">Why Donate?</a></li>     <li><a href="http://ocw.mit.edu/donate/our-supporters/">Our Supporters</a></li>     <li><a href="http://ocw.mit.edu/donate/other-ways-to-contribute/">Other Ways to Contribute</a></li>     <li><a href="http://ocw.mit.edu/donate/shop-ocw/">Shop OCW</a></li>     <li><a href="http://ocw.mit.edu/support/">Become a Corporate Sponsor</a></li> </ul>
</div> <div class="grid_2" id="foot-c4">
<h4 class="footer">Featured Sites</h4> <ul class="foot-bullet">
<li><a href="http://ocw.mit.edu/high-school/">Highlights for High School</a></li>     <li><a href="http://ocw.mit.edu/educator/">OCW Educator</a></li>     <li><a href="http://ocw.mit.edu/courses/crosslinks/">MIT Crosslinks and OCW</a></li>     <li><a href="http://ocw.mit.edu/ans7870/featured/mitx-courses-on-edx.htm">MITx Courses on edX</a></li>     <li><a href="http://teachingexcellence.mit.edu/">Teaching Excellence at MIT</a></li>     <li><a href="http://www.oeconsortium.org/">Open Education Consortium</a></li> </ul>
<h4 style="margin-top: 14px;" class="footer">Tools</h4> <ul class="foot-bullet">
<li><a href="http://ocw.mit.edu/help/">Help &amp; FAQs</a></li>     <li><a href="../../../common/jsp/feedback.htm">Contact Us</a></li>     <li><a href="../../../common/search/AdvancedSearch.htm">Advanced Search</a></li>     <li><a href="http://ocw.mit.edu/help/site-map/">Site Map</a></li>     <li><a href="../../../common/terms/index.htm">Privacy &amp; Terms of Use</a></li>     <li><a href="http://ocw.mit.edu/help/rss/">RSS Feeds</a></li> </ul>
</div> <div class="grid_4 omega" id="foot-c5">
<h4 class="footer">Our Corporate Supporters</h4> <!-- HOME_CORP_LOGO_1 --> <div class="sponsors_google_ads_even" id="div-gpt-ad-1388181177156-0"><script type="text/javascript">
googletag.cmd.push(function() { googletag.display('div-gpt-ad-1388181177156-0'); });
</script></div> <!-- HOME_CORP_LOGO_2 --> <div class="sponsors_google_ads_odd" id="div-gpt-ad-1388181177156-1"><script type="text/javascript">
googletag.cmd.push(function() { googletag.display('div-gpt-ad-1388181177156-1'); });
</script></div> <!-- HOME_CORP_LOGO_3 --> <div class="sponsors_google_ads_even" id="div-gpt-ad-1388181177156-2"><script type="text/javascript">
googletag.cmd.push(function() { googletag.display('div-gpt-ad-1388181177156-2'); });
</script></div> <!-- HOME_CORP_LOGO_4 --> <div class="sponsors_google_ads_odd" id="div-gpt-ad-1388181177156-3"><script type="text/javascript">
googletag.cmd.push(function() { googletag.display('div-gpt-ad-1388181177156-3'); });
</script></div> <!-- HOME_CORP_LOGO_5 --> <div class="sponsors_google_ads_even" id="div-gpt-ad-1388181177156-4"><script type="text/javascript">
googletag.cmd.push(function() { googletag.display('div-gpt-ad-1388181177156-4'); });
</script></div> <!-- HOME_CORP_LOGO_6 --> <div class="sponsors_google_ads_odd" id="div-gpt-ad-1388181177156-5"><script type="text/javascript">
googletag.cmd.push(function() { googletag.display('div-gpt-ad-1388181177156-5'); });
</script></div>
</div> <div class="grid_12 alpha omega" style="border-top: thin solid #d5c9ba; padding-top: 24px; margin-bottom: 10px; text-align: center;"><p style="font-family: TitilliumText22LRegular,Verdana; text-align: center; font-size: 1.1em;">Support for <span style="letter-spacing: 0.5px;"><strong>MIT OPENCOURSEWARE'S 15th anniversary</strong></span> is provided by <a href="http://www.sapientnitro.com/en-us.html#home"><img style="width: 145px; height: 35px; vertical-align: middle; margin-left: 7px;" alt="SapientNitro logo and nameplate." src="../../../common/images/logo_sapient.png"></a></p></div> <div itemtype="http://schema.org/CollegeOrUniversity" itemscope="" itemprop="publisher" class="grid_12 alpha omega">
<h4 style="border-top: thin solid #d5c9ba; padding-top: 10px; margin-bottom: 10px;" class="footer">About <span itemprop="name">MIT OpenCourseWare</span>
</h4> <p itemprop="description" style="color: #999; font-size: 1em; line-height: 1.5em; margin-top: 10px;">MIT OpenCourseWare makes the materials used in the teaching of almost all of MIT's subjects available on the Web, free of charge. With more than 2,200 courses available, OCW is delivering on the promise of open sharing of knowledge. <a href="http://ocw.mit.edu/about/">Learn more »</a></p>
</div> <div style="border-top: none;" class="grid_12 alpha omega" id="foot-copy">
<a href="http://web.mit.edu"><img style="width: 195; height: 44;" alt="Massachusetts Institute of Technology logo and name." src="../../../common/images/logo_mit.png"></a><a href="http://odl.mit.edu"><img style="width: 289; height: 54; vertical-align: top;" alt="MIT Office of Digital Learning logo and name." src="http://ocw.mit.edu/images/logo_odl.png"></a><a href="http://www.oeconsortium.org/"><img style="width: 219px; height: 59px; vertical-align: top;" alt="Open Education Consortium logo." src="http://ocw.mit.edu/images/logo_oec.png"></a><a itemprop="useRightsUrl" rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img style="width: 126px; height: 44px; margin-right: 0; margin-left: 13px;" alt="Creative Commons logo with terms BY-NC-SA." src="../../../common/images/cc_by-nc-sa.png"></a> <p class="copyright">© 2001–2015<br> Massachusetts Institute of Technology</p> <p style="font-size: 0.9em; margin-bottom: 15px;">Your use of the MIT OpenCourseWare site and materials is subject to our <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/">Creative Commons License</a> and other <a rel="cc:morePermissions" href="../../../common/terms/index.htm">terms of use</a>.</p>
</div>
</div>
</div></div> <!--googleon: index-->
</div>

</div>





                
			</div> <!-- bottom grid end -->
		</div>
<!-- bottom end -->
		
		
   </body>
</html>

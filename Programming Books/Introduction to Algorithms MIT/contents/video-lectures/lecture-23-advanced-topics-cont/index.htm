<!DOCTYPE html><html lang="en">
<head>
<meta charset="utf-8">
<meta name="format-detection" content="telephone=no">
<title>Lecture 23: Advanced Topics (cont.) | Video Lectures | Introduction to Algorithms (SMA 5503) | Electrical Engineering and Computer Science | MIT OpenCourseWare</title>
<!-- Begin Automatic Metadata Insertion --><meta content="6-046j-introduction-to-algorithms-sma-5503-fall-2005" name="WT.cg_n">
<meta content="Lecture 23: Advanced Topics (cont.)" name="WT.cg_s">
<meta content="" name="Description">
<meta content="Leiserson, Charles" name="Author">
<meta content="Demaine, Erik" name="Author">
<meta content="algorithms,efficient algorithms,sorting,search trees,heaps,hashing,divide-and-conquer,dynamic programming,amortized analysis,graph algorithms,shortest paths,network flow,computational geometry,number-theoretic algorithms,polynomial and matrix calculations,caching,parallel computing,Algorithms and Data Structures" name="keywords">
<meta content="6.046J Introduction to Algorithms (SMA 5503) | Lecture 23: Advanced Topics (cont.)" name="Search_Display">
<meta content="Algorithms and Data Structures" itemprop="about">
<!-- End Automatic Metadata Insertion --><link title="default" rel="stylesheet" type="text/css" href="../../../common/styles/grid.css">
<link title="default" rel="stylesheet" type="text/css" href="../../../common/styles/base.css">
<link title="default" rel="stylesheet" type="text/css" href="../../../common/styles/menu.css">
<link title="default" rel="stylesheet" type="text/css" href="../../../common/styles/jquery.bubblepopup.css">
<link title="default" rel="stylesheet" type="text/css" href="../../../common/styles/courses.css">
<link title="default" rel="stylesheet" type="text/css" href="../../../common/styles/courses_new.css">
<link title="default" rel="stylesheet" type="text/css" href="../../../common/styles/jquery.jscrollpane.css">
<link title="default" rel="stylesheet" type="text/css" href="../../../common/styles/media_tabs.css">
<link href="http://ocw.mit.edu/xml/ocwcc.rdf" type="application/rdf+xml" rel="metadata">
<link rel="canonical" href="http://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-046j-introduction-to-algorithms-sma-5503-fall-2005/video-lectures/lecture-23-advanced-topics-cont.">
<link rel="apple-touch-icon" href="../../../common/images/apple-touch-icon.png">
<script type="text/javascript" src="../../../common/scripts/jquery.js"></script><script type="text/javascript" src="../../../common/scripts/ocw-media-utils-offline.js"></script><script type="text/javascript" src="../../../common/scripts/ocw-offline.js"></script><script type="text/javascript" src="../../../common/scripts/jquery.bubblepopup.min.js"></script><script type="text/javascript" src="../../../common/scripts/jquery-ui.min.js"></script><script type="text/javascript" src="../../../common/scripts/jquery.jscrollpane.min.js"></script><script type="text/javascript" src="../../../common/scripts/bubble-popup-offline.js"></script><script type="text/javascript">
      $(document).ready(function() {
        $("#tabs").tabs();
        IpadScroller();
      });
    </script>
</head>
<body itemscope itemtype="http://schema.org/WebPage">
        
	

        <div id="top">
			<div id="grid">
				
				
					
<div id="portletwrapper-6f63772e746f70706f72746c65746d616e616765720a636f6e746578740a2f506c6f6e650a736974652d686561646572" class="portletWrapper kssattr-portlethash-6f63772e746f70706f72746c65746d616e616765720a636f6e746578740a2f506c6f6e650a736974652d686561646572">
<div class="portletStaticText portlet-static-site-header">
<!--googleoff: index-->
<div class="grid_6 alpha" role="banner" id="banner"><a href="http://ocw.mit.edu/"><img class="logo" alt="MIT OpenCourseWare, Massachusetts Institute of Technology" src="../../../common/images/ocw_mast.png"></a></div>
<div class="grid_6 omega" role="form toolbar" id="subscribe">
<div class="module">
<table class="social"><tbody><tr>
<td class="socialbutton"><a href="http://ocw.mit.edu/subscribe/index.htm?utm_source=header"><img src="../../../common/images/trans.gif" alt="An icon depicting an envelope.">Subscribe to the OCW Newsletter</a></td>
            <td>
<a href="https://plus.google.com/104567381989352550847/posts"><img alt="Click to visit our Google+ page." src="../../../common/images/icon_gp.png"></a><a href="https://www.pinterest.com/mitocw/pins/"><img alt="Click to visit our Pinterest page." src="../../../common/images/icon_pin.png"></a><a href="http://facebook.com/mitocw"><img alt="Click to visit our Facebook page." src="../../../common/images/icon_fb.png"></a><a href="http://twitter.com/mitocw"><img alt="Click to visit our Twitter feed." src="../../../common/images/icon_tw.png"></a>
</td>
        </tr></tbody></table>
</div>
<p class="helplinks"><a href="http://ocw.mit.edu/help">Help</a>   |   <a href="../../../common/jsp/feedback.htm">Contact Us</a></p>
</div>
<div class="clear"> </div>
<!--googleon: index-->
</div>

</div>





<!--googleoff: index-->
<div id="mega" role="navigation" class="grid_8 alpha">        
	<ul id="menu">
<li id="menu_home">
            <a href="http://ocw.mit.edu/"><img src="../../../common/images/top-nav_home.png" class="home_icon" alt="Click for site home page."></a><!-- Begin Home Item -->
        </li>
<!-- End Home Item -->        
        <li class="selected">
            <a href="#" class="drop">Find Courses</a><!-- Begin 5 columns Item -->
            <div class="dropdown_5columns-a mega-courses">                    
                <div class="col_1a">
                    <div class="row_1a">
                        <div class="quart">
                            <h2 class="nav">Find courses by:</h2>
                            <ul class="nav-bullet find_by">
<li><a href="http://ocw.mit.edu/courses/find-by-topic/">Topic</a></li>
                                <li><a href="http://ocw.mit.edu/courses/find-by-number/">MIT Course Number</a></li>
                                <li><a href="http://ocw.mit.edu/courses/find-by-department/">Department</a></li>
                            </ul>
<ul style="margin-top: 88px;" class="nav-bullet find_by">
<li style="font-weight: normal; font-size: 1em;"><a href="http://ocw.mit.edu/courses/">View All Courses</a></li>
							</ul>
</div>
                        <div class="quart">
                            <h2 class="nav">Collections</h2>
                            <ul class="nav-bullet">
<li><a href="http://ocw.mit.edu/courses/audio-video-courses/">Audio/Video Lectures</a></li>
                                <li><a href="http://ocw.mit.edu/courses/online-textbooks/">Online Textbooks</a></li>
                                <li><a href="http://ocw.mit.edu/courses/new-courses/">New Courses</a></li>
                                <li><a href="http://ocw.mit.edu/courses/most-visited-courses/">Most Visited Courses</a></li>
                                <li><a href="http://ocw.mit.edu/courses/ocw-scholar/">OCW Scholar Courses</a></li>
                                <li><a href="http://ocw.mit.edu/courses/this-course-at-mit/">This Course at MIT</a></li>
                                <li><a href="http://ocw.mit.edu/resources/">Supplemental Resources</a></li>
                            </ul>
</div>
                        <div class="clear"> </div>
                    </div>
                    <div class="row_1b">
                        <h2 class="nav">Cross-Disciplinary Topic Lists</h2>
                        <div class="quart">
                        <ul class="nav-bullet">
<li><a href="http://ocw.mit.edu/courses/energy-courses">Energy</a></li>
                            <li><a href="http://ocw.mit.edu/courses/entrepreneurship">Entrepreneurship</a></li>
                            <li><a href="http://ocw.mit.edu/courses/environment-courses">Environment</a></li>
                        </ul>
</div>    
                        <div class="quart">
                        <ul class="nav-bullet">
<li><a href="http://ocw.mit.edu/courses/intro-programming">Introductory Programming</a></li>
                            <li><a href="http://ocw.mit.edu/courses/life-sciences">Life Sciences</a></li>
                            <li><a href="http://ocw.mit.edu/courses/transportation-courses">Transportation</a></li>
                        </ul>
</div>
                        <div class="clear"> </div>
                    </div>
                    <div class="clear"> </div>
                </div>
                <div class="col_1b">
                    <h2 class="nav">Translated Courses</h2>
                    <ul class="nav-bullet">
<li><a href="http://ocw.mit.edu/courses/translated-courses/traditional-chinese">繁體字 / Traditional Chinese</a></li>
                        <li><a href="http://ocw.mit.edu/courses/translated-courses/spanish">Español / Spanish</a></li>
                        <li><a href="http://ocw.mit.edu/courses/translated-courses/portuguese">Português / Portuguese</a></li>
                        <li><a href="http://ocw.mit.edu/courses/translated-courses/persian">فارسی / Persian</a></li>
                        <li><a href="http://ocw.mit.edu/courses/translated-courses/turkish">Türkçe / Turkish</a></li>
                        <li><a href="http://ocw.mit.edu/courses/translated-courses/korean">(비디오)한국 / Korean</a></li>
                        <li><a href="http://ocw.mit.edu/courses/translated-courses">More...</a></li>
                    </ul>
</div>
            </div>
        </li>
        <li>
            <a href="" class="drop">About</a>
            <div class="dropdown_1column-a">
                <div class="col_1">
                    <ul class="nav-bullet mega-div-bottom">
<li><a href="http://ocw.mit.edu/about/">About MIT OpenCourseWare</a></li>
                    </ul>
<ul class="nav-bullet mega-div-bottom">
<li><a href="http://ocw.mit.edu/about/site-statistics/">Site Stats</a></li>
                        <li><a href="http://ocw.mit.edu/about/ocw-stories/">OCW Stories</a></li>                        
                    </ul>
<ul class="nav-bullet">
<li><a href="http://ocw.mit.edu/about/media-coverage/">Media Coverage</a></li>
                        <li><a href="http://ocw.mit.edu/about/newsletter/">Newsletter</a></li>                        
                    </ul>
</div>
            </div>  
        </li>    
        <li>
            <a href="" class="drop">Donate</a>        
            <div class="dropdown_1column-a">
                    <div class="col_1">
                        <ul class="nav-bullet mega-div-bottom">
<li><a href="http://ocw.mit.edu/donate/">Make a Donation</a></li>
                            <li><a href="http://ocw.mit.edu/donate/why-donate/">Why Donate?</a></li>
                            <li><a href="http://ocw.mit.edu/donate/our-supporters/">Our Supporters</a></li>
                            <li><a href="http://ocw.mit.edu/donate/other-ways-to-contribute/">Other Ways to Contribute</a></li>
                            <li><a href="http://ocw.mit.edu/donate/shop-ocw">Shop OCW</a></li>
                        </ul>
<ul class="nav-bullet">
<li><a href="http://ocw.mit.edu/support/">Become a Corporate Sponsor</a></li>
                        </ul>
</div>
            </div>            
        </li>        
        <li>
            <a href="" class="drop">Featured Sites</a>        
            <div class="dropdown_1column-a">
                <div class="col_1">
                    <ul class="nav-bullet mega-div-bottom">
<li><a href="http://ocw.mit.edu/high-school/">Highlights for High School</a></li>
                        <li><a href="http://ocw.mit.edu/educator/">OCW Educator</a></li>
                        <li><a href="http://ocw.mit.edu/courses/crosslinks/">MIT Crosslinks and OCW</a></li>                        
                    </ul>
<ul class="nav-bullet mega-div-top">
<li><a href="http://ocw.mit.edu/ans7870/featured/mitx-courses-on-edx.htm">MITx Courses on edX</a></li>
                        <li><a href="http://teachingexcellence.mit.edu/">Teaching Excellence at MIT</a></li>
						<li><a href="http://www.oeconsortium.org/">Open Education Consortium</a></li>
                    </ul>
</div>
            </div>            
        </li>
    </ul>
</div>
<div id="search" role="search" class="grid_4 omega">
    
    <form method="get" action="../../../common/search/AdvancedSearch.htm">
     	 <table class="search"><tbody><tr>
<td class="black"><input type="text" onblur="fillSearchBox()" onfocus="clearSearchBox()" maxlength="255" value="Search" name="q" class="greytext searchField" id="terms"></td> 			 
                    <td class="black"><input type="image" src="../../../common/images/button_search.png" name="btnG" class="sub_button"></td>			 
                    <td class="text2"><a href="../../../common/search/AdvancedSearch.htm">Advanced<br>Search</a></td>
                </tr></tbody></table>
</form>
</div>
<div class="clear"></div>
<!--googleon: index-->
<!-- *end header* -->  

				
				
			</div>
<!-- top grid end -->
		</div>
<!-- top end -->
			
		<div id="center_media">
      	<div id="grid">
      		<div id="left">
        		<div id="breadcrumb_media">
                	<p>

    <a href="http://ocw.mit.edu/">Home</a>
    
        »
        
    
    
        
            <a href="http://ocw.mit.edu/courses">Courses</a>
            
                »
                
            
            
         
    
    
        
            <a href="http://ocw.mit.edu/courses/electrical-engineering-and-computer-science">Electrical Engineering and Computer Science</a>
            
                »
                
            
            
         
    
    
        
            <a href="../../../contents/index.htm">Introduction to Algorithms (SMA 5503)</a>
            
                »
                
            
            
         
    
    
        
            <a href="../../../contents/video-lectures/index.htm">Video Lectures</a>
            
                »
                
            
            
         
    
    
        
            
            
            Lecture 23: Advanced Topics (cont.)
         
    
</p>

            	</div>
            	<div class="clear"></div>
        		<div id="media_title">
        		<h1 class="title" itemprop="name" property="dct:title">
        <span class="" id="parent-fieldname-title">
            Lecture 23: Advanced Topics (cont.)
        </span>
    </h1>
        		</div>
           		<div class="clear"></div>
           		<div id="course_wrapper_media">
           			<div id="course_nav">
           				<script language="javascript" type="text/javascript">
function toggleMenu(objID) {
  if (!document.getElementById) return;
  var ob = document.getElementById(objID);
  ob.className = (ob.className == 'selected')?'': 'selected';
}
function toggleClass(id)
{
  var divtoggleClass= document.getElementById(id);
  divtoggleClass.className = (divtoggleClass.className == 'mO')?'mC': 'mO';
  return false;
}
function changeAlt(id)
{
  id.alt = (id.alt == 'Expand Menu')?'Collapse Menu' : 'Expand Menu';
  id.title = (id.title == 'Expand Menu')?'Collapse Menu' : 'Expand Menu';
}
</script><!--Left Nav Starts --><ul>
<li class="">
			   			<a href="../../../contents/index.htm">
		                  Course Home  			                
	                    </a>
		        </li>
		    
         	
	
	
	    	
	    	    <li class="">
			   			<a href="../../../contents/syllabus/index.htm">
		                  Syllabus  			                
	                    </a>
		        </li>
		    
         	
	
	
	    	
	    	    <li class="">
			   			<a href="../../../contents/calendar/index.htm">
		                  Calendar  			                
	                    </a>
		        </li>
		    
         	
	
	
	    	
	    	    <li class="">
			   			<a href="../../../contents/readings/index.htm">
		                  Readings  			                
	                    </a>
		        </li>
		    
         	
	
	
	    	
	    	    <li class="">
			   			<a href="../../../contents/assignments/index.htm">
		                  Assignments  			                
	                    </a>
		        </li>
		    
         	
	
	
	    	
	    	    <li class="">
			   			<a href="../../../contents/exams/index.htm">
		                  Exams  			                
	                    </a>
		        </li>
		    
         	
	
	
	    	
	    	    <li class="selected">
			   			<a href="../../../contents/video-lectures/index.htm">
		                  Video Lectures  			                
	                    </a>
		        </li>
		    
         	
	
	
	    	
	    	    
		    
         	
	<!--second tal block close-->  
	
</ul>
<!--Left Nav Ends -->
</div>
           			<div id="course_inner_media">
      					 
        <div class="" id="parent-fieldname-text">
            
            
        </div>
    
      					 

<script type="text/javascript">var caption_embed_1 ={'English - US': '/courses/electrical-engineering-and-computer-science/6-046j-introduction-to-algorithms-sma-5503-fall-2005/video-lectures/lecture-23-advanced-topics-cont./F0VsQWWVWU4.srt'}</script><div id="media-embed">
         <div class="attention_message" id="embed_1">
<p>Flash and JavaScript are required for this feature.</p>
<p>Download the video from <a href="https://itunes.apple.com/us/itunes-u/id341597754">iTunes U</a> or the <a href="http://www.archive.org/download/MIT6.046JF05MPEG4/ocw-6.046-07dec2005-220k.mp4">Internet Archive</a>.</p>
</div>
     </div>
    
     <script type="text/javascript">ocw_embed_chapter_media('embed_1', 'http://www.youtube.com/v/F0VsQWWVWU4', 'youtube', '/courses/electrical-engineering-and-computer-science/6-046j-introduction-to-algorithms-sma-5503-fall-2005/video-lectures/lecture-23-advanced-topics-cont.', 'http://img.youtube.com/vi/F0VsQWWVWU4/0.jpg',0,0, 'http://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-046j-introduction-to-algorithms-sma-5503-fall-2005/video-lectures/lecture-23-advanced-topics-cont./F0VsQWWVWU4.srt')</script><div id="transcript1"></div>
				 <script type="text/javascript">setThreePlayTranscriptPlugin(2, 1004250)</script><script type="text/javascript" src="http://p3.3playmedia.com/p3.js"></script><div id="media_resource_next_prev_nav" style="margin-top: 1em;">
        <p>
        
            <a href="../../../contents/video-lectures/lecture-22-advanced-topics/index.htm">
                <img src="../../../common/images/btn_previous_resource.png" style="margin: 0 30px 0 50px;" alt="Previous track" title="Previous track"></a>
     	
     	
        
            <a href="../../../contents/video-lectures/lecture-24-advanced-topics-cont./index.htm"> 
                <img src="../../../common/images/btn_next_resource.png" alt="Next track" title="Next track"></a>
       
       </p>
     </div>
 


<script type="text/javascript">
		window.onload=function(){
		init();
		
		}
		var tabLinks = new Array();
		var contentDivs = new Array();
		function init() {
		  // Grab the tab links and content divs from the page
		  var tabListItems = document.getElementById('tabs').childNodes;
		  for ( var i = 0; i < tabListItems.length; i++ ) {
			if ( tabListItems[i].nodeName == "LI" ) {
			  var tabLink = getFirstChildWithTagName( tabListItems[i], 'A' );
			  var id = getHash( tabLink.getAttribute('href') );
			  tabLinks[id] = tabLink;
			  contentDivs[id] = document.getElementById( id );
			}
		  }
		  // Assign onclick events to the tab links, and
		  // highlight the first tab
		  var i = 0;
		  for ( var id in tabLinks ) {
			tabLinks[id].onclick = showTab;
			tabLinks[id].onfocus = function() { this.blur() };
			if ( i == 0 ) tabLinks[id].className = 'selected';
			i++;
		  }
		  // Hide all content divs except the first
		  var i = 0;
		  for ( var id in contentDivs ) {
			if ( i != 0 ) contentDivs[id].className = 'tabContent hide';
			i++;
		  }
		}
		function showTab() {
		  var selectedId = getHash( this.getAttribute('href') );
		  // Highlight the selected tab, and dim all others.
		  // Also show the selected content div, and hide all others.
		  for ( var id in contentDivs ) {
			if ( id == selectedId ) {
			  tabLinks[id].className = 'selected';
			  contentDivs[id].className = 'tabContent';
			} else {
			  tabLinks[id].className = '';
			  contentDivs[id].className = 'tabContent hide';
			}
		  }
		  // Stop the browser following the link
		  return false;
		}
		function getFirstChildWithTagName( element, tagName ) {
		  for ( var i = 0; i < element.childNodes.length; i++ ) {
			if ( element.childNodes[i].nodeName == tagName ) return element.childNodes[i];
		  }
		}
		function getHash( url ) {
		  var hashPos = url.lastIndexOf ( '#' );
		  return url.substring( hashPos + 1 );
		}
 </script><div id="media_tabs">
     
        <ul id="tabs">
<li class="first">
                <a href="#vid_about" class="selected">About this Video</a>
            </li>
            <li class="">
                <a href="#vid_index" class="">Playlist</a>
            </li>
            <li class="">
                <a href="#vid_playlist" class="">Related Resources</a>
            </li>
            <li class="">
                <a href="#vid_related" class="">Transcript</a>
            </li>
            <li class="">
                <a href="#vid_transcript" class="">Download this Video</a>
            </li>
        </ul>
<div id="vid_about" itemprop="description" class="tabContent">
<p><strong>Topics covered:</strong> Advanced Topics (cont.)</p>  <p><strong>Instructors:</strong> Prof. Erik Demaine, Prof. Charles Leiserson</p>
</div>
        <div id="vid_index" itemprop="description" class="tabContent hide">
<div class="related-media-thumbnail">
<a href="../../../contents/video-lectures/lecture-1-administrivia-introduction-analysis-of-algorithms-insertion-sort-mergesort/index.htm">
<img src="../../../contents/video-lectures/lecture-1-administrivia-introduction-analysis-of-algorithms-insertion-sort-mergesort/6_046J_lec01_th.jpg" title="Lecture 1: Administrivia; Introduction; Analysis of Algorithms, Insertion Sort, Mergesort" alt="Lecture 1: Administrivia; Introduction; Analysis of Algorithms, Insertion Sort, Mergesort"><p>Lecture 1: Administrivia; I...</p></a>
</div>
<div class="related-media-thumbnail">
<a href="../../../contents/video-lectures/lecture-2-asymptotic-notation-recurrences-substitution-master-method/index.htm">
<img src="../../../contents/video-lectures/lecture-2-asymptotic-notation-recurrences-substitution-master-method/6_046J_lec02_th.jpg" title="Lecture 2: Asymptotic Notation; Recurrences; Substitution, Master Method" alt="Lecture 2: Asymptotic Notation; Recurrences; Substitution, Master Method"><p>Lecture 2: Asymptotic Notat...</p></a>
</div>
<div class="related-media-thumbnail">
<a href="../../../contents/video-lectures/lecture-3-divide-and-conquer-strassen-fibonacci-polynomial-multiplication/index.htm">
<img src="../../../contents/video-lectures/lecture-3-divide-and-conquer-strassen-fibonacci-polynomial-multiplication/6_046J_lec03_th.jpg" title="Lecture 3: Divide-and-Conquer: Strassen, Fibonacci, Polynomial Multiplication" alt="Lecture 3: Divide-and-Conquer: Strassen, Fibonacci, Polynomial Multiplication"><p>Lecture 3: Divide-and-Conqu...</p></a>
</div>
<div class="related-media-thumbnail">
<a href="../../../contents/video-lectures/lecture-4-quicksort-randomized-algorithms/index.htm">
<img src="../../../contents/video-lectures/lecture-4-quicksort-randomized-algorithms/6_046J_lec04_th.jpg" title="Lecture 4: Quicksort, Randomized Algorithms" alt="Lecture 4: Quicksort, Randomized Algorithms"><p>Lecture 4: Quicksort, Rando...</p></a>
</div>
<div class="related-media-thumbnail">
<a href="../../../contents/video-lectures/lecture-5-linear-time-sorting-lower-bounds-counting-sort-radix-sort/index.htm">
<img src="../../../contents/video-lectures/lecture-5-linear-time-sorting-lower-bounds-counting-sort-radix-sort/6_046J_lec05_th.jpg" title="Lecture 5: Linear-time Sorting: Lower Bounds, Counting Sort, Radix Sort" alt="Lecture 5: Linear-time Sorting: Lower Bounds, Counting Sort, Radix Sort"><p>Lecture 5: Linear-time Sort...</p></a>
</div>
<div class="related-media-thumbnail">
<a href="../../../contents/video-lectures/lecture-6-order-statistics-median/index.htm">
<img src="../../../contents/video-lectures/lecture-6-order-statistics-median/6_046J_lec06_th.jpg" title="Lecture 6: Order Statistics, Median" alt="Lecture 6: Order Statistics, Median"><p>Lecture 6: Order Statistics...</p></a>
</div>
<div class="related-media-thumbnail">
<a href="../../../contents/video-lectures/lecture-7-hashing-hash-functions/index.htm">
<img src="../../../contents/video-lectures/lecture-7-hashing-hash-functions/6_046J_lec07_th.jpg" title="Lecture 7: Hashing, Hash Functions" alt="Lecture 7: Hashing, Hash Functions"><p>Lecture 7: Hashing, Hash Fu...</p></a>
</div>
<div class="related-media-thumbnail">
<a href="../../../contents/video-lectures/lecture-8-universal-hashing-perfect-hashing/index.htm">
<img src="../../../contents/video-lectures/lecture-8-universal-hashing-perfect-hashing/6_046J_lec08_th.jpg" title="Lecture 8: Universal Hashing, Perfect Hashing" alt="Lecture 8: Universal Hashing, Perfect Hashing"><p>Lecture 8: Universal Hashin...</p></a>
</div>
<div class="related-media-thumbnail">
<a href="../../../contents/video-lectures/lecture-9-relation-of-bsts-to-quicksort-analysis-of-random-bst/index.htm">
<img src="../../../contents/video-lectures/lecture-9-relation-of-bsts-to-quicksort-analysis-of-random-bst/6_046J_lec09_th.jpg" title="Lecture 9: Relation of BSTs to Quicksort - Analysis of Random BST" alt="Lecture 9: Relation of BSTs to Quicksort - Analysis of Random BST"><p>Lecture 9: Relation of BSTs...</p></a>
</div>
<div class="related-media-thumbnail">
<a href="../../../contents/video-lectures/lecture-10-red-black-trees-rotations-insertions-deletions/index.htm">
<img src="../../../contents/video-lectures/lecture-10-red-black-trees-rotations-insertions-deletions/6_046J_lec10_th.jpg" title="Lecture 10: Red-black Trees, Rotations, Insertions, Deletions" alt="Lecture 10: Red-black Trees, Rotations, Insertions, Deletions"><p>Lecture 10: Red-black Trees...</p></a>
</div>
<div class="related-media-thumbnail">
<a href="../../../contents/video-lectures/lecture-11-augmenting-data-structures-dynamic-order-statistics-interval-trees/index.htm">
<img src="../../../contents/video-lectures/lecture-11-augmenting-data-structures-dynamic-order-statistics-interval-trees/6_046J_lec11_th.jpg" title="Lecture 11: Augmenting Data Structures, Dynamic Order Statistics, Interval Trees" alt="Lecture 11: Augmenting Data Structures, Dynamic Order Statistics, Interval Trees"><p>Lecture 11: Augmenting Data...</p></a>
</div>
<div class="related-media-thumbnail">
<a href="../../../contents/video-lectures/lecture-12-skip-lists/index.htm">
<img src="../../../contents/video-lectures/lecture-12-skip-lists/6_046J_lec12_th.jpg" title="Lecture 12: Skip Lists" alt="Lecture 12: Skip Lists"><p>Lecture 12: Skip Lists</p></a>
</div>
<div class="related-media-thumbnail">
<a href="../../../contents/video-lectures/lecture-13-amortized-algorithms-table-doubling-potential-method/index.htm">
<img src="../../../contents/video-lectures/lecture-13-amortized-algorithms-table-doubling-potential-method/6_046J_lec13_th.jpg" title="Lecture 13: Amortized Algorithms, Table Doubling, Potential Method" alt="Lecture 13: Amortized Algorithms, Table Doubling, Potential Method"><p>Lecture 13: Amortized Algor...</p></a>
</div>
<div class="related-media-thumbnail">
<a href="../../../contents/video-lectures/lecture-14-competitive-analysis-self-organizing-lists/index.htm">
<img src="../../../contents/video-lectures/lecture-14-competitive-analysis-self-organizing-lists/6_046J_lec14_th.jpg" title="Lecture 14: Competitive Analysis: Self-organizing Lists" alt="Lecture 14: Competitive Analysis: Self-organizing Lists"><p>Lecture 14: Competitive Ana...</p></a>
</div>
<div class="related-media-thumbnail">
<a href="../../../contents/video-lectures/lecture-15-dynamic-programming-longest-common-subsequence/index.htm">
<img src="../../../contents/video-lectures/lecture-15-dynamic-programming-longest-common-subsequence/6_046J_lec15_th.jpg" title="Lecture 15: Dynamic Programming, Longest Common Subsequence" alt="Lecture 15: Dynamic Programming, Longest Common Subsequence"><p>Lecture 15: Dynamic Program...</p></a>
</div>
<div class="related-media-thumbnail">
<a href="../../../contents/video-lectures/lecture-16-greedy-algorithms-minimum-spanning-trees/index.htm">
<img src="../../../contents/video-lectures/lecture-16-greedy-algorithms-minimum-spanning-trees/6_046J_lec16_th.jpg" title="Lecture 16: Greedy Algorithms, Minimum Spanning Trees" alt="Lecture 16: Greedy Algorithms, Minimum Spanning Trees"><p>Lecture 16: Greedy Algorith...</p></a>
</div>
<div class="related-media-thumbnail">
<a href="../../../contents/video-lectures/lecture-17-shortest-paths-i-properties-dijkstras-algorithm-breadth-first-search/index.htm">
<img src="../../../contents/video-lectures/lecture-17-shortest-paths-i-properties-dijkstras-algorithm-breadth-first-search/6_046J_lec17_th.jpg" title="Lecture 17: Shortest Paths I: Properties, Dijkstra's Algorithm, Breadth-first Search" alt="Lecture 17: Shortest Paths I: Properties, Dijkstra's Algorithm, Breadth-first Search"><p>Lecture 17: Shortest Paths ...</p></a>
</div>
<div class="related-media-thumbnail">
<a href="../../../contents/video-lectures/lecture-18-shortest-paths-ii-bellman-ford-linear-programming-difference-constraints/index.htm">
<img src="../../../contents/video-lectures/lecture-18-shortest-paths-ii-bellman-ford-linear-programming-difference-constraints/6_046J_lec18_th.jpg" title="Lecture 18: Shortest Paths II: Bellman-Ford, Linear Programming, Difference Constraints" alt="Lecture 18: Shortest Paths II: Bellman-Ford, Linear Programming, Difference Constraints"><p>Lecture 18: Shortest Paths ...</p></a>
</div>
<div class="related-media-thumbnail">
<a href="../../../contents/video-lectures/lecture-19-shortest-paths-iii-all-pairs-shortest-paths-matrix-multiplication-floyd-warshall-johnson/index.htm">
<img src="../../../contents/video-lectures/lecture-19-shortest-paths-iii-all-pairs-shortest-paths-matrix-multiplication-floyd-warshall-johnson/6_046J_lec19_th.jpg" title="Lecture 19: Shortest Paths III: All-pairs Shortest Paths, Matrix Multiplication, Floyd-Warshall, Johnson" alt="Lecture 19: Shortest Paths III: All-pairs Shortest Paths, Matrix Multiplication, Floyd-Warshall, Johnson"><p>Lecture 19: Shortest Paths ...</p></a>
</div>
<div class="related-media-thumbnail">
<a href="../../../contents/video-lectures/lecture-22-advanced-topics/index.htm">
<img src="../../../contents/video-lectures/lecture-22-advanced-topics/6_046J_lec22_th.jpg" title="Lecture 22: Advanced Topics" alt="Lecture 22: Advanced Topics"><p>Lecture 22: Advanced Topics</p></a>
</div>
<div class="related-media-thumbnail-nolink">
<div class="now-playing-resource">Now Playing</div>
<img src="../../../contents/video-lectures/lecture-23-advanced-topics-cont./6_046J_lec23_th.jpg" title="Lecture 23: Advanced Topics (cont.)" alt="Lecture 23: Advanced Topics (cont.)"><p>Lecture 23: Advanced Topics...</p>
</div>
<div class="related-media-thumbnail">
<a href="../../../contents/video-lectures/lecture-24-advanced-topics-cont./index.htm">
<img src="../../../contents/video-lectures/lecture-24-advanced-topics-cont./6_046J_lec24_th.jpg" title="Lecture 24: Advanced Topics (cont.)" alt="Lecture 24: Advanced Topics (cont.)"><p>Lecture 24: Advanced Topics...</p></a>
</div>
<div class="related-media-thumbnail">
<a href="../../../contents/video-lectures/lecture-25-advanced-topics-cont.-discussion-of-follow-on-classes/index.htm">
<img src="../../../contents/video-lectures/lecture-25-advanced-topics-cont.-discussion-of-follow-on-classes/6_046J_lec25_th.jpg" title="Lecture 25: Advanced Topics (cont.) - Discussion of Follow-on Classes" alt="Lecture 25: Advanced Topics (cont.) - Discussion of Follow-on Classes"><p>Lecture 25: Advanced Topics...</p></a>
</div>
</div>
        <div id="vid_playlist" itemprop="description" class="tabContent hide">
<h2 class="subhead">Related Resources</h2>
<p><a target="_blank" href="../../../contents/assignments/index.htm">Assignments</a><br><a target="_blank" href="../../../contents/exams/index.htm">Exams</a></p>
</div>
        <div id="vid_related" itemprop="description" class="tabContent hide">
<ul><li><a class="transcript-link" title="Open in a new window." alt="Open in a new window." style="text-decoration: none; font-size: 1.0em;" target="_blank" text-decoration: none font-size: href="../../../contents/video-lectures/lecture-23-advanced-topics-cont./F0VsQWWVWU4.pdf"> Download this transcript - PDF (English - US)</a></li></ul>
<p><span m="7000"> OK, good morning. So today, we're going to</span> <span m="11000">continue our exploration of multithreaded algorithms.</span> <span m="16000">Last time we talked about some aspects of scheduling,</span> <span m="21000">and a little bit about linguistics to describe a</span> <span m="26000">multithreaded competition. And today, we're going to</span> <span m="30000">actually deal with some algorithms.</span> <span m="47000">So, we're going to start out with a really simple,</span> <span m="50000">actually, what's fun about this, actually,</span> <span m="53000">is that everything I'm going to teach you today I could have</span> <span m="57000">taught you in week two, OK, because basically it's just</span> <span m="61000">taking the divide and conquer hammer, and just smashing</span> <span m="65000">problem after problem with it. OK, and so, actually next</span> <span m="70000">week's lectures on caching, also very similar.</span> <span m="73000">So, everybody should bone up on their master theorem and</span> <span m="78000">substitution methods for occurrences, and so forth</span> <span m="82000">because that's our going to be doing.</span> <span m="85000">And of course, all the stuff will be on the</span> <span m="88000">final. So let's start with matrix</span> <span m="91000">multiplication.</span> <span m="100000">And we'll do n by n. So, our problem is to do C</span> <span m="105000">equals A times B. And the way we'll do that is</span> <span m="110000">using divide and conquer, as we saw before,</span> <span m="115000">although we're not going to use Strassen's method.</span> <span m="122000">OK, we'll just use the ordinary thing, and I'll leave Strassen's</span> <span m="128000">as an exercise. So, the idea is we're going to</span> <span m="132000">look at matrix multiplication in terms of an n by n matrix,</span> <span m="138000">in terms of n over 2 by n over 2 matrices.</span> <span m="142000">So, I partition C into four blocks, and likewise with A and</span> <span m="148000">B.</span> <span m="170000">OK, and we multiply those out, and that gives us the</span> <span m="178000">following. Make sure I get all my indices</span> <span m="183000">right.</span> <span m="220000">OK, so it gives us the sum of these two n by n matrices.</span> <span m="225000">OK, so for example, if I multiply the first row by</span> <span m="229000">the first column, I'm putting the first term,</span> <span m="234000">A_1-1 times B_1-1 in this matrix, in the second one,</span> <span m="238000">A_1-2 times B_2-1 gets placed here.</span> <span m="243000">So, when I sum them, and so forth,</span> <span m="246000">for the other entries, and when I sum them,</span> <span m="250000">I'm going to get my result. So, we can write that out as a,</span> <span m="256000">let's see, I'm not sure this is going to all fit on one board,</span> <span m="262000">but we'll see we can do. OK, so we can write that out as</span> <span m="268000">a multithreaded program. So this, we're going to see</span> <span m="275000">that n is an exact power of two for simplicity.</span> <span m="281000">And since we're going to have two matrices that we have to</span> <span m="289000">add, we're going to basically put one of them in our output,</span> <span m="297000">C; that'll be the first one, and we're going to use a</span> <span m="304000">temporary matrix, T, which is also n by n.</span> <span m="311000">OK, and the code looks something like this,</span> <span m="321000">OK, n equals one, and C of one gets A of 1-1</span> <span m="332000">times B of 1-1. Otherwise, what we do then is</span> <span m="341000">we partition the matrices. OK, so we partition them into</span> <span m="349000">the block. So, how long does it take me to</span> <span m="355000">partition at matrix into blocks if I'm clever at my programming?</span> <span m="365000">Yeah? No time, or it actually does</span> <span m="367000">take a little bit of time. Yeah, order one,</span> <span m="370000">basically, OK, because all it is is just index</span> <span m="373000">calculations. You have to change what the</span> <span m="375000">index is. You have to pass in what you're</span> <span m="378000">passing these in addition to A, B, and C for example,</span> <span m="382000">pass and arrange which would have essentially a constant</span> <span m="386000">overhead. But it's basically order one</span> <span m="388000">time.</span> <span m="396000">Basically order one time, OK, to partition the matrices</span> <span m="399000">because all we are doing is index calculations.</span> <span m="403000">And all we have to do is just as we go through,</span> <span m="406000">is just make sure we keep track of the indices,</span> <span m="410000">OK? Any questions about that?</span> <span m="412000">People follow? OK, that's sort of standard</span> <span m="415000">programming. So then, what I do is I spawn</span> <span m="425000">multiplication of, woops, the sub-matrices,</span> <span m="437000">and spawn --</span> <span m="456000">-- and continue, C_2-1, gets A_2-1,</span> <span m="463000">B_1-1, two, and let's see, 2-2, yeah, it's 2-1.</span> <span m="473000">OK, and continuing onto the next page.</span> <span m="482000">Let me just make sure I somehow get the indentation right.</span> <span m="490000">This is my level of indentation, and I'm continuing</span> <span m="498000">right along. And now what I do is put the</span> <span m="505000">results in T, and then --</span> <span m="538000">OK, so I've spawn off all these multiplications.</span> <span m="541000">So that means when I spawn, I get to, after I spawn</span> <span m="546000">something I can go onto the next statement, and execute that even</span> <span m="551000">as this is executing. OK, so that's our notion of</span> <span m="555000">multithreaded programming. I spawn off these eight things.</span> <span m="560000">What do I do next? What's the next step in this</span> <span m="564000">code? Sync.</span> <span m="565000">Yeah. OK, I've got to wait for them</span> <span m="568000">to be done before I can use their results.</span> <span m="573000">OK, so I put a sync in, say wait for all those things I</span> <span m="578000">spawned off to be done, and then what?</span> <span m="588000">Yeah. That you have to add T and C.</span> <span m="591000">So let's do that with a subroutine call.</span> <span m="595000">OK, and then we are done. We do a return at the end.</span> <span m="602000">OK, so let's write the code for add, because add,</span> <span m="608000">we also would like to do in parallel if we can.</span> <span m="614000">And what we are doing here is doing C gets C plus T,</span> <span m="621000">OK? So, we're going to add T into</span> <span m="625000">C. So, we have some code here to</span> <span m="629000">do our base case, and partitioning because we're</span> <span m="635000">going to do it divide and conquer as before.</span> <span m="643000">And this one's actually a lot easier.</span> <span m="649000">We just spawn, add a C_1-1,</span> <span m="654000">T_1-1, n over 2, C_1-2, T_1-2,</span> <span m="660000">n over 2, C_2-1, T_2-1, n over 2,</span> <span m="666000">C_2-2, 2-2-2, n over 2, and then sync,</span> <span m="673000">and return the result. OK, so all we're doing here is</span> <span m="681000">just dividing it into four pieces, spawning them off.</span> <span m="686000">That's it. OK, wait until they're all</span> <span m="690000">done, then we return with the result.</span> <span m="692000">OK, so any questions about how this code works?</span> <span m="696000">So, remember that, here, we're going to have a</span> <span m="699000">scheduler underneath which is scheduling this onto our</span> <span m="703000">processors. And we're going to have to</span> <span m="706000">worry about how well that scheduler is doing.</span> <span m="710000">And, from last time, we learned that there were two</span> <span m="713000">important measures, OK, that can be used</span> <span m="716000">essentially to predict the performance on any number of</span> <span m="721000">processors. And what are those two</span> <span m="723000">measures? Yeah, T_1 and T infinity so</span> <span m="728000">that we had some names. T_1 is the work,</span> <span m="732000">good, and T infinity is critical path length,</span> <span m="736000">good. So, you have to work in the</span> <span m="739000">critical path length. If we know the work in the</span> <span m="743000">critical path length, we can do things like say what</span> <span m="748000">the parallelism is of our program, and from that,</span> <span m="753000">understand how many processors it makes sense to run this</span> <span m="758000">program on. OK, so let's do that analysis.</span> <span m="767000">OK, so let's let M_P of n be the p processor execution time</span> <span m="779000">for our mult code, and A_P of n be the same thing</span> <span m="789000">for our matrix addition code. So, the first thing we're going</span> <span m="799000">to analyze is work. And, what do we hope our answer</span> <span m="803000">to our work is? What we analyze work,</span> <span m="806000">what do we hope it's going to be?</span> <span m="819000">Well, we hope it's going to be small.</span> <span m="821000">I'll grant you that. What could we benchmark it</span> <span m="825000">against? Yeah, if we wrote just</span> <span m="828000">something that didn't used to have any parallelism.</span> <span m="832000">We'd like our parallel code when run on one processor to be</span> <span m="837000">just as fast as our serial code, the normal code that we would</span> <span m="842000">use to write to do this problem. That's generally the way that</span> <span m="848000">we would like these things to operate, OK?</span> <span m="851000">So, what is that for matrix multiplication in the naÔve way?</span> <span m="856000">Yeah, it's n^3. Of course, we use Strassen's</span> <span m="859000">algorithm, or one of the other, faster algorithms beat n^3.</span> <span m="864000">But, for this problem, we are just going to focus on</span> <span m="868000">n^3. I'm going to let you do the</span> <span m="872000">Strassen as an exercise. So, let's analyze the work.</span> <span m="877000">OK, since we have a subroutine for add that we are using in the</span> <span m="883000">multiply code, OK, we start by analyzing the</span> <span m="887000">add. So, we have A_1 of n,</span> <span m="889000">OK, is, well, can somebody give me a</span> <span m="892000">recurrence here? What's the recurrence for</span> <span m="896000">understanding the running time of this code?</span> <span m="910000">OK, this is basically week two. This is lecture one actually.</span> <span m="916000">This is like lecture two or, at worst, lecture three.</span> <span m="922000">Well, A of 1 of n.</span> <span m="934000">Plus order one, right.</span> <span m="935000">OK, that's right. So, we have four problems of</span> <span m="939000">size n over 2 that we are solving.</span> <span m="941000">OK, so to see this, you don't even have to know</span> <span m="945000">that we are doing this in parallel, because the work is</span> <span m="949000">basically what would happen if it executed on a serial machine.</span> <span m="954000">So, we have four problems of size n over 2 plus order one is</span> <span m="959000">the total work. Any questions about how I got</span> <span m="965000">that recurrence? Is that pretty straightforward?</span> <span m="970000">If not, let me know. OK, and so, what's the solution</span> <span m="975000">to this recurrence? Yeah, order n^2.</span> <span m="979000">How do we know that? Yeah, master method,</span> <span m="983000">so n to the log base two of four, right, is n^2.</span> <span m="990000">Compare that with order one. This dramatically dominates.</span> <span m="993000">So this is the answer, the n to the log base two of</span> <span m="997000">four, n^2. OK, everybody remember that?</span> <span m="999000">OK, so I want people to bone up because this is going to be</span> <span m="1003000">recurrences, and divide and conquer and stuff is going to be</span> <span m="1007000">on the final, OK, even though we haven't seen</span> <span m="1010000">it in many moons. OK, so that's good.</span> <span m="1012000">That's the same as the serial. If I had to add 2N by n</span> <span m="1016000">matrices, how long does it take me to do it?</span> <span m="1019000">n^2 time. OK, so the input is size n^2.</span> <span m="1024000">So, you're not going to be the size of the input if you have to</span> <span m="1032000">look at every piece of the input.</span> <span m="1036000">OK, let's now do the work of the matrix multiplication.</span> <span m="1043000">So once again, we want to get a recurrence</span> <span m="1048000">here. So, what's our recurrence here?</span> <span m="1056000">Yeah? Not quite.</span> <span m="1059000">Eight, right, good.</span> <span m="1062000">OK, eight, M1, n over 2, plus,</span> <span m="1068000">yeah, there's theta n^2 for the addition, and then there's extra</span> <span m="1080000">theta one that we can absorb into theta n^2.</span> <span m="1091000">Isn't asymptotics great? OK, it's just great.</span> <span m="1099000">And so, what's the solution to that one?</span> <span m="1107000">Theta n^3, why is that? Man, we are exercising old</span> <span m="1115000">muscles. Aren't we?</span> <span m="1116000">And they're just creaking. I can hear them.</span> <span m="1119000">Why is that? Yeah, master method because</span> <span m="1122000">we're looking at, what are we comparing?</span> <span m="1126000">Yeah, n to the log base two of eight, or n^3 versus n^2,</span> <span m="1130000">this one dominates order n^3. OK, so this is same as serial.</span> <span m="1135000">This was the same as serial. This was the same as serial.</span> <span m="1139000">That's good. OK, we know we have a program</span> <span m="1142000">that on one processor, will execute the same as our</span> <span m="1146000">serial code on which it's based. Namely, we could have done</span> <span m="1152000">this. If I had just got rid of all</span> <span m="1155000">the spawns and syncs, that would have just been a</span> <span m="1159000">perfectly good piece of pseudocode describing the</span> <span m="1162000">runtime of the algorithm, describing the serial</span> <span m="1166000">algorithm. And its run time ends up being</span> <span m="1169000">exactly the same, not too surprising.</span> <span m="1173000">OK? OK, so now we do the new stuff,</span> <span m="1178000">critical path length. OK, so here we have A infinity</span> <span m="1187000">of n. Ooh, OK, so we're going to add</span> <span m="1194000">up the critical path of this code here.</span> <span m="1202000">Hmm, how do I figure out the critical path on a piece of code</span> <span m="1207000">like that?</span> <span m="1226000">So, it's going to expand into one of those DAG's.</span> <span m="1230000">What's the DAG going to look like?</span> <span m="1233000">How do I reason? So, it's actually easier not to</span> <span m="1237000">think about the DAG, but to simply think about</span> <span m="1242000">what's going on in the code. Yeah?</span> <span m="1245000">Yeah, so it's basically, since all four spawns are</span> <span m="1249000">spawning off the same thing, and they're operating in</span> <span m="1254000">parallel, I could just look at one.</span> <span m="1259000">Or in general, if I spawned off several</span> <span m="1261000">things, I look at which everyone is going to have the maximum</span> <span m="1266000">critical path for the things that I've spawned off.</span> <span m="1269000">So, when we do work, we're usually doing plus when I</span> <span m="1273000">have multiple subroutines. When we do critical path,</span> <span m="1277000">I'm doing max. It's going to be the max over</span> <span m="1280000">the critical paths of the subroutines that I call.</span> <span m="1283000">OK, and here they are all equal.</span> <span m="1286000">So what's the recurrence that I get?</span> <span m="1301000">What's the recurrence I'm going to get out of this one?</span> <span m="1307000">Yeah, A infinity, n over 2, plus constant,</span> <span m="1311000">OK, because this is what the worst is of any of those four</span> <span m="1318000">because they're all the same. They're all a problem looking</span> <span m="1325000">at the critical path of something that's half the size,</span> <span m="1331000">for a problem that's half the size.</span> <span m="1335000">OK, people with me? OK, so what's the solution to</span> <span m="1341000">this? Yeah, that's theta log n.</span> <span m="1344000">That's just, once again, master theorem,</span> <span m="1349000">case two, because the solution to this is n to the log base two</span> <span m="1356000">of one, which is n to the zero. So we have, on this side,</span> <span m="1364000">we have one, and here, we're comparing it</span> <span m="1367000">with one. They're the same,</span> <span m="1370000">so therefore we tack on that extra log n.</span> <span m="1373000">OK, so tack on one log n. OK, so case two of the master</span> <span m="1378000">method. Pretty good.</span> <span m="1381000">OK, so that's pretty good, because the critical path is</span> <span m="1386000">pretty short, log n compared to the work,</span> <span m="1391000">n^2. So, let's do,</span> <span m="1392000">then, this one which is a little bit more interesting,</span> <span m="1398000">but not much harder. How about this one?</span> <span m="1402000">What's the recurrence going to be?</span> <span m="1405000">Critical path of the multiplication?</span> <span m="1418000">So once again, it's going to be the maximum of</span> <span m="1422000">everything we spawned off in parallel, which is,</span> <span m="1426000">by symmetry, the same as one of them.</span> <span m="1430000">So what do I get here? M infinity, n over 2,</span> <span m="1434000">plus theta log n. Where'd the theta log n come</span> <span m="1438000">from? Yeah, from the addition.</span> <span m="1442000">That's the critical path of the addition.</span> <span m="1445000">Now, why is it that the maximum of that with all the spawns?</span> <span m="1451000">You said that when you spawn things off, you're going to do</span> <span m="1456000">them, yeah, you sync first. And, sync says you wait for all</span> <span m="1462000">those to be done. So, you're only taking the</span> <span m="1466000">maximum, and across syncs you're adding.</span> <span m="1471000">So, you add across syncs, and across things that you</span> <span m="1474000">spawned off in parallel. That's where you are doing the</span> <span m="1477000">max. OK, but if you have a sync,</span> <span m="1479000">it says that that's the end. You've got to wait for</span> <span m="1481000">everything there to end. This isn't going on in parallel</span> <span m="1485000">with it. This is going on after it.</span> <span m="1487000">So, whatever the critical path is here, OK, if I have an</span> <span m="1490000">infinite number of processors, I'd still have to wait up at</span> <span m="1493000">this point, and that would therefore make it so that the</span> <span m="1497000">remaining execution gear was whatever the critical,</span> <span m="1500000">I would have to add whatever the critical path was to this</span> <span m="1503000">one. Is that clear to everybody?</span> <span m="1508000">OK, so we get this recurrence. And, that has solution what?</span> <span m="1516000">Yeah, theta log squared n. OK, once again,</span> <span m="1521000">by master method, case two, where this ends up</span> <span m="1527000">being a constant versus log n, those don't differ by a</span> <span m="1534000">polynomial amount, or equal to a log factor.</span> <span m="1541000">What we do in that circumstance is tack on an extra log factor.</span> <span m="1548000">OK, so as I say, good idea to review the master</span> <span m="1553000">method. OK, that's great.</span> <span m="1556000">So now, let's take a look at the parallelism that we get.</span> <span m="1564000">We'll just do it right here for the multiplication.</span> <span m="1572000">OK, so parallelism is what for the multiplication?</span> <span m="1581000">What's the formula for parallelism?</span> <span m="1586000">So, we have p bar is the notation we use for this</span> <span m="1595000">problem. What's the parallelism going to</span> <span m="1603000">be? What's the ratio I take?</span> <span m="1607000">Yeah, it's M_1 of n divided by M infinity of n.</span> <span m="1614000">OK, and that's equal to, that's n^3.</span> <span m="1620000">That's n^2, or log n^2, sorry, log squared n.</span> <span m="1629000">OK, so this is the parallelism. That says you could run up to</span> <span m="1632000">this many processors and expect to be getting linear speed up.</span> <span m="1636000">If I ran with more processors than the parallelism,</span> <span m="1640000">I don't expect to be getting linear speed up anymore,</span> <span m="1643000">OK, because what I expect to run in, is just time</span> <span m="1646000">proportional to critical path length, and throwing more</span> <span m="1650000">processors at the problem is not going to help me very much,</span> <span m="1653000">OK? So let's just look at this just</span> <span m="1659000">to get a sense of what's going on here.</span> <span m="1664000">Let's imagine that the constants are irrelevant,</span> <span m="1670000">and we have, say, thousand by thousand</span> <span m="1675000">matrices, OK, so in that case,</span> <span m="1679000">our parallelism is 1,000^3 divided by log of 1,000^2.</span> <span m="1688000">What's log of 1,000? Ten, approximately,</span> <span m="1692000">right? Log base two of 1,000 is about</span> <span m="1696000">ten, so that's 10^2. So, you have about 10^7</span> <span m="1701000">parallelism. How big is 10^7?</span> <span m="1704000">Ten million processors. OK, so who knows of a machine</span> <span m="1710000">with ten million processors? What's the most number of</span> <span m="1718000">processors anybody knows about? Yeah, not quite,</span> <span m="1724000">the IBM Blue Jean has a humungous number of processors,</span> <span m="1732000">exceeding 10,000. Yeah.</span> <span m="1735000">Those were one bit processors. OK, so this is actually a</span> <span m="1743000">pretty big number, and so, our parallelism is much</span> <span m="1749000">bigger than a typical, actual number of processors.</span> <span m="1755000">So, we would expect to be able to run this and get very good</span> <span m="1762000">performance, OK, because we're never going to be</span> <span m="1768000">limited in this algorithm by performance.</span> <span m="1775000">However, there are some tricks we can do.</span> <span m="1778000">One of the things in this code is that we actually have some</span> <span m="1782000">overhead that's not apparent because I haven't run this code</span> <span m="1787000">with you, although I could, which is that we have this</span> <span m="1791000">temporary matrix, T, and if you look at the</span> <span m="1794000">execution stack, we're always allocating T and</span> <span m="1798000">getting rid of it, etc.</span> <span m="1801000">And, one of the things when you actually look at the performance</span> <span m="1804000">of real code, which is now that you have your</span> <span m="1807000">algorithmic background, you're ready to go and do that</span> <span m="1810000">with some insight. Of course, you're interested in</span> <span m="1813000">getting more than just asymptotic behavior.</span> <span m="1816000">You're interested in getting real performance behavior on</span> <span m="1819000">real things. So, you do care about constants</span> <span m="1821000">in that nature. OK, and one of the things is</span> <span m="1824000">having a large, temporary variable.</span> <span m="1826000">That turns out to be a lot of overhead.</span> <span m="1830000">And, in fact, it's often the case when you're</span> <span m="1833000">looking at real code that if you can optimize for space,</span> <span m="1837000">you also optimized for time. If you can run your code with</span> <span m="1842000">smaller space, you can actually run it with</span> <span m="1845000">smaller time, tends to be a constant factor</span> <span m="1849000">advantage. But, those constants can add</span> <span m="1852000">up, and can make a difference in whether somebody else's code is</span> <span m="1857000">faster or your code is faster, once you have your basic</span> <span m="1861000">algorithm. So, the idea is to,</span> <span m="1863000">in this case, we're going to get rid of it by</span> <span m="1867000">trading parallelism because we've got oodles of parallelism</span> <span m="1872000">here for space efficiency. OK, and the idea is we're going</span> <span m="1882000">to get rid of T. OK, so let's throw this up.</span> <span m="1893000">So, who can suggest how I might get rid of T here,</span> <span m="1900000">get rid of this temporary matrix?</span> <span m="1904000">Yeah?</span> <span m="1918000">Yeah?</span> <span m="1934000">So, if you just did adding it into C?</span> <span m="1935000">So, the issue that you get there if they're both adding</span> <span m="1938000">into C is you get interference between the two subcomputations.</span> <span m="1941000">Now, there are ways of doing that that work out,</span> <span m="1944000">but you now have to worry about things we're not going to talk</span> <span m="1947000">about such as mutual exclusion to make sure that as you're</span> <span m="1950000">updating it, somebody else isn't updating it, and you don't have</span> <span m="1953000">race conditions. But you can actually do it in</span> <span m="1958000">this context with no race conditions.</span> <span m="1961000">Yeah, exactly. Exactly, OK,</span> <span m="1964000">exactly. So, the idea is spawn off four</span> <span m="1968000">of them. OK, they all update their copy</span> <span m="1972000">of C, and then spawn off the other four that add their values</span> <span m="1978000">in. So, that is a piece of code</span> <span m="1983000">we'll call mult add. And, it's actually going to do</span> <span m="1988000">C gets C plus A times B. OK, so it's actually going to</span> <span m="1995000">add it in. So, initially you'd have to</span> <span m="1999000">zero out C, but we can do that with code very similar to the</span> <span m="2006000">addition code with order n^2 work, and order log n critical</span> <span m="2013000">path. So that's not going to be a big</span> <span m="2018000">part of what we have to deal with.</span> <span m="2021000">OK, so here's the code. We basically,</span> <span m="2025000">once again, do the base and partition which I'm not going to</span> <span m="2031000">write out the code for. We spawn a mult add of C1-1,</span> <span m="2040000">A1-1, B1-1, n over 2, and we do a few more of those</span> <span m="2049000">down to the fourth one.</span> <span m="2065000">And then we put in a sync. And then we do the other four --</span> <span m="2101000">-- and then sync when we're done with that.</span> <span m="2112000">OK, does everybody understand that code?</span> <span m="2114000">See that it basically does the same calculation.</span> <span m="2118000">We actually don't need to call add anymore, because we are</span> <span m="2122000">doing that as part of the multiply because we're adding it</span> <span m="2126000">in. But we do have to initialize.</span> <span m="2128000">OK, we do have to initialize the matrix in this case.</span> <span m="2133000">OK, so there is another phase. So, people understand the</span> <span m="2142000">semantics of this code. So let's analyze it.</span> <span m="2150000">OK, so what's the work of multiply, add of n?</span> <span m="2158000">It's basically the same thing, right?</span> <span m="2166000">It's order n^3 because the serial code is almost the same</span> <span m="2170000">as the serial code up there, OK, not quite,</span> <span m="2174000">OK, but you get essentially the same recurrence except you don't</span> <span m="2179000">even have the add. You just get the same</span> <span m="2183000">recurrence but with order one here, oops, order one up here.</span> <span m="2188000">So, it's still got the order n^3 solution.</span> <span m="2193000">OK, so that, I think, is not too hard.</span> <span m="2197000">OK, so the critical path length, so there,</span> <span m="2202000">let's write out, so multiply,</span> <span m="2205000">add, of n, OK, what's my recurrence for this</span> <span m="2210000">code?</span> <span m="2222000">Yeah, 2M infinity, M over 2 [ost that,</span> <span m="2226000">so order one. Plus order one,</span> <span m="2229000">yeah. OK, so the point is that we're</span> <span m="2233000">going to have, for the critical path,</span> <span m="2237000">we're going to spawn these four off, and so I take the maximum</span> <span m="2243000">of whatever those is, which since they're symmetric</span> <span m="2249000">is any one of them, OK, and then I have to wait.</span> <span m="2256000">And then I do it again. So, that sync,</span> <span m="2259000">once again, translates into, in the analysis,</span> <span m="2262000">it translates into a plus of the critical path,</span> <span m="2266000">which are the things I spawn off in parallel,</span> <span m="2270000">I do the max. OK, so people see that?</span> <span m="2273000">So, I get this recurrence, 2MA of n over 2 plus order one,</span> <span m="2278000">and what's the solution to that?</span> <span m="2282000">OK, that's order n, OK, because n to the log base</span> <span m="2290000">two of two is n, and that's bigger than one so</span> <span m="2298000">we get order n. OK, so the parallelism,</span> <span m="2305000">we have p bar is equal to MA one of n over MA infinity of n</span> <span m="2316000">is equal to, in this case, n^3 over n, or order n^2.</span> <span m="2327000">OK, so for 1,000 by 1,000 matrices, for example,</span> <span m="2331000">by the way, 1,000 by 1,000 is considered a small matrix,</span> <span m="2336000">these days, because that's only one million entries.</span> <span m="2342000">You can put that on your laptop no sweat.</span> <span m="2347000">OK, so, but for 1,000 by 1,000 matrices, our parallelism is</span> <span m="2354000">about 10^6. OK, so once again,</span> <span m="2358000">ample parallelism for anything we would run it on today.</span> <span m="2367000">And as it turns out, it's faster in practice --</span> <span m="2378000">-- because we have less space. OK, so here's a game where,</span> <span m="2383000">so, often the game you'll see in theory papers if you look at</span> <span m="2389000">research papers, people are often striving to</span> <span m="2393000">get the most parallelism, and that's a good game to play,</span> <span m="2399000">OK, but it's not necessarily the only game.</span> <span m="2404000">Particularly, if you have a lot of</span> <span m="2406000">parallelism, one of the things that's very easy to do is to</span> <span m="2409000">retreat on the parallelism and gain other aspects that you may</span> <span m="2414000">want in your code. OK, and so this is a good</span> <span m="2416000">example of that. In fact, and this is an</span> <span m="2419000">exercise, you can actually achieve work n^3,</span> <span m="2422000">order n^3 work, and a critical path of log n,</span> <span m="2425000">so even better than either of these two algorithms in terms of</span> <span m="2429000">parallelism. OK, so that gives you n^3 over</span> <span m="2433000">log n parallelism. So, that's an exercise.</span> <span m="2436000">And then, the other exercise that I mention that that's good</span> <span m="2440000">to do is parallel Strassen, OK, doing the same thing with</span> <span m="2444000">Strassen, and analyze, what's the working critical</span> <span m="2448000">path and parallelism of the Strassen code?</span> <span m="2451000">OK, any questions about matrix multiplication?</span> <span m="2454000">Yeah?</span> <span m="2463000">Yeah, so that would take, that would add a log n to the</span> <span m="2467000">critical path, which is nothing compared to</span> <span m="2470000">the n. Excuse me?</span> <span m="2472000">Well, you got to make sure C is zero to begin with.</span> <span m="2476000">OK, so you have to set all the entries to zero,</span> <span m="2480000">and so that will take you n^2 work, which is nothing compared</span> <span m="2485000">to the n^3 work you're doing here, and it will cost you log n</span> <span m="2490000">additional to the critical path, which is nothing compared to</span> <span m="2494000">the order n that you're spending.</span> <span m="2499000">Any other questions about matrix multiplication?</span> <span m="2505000">OK, as they say, this all goes back to week two,</span> <span m="2511000">or something, in the class.</span> <span m="2515000">Did you have a comment? Yes, you can.</span> <span m="2521000">OK, yes you can. It's actually kind of</span> <span m="2525000">interesting to look at that. Actually, we'll talk later.</span> <span m="2531000">We'll write a research paper after the class is over,</span> <span m="2537000">OK, because there's actually some interesting open questions</span> <span m="2544000">there. OK, let's move on to something</span> <span m="2548000">that you thought you'd gotten rid of weeks ago,</span> <span m="2554000">and that would be the topic of sorting.</span> <span m="2560000">Back to sorting. OK, so we want to parallel sort</span> <span m="2564000">now, OK? Hugely important problem.</span> <span m="2567000">So, let's take a look at, so if I think about algorithms</span> <span m="2572000">for sorting that sound easy to parallelize, which ones sound</span> <span m="2577000">kind of easy to parallelize? Quick sort, yeah,</span> <span m="2581000">that's a good one. Yeah, quick sort is a pretty</span> <span m="2585000">good one to parallelize and analyze.</span> <span m="2588000">But remember, quick sort has a little bit</span> <span m="2590000">more complicated analysis than some other sorts.</span> <span m="2593000">What's another one that looks like it should be pretty easy to</span> <span m="2597000">parallelize? Merge sort.</span> <span m="2599000">When did we teach merge sort? Day one.</span> <span m="2601000">OK, so do merge sort because it's just a little bit easier to</span> <span m="2605000">analyze. OK, we could do the same thing</span> <span m="2607000">for quick sort. Here's merge sort,</span> <span m="2612000">OK, and it's going to sort A of p to r.</span> <span m="2618000">So, if p is less than r, then we get the middle element,</span> <span m="2627000">and then we'll spawn off since we have to, as you recall,</span> <span m="2635000">when you merge sort you first recursively sort the two</span> <span m="2643000">sub-arrays. There's no reason not to do</span> <span m="2651000">those parallel. Let's just do them in parallel.</span> <span m="2658000">Let's spawn off, merge sort of A,</span> <span m="2663000">p, q, and spawn off, then, merge sort of A,</span> <span m="2670000">q plus one r. And then, we wait for them to</span> <span m="2678000">be done. Don't forget your syncs.</span> <span m="2682000">Sync or swim. OK, and then what to do what we</span> <span m="2688000">are done with this? OK, we merge.</span> <span m="2694000">OK, so we merge of A, p, q, r, which is merge A of p</span> <span m="2703000">up to q with A of q plus one up to r.</span> <span m="2710000">And, once we've merged, we're done.</span> <span m="2716000">OK, so this is the same code as we saw before in day one except</span> <span m="2727000">we've got a couple of spawns in the sync.</span> <span m="2737000">So let's analyze this. So, the work is called T_1 of</span> <span m="2752000">n, what's the recurrence for this?</span> <span m="2763000">This really is going back to day one, right?</span> <span m="2767000">We actually did this on day one.</span> <span m="2771000">OK, so what's the recurrence? 2T1 of n over 2 plus order n</span> <span m="2777000">merges order n time operation, OK?</span> <span m="2781000">And so, that gives us a solution of n log n,</span> <span m="2785000">OK, even if you didn't know the solution, you should know the</span> <span m="2792000">answer, OK, which is the same as the serial code,</span> <span m="2797000">not surprisingly. That's what we want.</span> <span m="2805000">OK, critical path length, AT infinity of n is equal to,</span> <span m="2817000">OK, T infinity of n over 2 plus order n again.</span> <span m="2828000">And that's equal to order n, OK?</span> <span m="2835000">So, the parallelism is then p bar equals T_1 of n over T</span> <span m="2849000">infinity of n is equal to theta of log n.</span> <span m="2860000">Is that a lot of parallelism? No, we have a technical name</span> <span m="2865000">for that. We call it puny.</span> <span m="2867000">OK, that's puny parallelism. Log n?</span> <span m="2870000">Now, so this is actually probably a decent algorithm for</span> <span m="2875000">some of the small scale processors, especially the</span> <span m="2880000">multicore processors that are coming on the market,</span> <span m="2884000">and some of the smaller SMP, symmetric multiprocessors,</span> <span m="2889000">that are available. You know, they have four or</span> <span m="2895000">eight processors or something. It might be OK.</span> <span m="2899000">There's not a lot of parallelism.</span> <span m="2902000">For a million elements, log n is about 20.</span> <span m="2905000">OK, and so and then there's constant overheads,</span> <span m="2909000">etc. This is not very much</span> <span m="2914000">parallelism at all. Question?</span> <span m="2919000">Yeah, so how can we do better? I mean, it's like,</span> <span m="2926000">man, at merge, right, it takes order n.</span> <span m="2933000">if I want to do better, what should I do?</span> <span m="2939000">Yeah? Sort in-place,</span> <span m="2943000">but for example if you do quick sort and partition,</span> <span m="2948000">you still have a linear time partition.</span> <span m="2952000">So you're going to be very much in the same situation.</span> <span m="2957000">But what can I do here? Parallel merge.</span> <span m="2961000">OK, let's make merge go in parallel.</span> <span m="2964000">That's where all the critical path is.</span> <span m="2968000">Let's figure out a way of building a merge program that</span> <span m="2973000">has a very short critical path. You have to parallelize the</span> <span m="2981000">merge. This is great.</span> <span m="2983000">It's so nice to see at the end of a course like this that</span> <span m="2990000">people have the intuition that, oh, you can look at it and sort</span> <span m="2997000">of see, where should you put in your work?</span> <span m="3003000">OK, the one thing about algorithms is it doesn't stop</span> <span m="3005000">you from having to engineer a program when you code it.</span> <span m="3009000">There's a lot more to coding a program well than just having</span> <span m="3012000">the algorithm as we talked about, also, in day one.</span> <span m="3015000">There's things like making it modular, and making it</span> <span m="3018000">maintainable, and a whole bunch of things</span> <span m="3020000">like that. But one of the things that</span> <span m="3022000">algorithms does is it tells you, where should you focus your</span> <span m="3025000">work? OK, there's no point in,</span> <span m="3028000">for example, sort of saying,</span> <span m="3030000">OK, let me spawn off four of these things of size n over 4 in</span> <span m="3034000">hopes of getting, I mean, it's like,</span> <span m="3037000">that's not where you put the work.</span> <span m="3039000">You put the work in merge because that's the one that's</span> <span m="3042000">the bottleneck, OK?</span> <span m="3044000">And, that's the nice thing about algorithms is it very</span> <span m="3047000">quickly lets you hone in on where you should put your</span> <span m="3051000">effort, OK, when you're doing algorithmic design in</span> <span m="3054000">engineering practice. So you must parallelize the</span> <span m="3058000">merge.</span> <span m="3069000">The merge we're taking, so here's the basic idea we're</span> <span m="3072000">going to use. So, in general,</span> <span m="3074000">when we merge, when we do our recursive merge,</span> <span m="3077000">we're going to have two arrays. Let's call them A and B.</span> <span m="3081000">I called them A there. I probably shouldn't have used</span> <span m="3085000">A. I probably should have called</span> <span m="3087000">them something else, but that's what my notes have,</span> <span m="3090000">so we're going to stick to it. But we get a little bit more</span> <span m="3096000">space there and see what's going on.</span> <span m="3099000">We have two arrays. I'll call them A and B,</span> <span m="3103000">OK? And, what we're going to do,</span> <span m="3106000">these are going to be already sorted.</span> <span m="3109000">And our job is going to be to merge them together.</span> <span m="3114000">So, what I'll do is I'll take the middle element of A.</span> <span m="3120000">So this, let's say, goes from one to l,</span> <span m="3125000">and this goes from one to m. OK, I'll take the middle</span> <span m="3131000">element, the element at l over 2, say, and what I'll do is use</span> <span m="3140000">binary search to figure out, where does it go in the array</span> <span m="3147000">B? Where does this element go?</span> <span m="3151000">It goes to some point here where we have j here and j plus</span> <span m="3156000">one here. So, we know,</span> <span m="3158000">since this is sorted, that all these things are less</span> <span m="3163000">than or equal to A of l over 2, and all these things are</span> <span m="3168000">greater than or equal to A of l over 2.</span> <span m="3172000">And similarly, since that element falls here,</span> <span m="3176000">all these are less than or equal to A of l over 2.</span> <span m="3182000">And all these are going to be less greater than or equal to</span> <span m="3189000">two. OK, and so now what I can do is</span> <span m="3193000">once I figured out where this goes, I can recursively merge</span> <span m="3200000">this array with this one, and this one with this one,</span> <span m="3207000">and then if I can just concatenate them altogether,</span> <span m="3213000">I've got my merged array. OK, so let's write that code.</span> <span m="3221000">Everybody get the gist of what's going on there,</span> <span m="3227000">how we're going to parallelize the merge?</span> <span m="3232000">Of course, you can see, it's going to get a little</span> <span m="3238000">messy because j could be anywhere.</span> <span m="3242000">Secures my code, parallel merge of,</span> <span m="3246000">and we're going to put it in C of one to n, so I'm going to</span> <span m="3253000">have n elements. So, this is doing merge A and B</span> <span m="3261000">into C, and n is equal to l plus n.</span> <span m="3267000">OK, so we're going to take two arrays and merge it into the</span> <span m="3276000">third array, OK? So, without loss of generality,</span> <span m="3282000">I'm going to say, let's see, without loss of</span> <span m="3285000">generality, I'm going to say l is bigger than m as I show here</span> <span m="3289000">because if it's not, what do I do?</span> <span m="3292000">Just do it the other way around, right?</span> <span m="3295000">So, I figure out which one was bigger.</span> <span m="3297000">So that only cost me order one to test that,</span> <span m="3301000">or whatever. And then, I basically do a base</span> <span m="3304000">case, you know, if the two arrays are empty or</span> <span m="3307000">whatever, what you do in practice, of course,</span> <span m="3310000">is if they're small enough, you just do a serial merge,</span> <span m="3314000">OK, if they're small enough, and I don't really expect to</span> <span m="3317000">get much parallelism. There isn't much work there.</span> <span m="3320000">You might as well just do serial merge,</span> <span m="3323000">and be a little bit more efficient, OK?</span> <span m="3325000">So, do the base case. So then, what I do is I find</span> <span m="3332000">the j such that B of j is less than or equal to A of l over 2,</span> <span m="3341000">less than or equal to B of j plus one, using binary search.</span> <span m="3350000">What did recover binary search? Oh yeah, that was week one,</span> <span m="3359000">right? That was first recitation or</span> <span m="3367000">something. Yeah, it's amazing.</span> <span m="3373000">OK, and now, what we do is we spawn off p</span> <span m="3380000">merge of A of one, l over 2, B of one to j,</span> <span m="3389000">and stick it into C of one, two, l over 2 plus j.</span> <span m="3400000">OK, and similarly now, we can spawn off a merge of A</span> <span m="3413000">of l over 2 plus one up to l. B of j plus one up to M,</span> <span m="3427000">and a C of l over two plus j plus one up to n.</span> <span m="3439000">And then, I sync.</span> <span m="3452000">So, code is pretty straightforward,</span> <span m="3455000">doing exactly what I said we were going to do over here,</span> <span m="3462000">analysis, a little messier, a little messier.</span> <span m="3467000">So, let's just try to understand us before we do the</span> <span m="3473000">analysis. Why is it that I want to pick</span> <span m="3477000">the middle of the big array rather than the small array?</span> <span m="3485000">What sort of my rationale there?</span> <span m="3493000">That's actually a key part, going to be a key part of the</span> <span m="3507000">analysis. Yeah?</span> <span m="3511000">OK. Yeah, imagine that B,</span> <span m="3516000">for example, had only one element in it,</span> <span m="3520000">OK, or just a few elements, then finding it in A might mean</span> <span m="3526000">finding it right near the beginning of A.</span> <span m="3530000">And now, I'd be left with subproblems that were very big,</span> <span m="3536000">whereas here, as you're pointing out,</span> <span m="3540000">if I start here, if my total number of elements</span> <span m="3544000">is n, what's the smallest that one of these recursions could</span> <span m="3551000">be? n over 4 is the smallest it</span> <span m="3555000">could be, OK, because I would have at least a</span> <span m="3558000">quarter of the total number of elements to the left here or to</span> <span m="3563000">the right here. If I do it the other way</span> <span m="3566000">around, my recursion, I might get a recursion that</span> <span m="3570000">was nearly as big as n, and that's sort of,</span> <span m="3573000">once again, sort of like the difference when we were</span> <span m="3577000">analyzing quick sort with whether we got a good</span> <span m="3581000">partitioning element or not. The partitioning element is</span> <span m="3586000">somewhere in the middle, we're really good,</span> <span m="3589000">but it's always at one end, it's no better than insertion</span> <span m="3592000">sort. You want to cut off at least a</span> <span m="3594000">constant fraction in your divided and conquered in order</span> <span m="3597000">to get the logarithmic behavior. OK, so we'll see that in the</span> <span m="3602326">analysis. But the key thing here is that</span> <span m="3605566">what we are going to do the recursion, we're going to have</span> <span m="3610302">at least n over 4 elements in whatever the smaller thing is.</span> <span m="3615204">OK, but let's start. It turns out the work is the</span> <span m="3619192">hard part of this. Let's start with critical path</span> <span m="3623181">length. OK, look at that,</span> <span m="3625175">critical path length. OK, so parallel merge,</span> <span m="3632045">so infinity of n is going to be, at most, so if the smaller</span> <span m="3642712">piece has at least a quarter, what's the larger piece going</span> <span m="3653379">to be of these two things here? So, we have two problems</span> <span m="3663588">responding off. Now, we really have to do max</span> <span m="3670166">because they're not symmetric. Which one's going to be worse?</span> <span m="3679136">One could have, at most, three quarters,</span> <span m="3684966">OK, of n. Woops, 3n, of 3n over 4 plus,</span> <span m="3690647">OK, so the worst of those two is going to be three quarters of</span> <span m="3699767">the elements plus, what?</span> <span m="3705000">Plus log n. What's the log n?</span> <span m="3712000">The binary search. OK, and that gives me a</span> <span m="3722250">solution of, this ends up being n to the, what?</span> <span m="3735000">n to the zero, right.</span> <span m="3736845">OK, it's n to the log base four thirds of one.</span> <span m="3740996">OK, it was the log of anything of one is zero.</span> <span m="3745147">So, it's n to the zero. So that's just one compared</span> <span m="3749760">with log n, tack on this log squared n.</span> <span m="3753265">So, we have a critical path of log squared n.</span> <span m="3757324">That's good news. Now, let's hope that we didn't</span> <span m="3764090">blow up the work by a substantial amount.</span> <span m="3769545">OK, so the work is PM_1 of n is equal to, OK,</span> <span m="3775545">so we don't know what the split is.</span> <span m="3781000">So let's call it alpha. OK, so alpha n in one side,</span> <span m="3787529">and then the work on the other side will be PM of one of one</span> <span m="3795235">minus alpha n plus, and then still order of log n</span> <span m="3801503">to the binary search where, as we've said,</span> <span m="3806858">alpha is going to fall between one quarter and three quarters.</span> <span m="3826000">OK, how do we solve a recurrence like this?</span> <span m="3831090">What's the technical name for this kind of recurrence?</span> <span m="3837515">Hairy. It's a hairy recurrence.</span> <span m="3841151">How do we solve hairy recurrences?</span> <span m="3846000">Substitution. OK, good.</span> <span m="3849318">Substitution. OK, so we're going to say PM</span> <span m="3855502">one of k is less than or equal to, OK, I want to make a good</span> <span m="3864402">guess here, OK, because I've fooled around with</span> <span m="3871340">it. I want it to be linear,</span> <span m="3874493">so it's going to have a linear term, a times k minus,</span> <span m="3877870">and then I'm going to do b log k.</span> <span m="3879948">So, this is this trick of subtracting a low order term.</span> <span m="3883454">Remember that in substitution in order to make it stronger?</span> <span m="3887220">If I just did ak it's not going to work because here I would get</span> <span m="3891311">n, and then when I did this substitution I'm going to get a</span> <span m="3895077">alpha n, and then a one minus alpha n, and those two together</span> <span m="3898974">are already going to add up to everything here.</span> <span m="3903000">So, there's no way I'm going to get it down when I add this term</span> <span m="3908411">in. So, I need to subtract</span> <span m="3910558">something from both of these so as to absorb this term,</span> <span m="3915196">OK? So, I'm skipping over those</span> <span m="3917773">steps, OK, because we did those steps in lecture two or</span> <span m="3922411">something. OK, so that's the thing I'm</span> <span m="3925588">going to guess where a and b are greater than zero.</span> <span m="3931000">OK, so let's do the substitution.</span> <span m="3946000">OK, so we have PM one of n is less than or equal to,</span> <span m="3952000">OK, we substitute this inductive hypothesis in for</span> <span m="3957764">these two guys. So, we get a alpha n minus b</span> <span m="3962234">log of alpha n plus a of one minus alpha n minus b log of one</span> <span m="3967023">minus alpha, maybe another parentheses there,</span> <span m="3970535">one minus alpha n, and even leave myself enough</span> <span m="3974206">space here plus a of one minus alpha n minus b log of one minus</span> <span m="3979154">alpha, maybe another parenthesis there, one minus alpha n.</span> <span m="3983704">I didn't even leave myself enough space here.</span> <span m="3987215">Plus, let me just move this over so I don't end up using too</span> <span m="3991924">much space. So, b log of one minus alpha n</span> <span m="3999704">plus theta of log n. How's that?</span> <span m="4005598">Are we OK on that? OK, so that's just</span> <span m="4012443">substitution. Let's do a little algebra.</span> <span m="4021000">That's equal to a of times alpha na times one minus alpha</span> <span m="4027977">n. That's just an,</span> <span m="4030095">OK, minus, well, the b isn't quite so simple.</span> <span m="4035578">OK, so I have a b term. Now I've got a whole bunch of</span> <span m="4042057">stuff there. I've got log of alpha n.</span> <span m="4046543">I have, then, this log of one minus alpha n,</span> <span m="4051900">OK, I'll start with the n, and then plus theta log n.</span> <span m="4060000">Did I do that right? Does that look OK?</span> <span m="4065947">OK, so look at that. OK, so now let's just multiply</span> <span m="4073773">some of this stuff out. So, I have an minus b times,</span> <span m="4081943">well, log of alpha n is just log alpha plus log n.</span> <span m="4088845">And then I have plus log of one minus alpha plus log n,</span> <span m="4096450">OK, plus theta log n. That's just more algebra,</span> <span m="4102929">OK, using our rules for logs. Now let me express this as my</span> <span m="4112035">solution minus my desired solution minus a residual,</span> <span m="4119131">an minus b log n, OK, minus, OK,</span> <span m="4123446">and so that was one of these b log n's, right,</span> <span m="4129707">is here. And the other one's going to</span> <span m="4134718">end up in here. I have B times log n plus log</span> <span m="4140841">of alpha times one minus alpha minus, oops, I've got too many.</span> <span m="4151000">Do I have the right number of closes.</span> <span m="4157716">Close that, close that, that's good,</span> <span m="4164246">minus theta log n. Two there.</span> <span m="4169470">Boy, my writing is degrading. OK, did I do that right?</span> <span m="4178895">Do I have the parentheses right?</span> <span m="4182636">That matches, that matches,</span> <span m="4185774">that matches, good.</span> <span m="4187948">And then B goes to that, OK, good.</span> <span m="4191931">OK, and I claim that is less than or equal to AN minus B log</span> <span m="4199051">n if we choose B large enough. OK, this mess dominates this</span> <span m="4209860">because this is basically a log n here, and this is essentially</span> <span m="4222837">a constant. OK, so if I increase B,</span> <span m="4229952">OK, times log n, I can overcome that log n,</span> <span m="4240000">whatever the constant is, hidden by the asymptotic</span> <span m="4247587">notation, OK, such that B times log n plus</span> <span m="4253934">log of alpha times one minus alpha dominates the theta log n.</span> <span m="4264000">OK, and I can also choose my base condition to be big enough</span> <span m="4273961">to handle the initial conditions, whatever they might</span> <span m="4282740">be. OK, so we'll choose A big</span> <span m="4287467">enough --</span> <span m="4308000">-- to satisfy the base of the induction.</span> <span m="4315172">OK, so thus PM_1 of n is equal to theta n, OK?</span> <span m="4324000">So I actually showed O, and it turns out,</span> <span m="4327384">the lower bound that it is omega n is more straightforward</span> <span m="4332207">because the recurrence is easier because I can do the same</span> <span m="4337030">substitution. I just don't have to subtract</span> <span m="4340584">off low order terms. OK, so it's actually theta,</span> <span m="4344561">not just O. OK, so that gives us a log,</span> <span m="4347776">what did we say the critical path was?</span> <span m="4350907">The critical path is log squared n for the parallel</span> <span m="4355138">merge. So, let's do the analysis of</span> <span m="4360787">merge sort using this. So, the work is,</span> <span m="4365927">as we know already, T_1 of n is theta of n log n</span> <span m="4372285">because our work that we just analyzed was order n,</span> <span m="4379048">same as for the serial algorithm, OK?</span> <span m="4385000">The critical path length, now, is T infinity of n is</span> <span m="4390481">equal to, OK, so in normal merge sort,</span> <span m="4394457">we have a problem of half the size, T of n over 2 plus,</span> <span m="4400261">now, my critical path for merging is not order n as it was</span> <span m="4406387">before. Instead, it's just over there.</span> <span m="4417428">Log squared n, there we go.</span> <span m="4425600">OK, and so that gives us theta of log cubed n.</span> <span m="4441000">So, our parallelism is then theta of n over log cubed n.</span> <span m="4450312">And, in fact, the best that's been done is,</span> <span m="4457423">sorry, log squared n, you're right.</span> <span m="4463179">Log squared n because it's n log n over log cubed n.</span> <span m="4473000">It's n over log squared n, OK?</span> <span m="4477247">And the best, so now I wonder if I have a</span> <span m="4483106">typo here. I have that the best is,</span> <span m="4488085">p bar is theta of n over log n. Is that right?</span> <span m="4494676">I think so. Yeah, that's the best to date.</span> <span m="4502000">That's the best to date. By Occoli, I believe,</span> <span m="4505576">is who did this. OK, so you can actually get a</span> <span m="4509153">fairly good, but it turns out sorting is a really tough</span> <span m="4513446">problem to parallelize to get really good constants where you</span> <span m="4518215">want to make it so it's running exactly the same.</span> <span m="4522030">Matrix multiplication, you can make it run in parallel</span> <span m="4526243">and get straight, hard rail, linear speed up with</span> <span m="4530058">a number of processors. There is plenty of parallelism,</span> <span m="4535356">and running on more processors, every processor carries a full</span> <span m="4539994">weight. With sorting,</span> <span m="4541514">typically you lose, I don't know,</span> <span m="4543947">20% in my experience, OK, in terms of other stuff</span> <span m="4547596">going on because you have to work really hard to get the</span> <span m="4551777">constants of this merge algorithm down to the constants</span> <span m="4555883">of that normal merge, right?</span> <span m="4559000">I mean that's a pretty good algorithm, right,</span> <span m="4562337">the one that just goes, BUZZING SOUND,</span> <span m="4565143">and just takes two lists and merges them like that.</span> <span m="4568934">So, it's an interesting issue. And a lot of people work very</span> <span m="4573410">hard on sorting, because it's a hugely important</span> <span m="4576975">problem, and how it is that you can actually get the constants</span> <span m="4581601">down while still guaranteeing that it will scale up with a</span> <span m="4585924">number of processors. OK, that's our little sojourn</span> <span m="4589716">into parallel land, and next week we're going to</span> <span m="4593281">talk about caching, which is another very important</span> <span m="4597073">area of algorithms, and of programming in general.</span> </p>
</div>
        <div id="vid_transcript" itemprop="description" class="tabContent hide">
<h2 class="subhead">Free Downloads</h2>
<h3 class="subsubhead">Video</h3>
<ul>
<li>iTunes U (<a href="https://itunes.apple.com/us/itunes-u/id341597754">MP4 - 161MB</a>)</li>
<li>Internet Archive (<a href="http://www.archive.org/download/MIT6.046JF05MPEG4/ocw-6.046-07dec2005-220k.mp4">MP4 - 316MB</a>)</li>
</ul>
<br><h3 class="subsubhead">Free Streaming</h3>
<ul><li><a href="http://videolectures.net/mit6046jf05_introduction_algorithms/">VideoLectures.net</a></li></ul>
<br><h3 class="subsubhead">Subtitle</h3>
<ul><li>English - US (<a href="../../../contents/video-lectures/lecture-23-advanced-topics-cont./F0VsQWWVWU4.srt">SRT</a>)</li></ul>
</div>
    
   </div>  




      					 
        <div class="" id="parent-fieldname-bottom_html_area">
            
            
        </div>
    
                    </div>
<!--Course_inner_chip tag close -->
           		</div>
<!--Course_wrapper tag close --> 
            </div>
<!--left tag close -->
            <div id="right">
                <!--Begin Right Portion -->
                    <div>
    
<div id="portletwrapper-6f63772e7269676874746f70706f72746c65746d616e616765720a636f6e746578740a2f506c6f6e650a646f6e617465" class="portletWrapper kssattr-portlethash-6f63772e7269676874746f70706f72746c65746d616e616765720a636f6e746578740a2f506c6f6e650a646f6e617465">
<div class="portletStaticText portlet-static-donate"><p class="zero"><a href="http://ocw.mit.edu/donate"><img src="../../../common/images/button_donate-now.png" alt="Donate Now." class="donate"></a></p></div>

</div>




</div>

                	<div>
    



</div>


        <div class="" id="parent-fieldname-rsi_top_html_area">
            
            
        </div>
    

<!-- RSI google ad space-->


<div id="google_ads">    
    <script type="text/javascript" src="http://partner.googleadservices.com/gampad/google_service.js"></script><script type="text/javascript">GS_googleAddAdSenseService("ca-pub-6588555046597237");GS_googleEnableAllServices();</script><script type="text/javascript">GA_googleAddSlot("ca-pub-6588555046597237", "VIDEO_INDIVIDUAL_SLOT_A_DL");GA_googleAddSlot("ca-pub-6588555046597237", "VIDEO_INDIVIDUAL_SLOT_B_DL");GA_googleAddSlot("ca-pub-6588555046597237", "VIDEO_INDIVIDUAL_SLOT_C_DL");</script><script type="text/javascript">GA_googleFetchAds();</script><script language="javascript" type="text/javascript">
GA_googleAddAttr("TYPE","HOUSE");
GA_googleAddAttr("DEPARTMENT","6");
GA_googleAddAttr("CRS_BEG2","04");
GA_googleAddAttr("CRS_END","6J");
GA_googleAddAttr("SESSION","F");
GA_googleAddAttr("YEAR","05");
</script><script type="text/javascript">GA_googleFillSlot("VIDEO_INDIVIDUAL_SLOT_A_DL");</script><script type="text/javascript">GA_googleFillSlot("VIDEO_INDIVIDUAL_SLOT_B_DL");</script><script type="text/javascript">GA_googleFillSlot("VIDEO_INDIVIDUAL_SLOT_C_DL");</script>
</div>

<!-- End RSI ads--> 

<div>
    



</div>

            </div>
<!--Right div close -->
            <div class="clear"></div> 
        </div>
<!--grid tag close --> 
      </div>
		
		<div id="bottom">
			<div id="grid">
				
<div id="portletwrapper-6f63772e626f74746f6d706f72746c65746d616e616765720a636f6e746578740a2f506c6f6e650a736974652d666f6f746572" class="portletWrapper kssattr-portlethash-6f63772e626f74746f6d706f72746c65746d616e616765720a636f6e746578740a2f506c6f6e650a736974652d666f6f746572">
<div class="portletStaticText portlet-static-site-footer">
<!--googleoff: index--> <div id="bottom"><div id="grid">
<!-- *begin footer* --> <div role="navigation sitemap" id="footer">
<div class="grid_2 alpha" id="foot-c1">
<h4 class="footer">Find Courses</h4> <ul class="foot-bullet">
<li><a href="http://ocw.mit.edu/courses/find-by-topic/">Find by Topic</a></li>     <li><a href="http://ocw.mit.edu/courses/find-by-number/">Find by Course Number</a></li>     <li><a href="http://ocw.mit.edu/courses/find-by-department/">Find by Department</a></li>     <li><a href="http://ocw.mit.edu/courses/audio-video-courses/">Audio/Video Courses</a></li>     <li><a href="http://ocw.mit.edu/courses/subtitled/">Courses with Subtitles</a></li>     <li><a href="http://ocw.mit.edu/courses/online-textbooks/">Online Textbooks</a></li>     <li><a href="http://ocw.mit.edu/courses/new-courses/">New Courses</a></li>     <li><a href="http://ocw.mit.edu/courses/most-visited-courses/">Most Visited Courses</a></li>     <li><a href="http://ocw.mit.edu/courses/ocw-scholar/">OCW Scholar Courses</a></li>     <li><a href="http://ocw.mit.edu/courses/this-course-at-mit/">This Course at MIT</a></li>     <li><a href="http://ocw.mit.edu/resources/">Supplemental Resources</a></li>     <li><a href="http://ocw.mit.edu/courses/translated-courses/">Translated Courses</a></li>     <li><a href="http://ocw.mit.edu/courses/">View All Courses</a></li> </ul>
</div> <div class="grid_2" id="foot-c2">
<h4 class="footer">About</h4> <ul class="foot-bullet">
<li><a href="http://ocw.mit.edu/about/">About OpenCourseWare</a></li>     <li><a href="http://ocw.mit.edu/about/site-statistics/">Site Stats</a></li>     <li><a href="http://ocw.mit.edu/about/ocw-stories/">OCW Stories</a></li>     <li><a href="http://ocw.mit.edu/about/media-coverage/">Media Coverage</a></li>     <li><a href="http://ocw.mit.edu/about/newsletter/">Newsletter</a></li>     <li><a href="http://ocw.mit.edu/about/media-coverage/press-releases/">Press Releases</a></li> </ul>
</div> <div class="grid_2" id="foot-c3">
<h4 class="footer">Donate</h4> <ul class="foot-bullet">
<li><a href="http://ocw.mit.edu/donate">Make a Donation</a></li>     <li><a href="http://ocw.mit.edu/donate/why-donate/">Why Donate?</a></li>     <li><a href="http://ocw.mit.edu/donate/our-supporters/">Our Supporters</a></li>     <li><a href="http://ocw.mit.edu/donate/other-ways-to-contribute/">Other Ways to Contribute</a></li>     <li><a href="http://ocw.mit.edu/donate/shop-ocw/">Shop OCW</a></li>     <li><a href="http://ocw.mit.edu/support/">Become a Corporate Sponsor</a></li> </ul>
</div> <div class="grid_2" id="foot-c4">
<h4 class="footer">Featured Sites</h4> <ul class="foot-bullet">
<li><a href="http://ocw.mit.edu/high-school/">Highlights for High School</a></li>     <li><a href="http://ocw.mit.edu/educator/">OCW Educator</a></li>     <li><a href="http://ocw.mit.edu/courses/crosslinks/">MIT Crosslinks and OCW</a></li>     <li><a href="http://ocw.mit.edu/ans7870/featured/mitx-courses-on-edx.htm">MITx Courses on edX</a></li>     <li><a href="http://teachingexcellence.mit.edu/">Teaching Excellence at MIT</a></li>     <li><a href="http://www.oeconsortium.org/">Open Education Consortium</a></li> </ul>
<h4 style="margin-top: 14px;" class="footer">Tools</h4> <ul class="foot-bullet">
<li><a href="http://ocw.mit.edu/help/">Help &amp; FAQs</a></li>     <li><a href="../../../common/jsp/feedback.htm">Contact Us</a></li>     <li><a href="../../../common/search/AdvancedSearch.htm">Advanced Search</a></li>     <li><a href="http://ocw.mit.edu/help/site-map/">Site Map</a></li>     <li><a href="../../../common/terms/index.htm">Privacy &amp; Terms of Use</a></li>     <li><a href="http://ocw.mit.edu/help/rss/">RSS Feeds</a></li> </ul>
</div> <div class="grid_4 omega" id="foot-c5">
<h4 class="footer">Our Corporate Supporters</h4> <!-- HOME_CORP_LOGO_1 --> <div class="sponsors_google_ads_even" id="div-gpt-ad-1388181177156-0"><script type="text/javascript">
googletag.cmd.push(function() { googletag.display('div-gpt-ad-1388181177156-0'); });
</script></div> <!-- HOME_CORP_LOGO_2 --> <div class="sponsors_google_ads_odd" id="div-gpt-ad-1388181177156-1"><script type="text/javascript">
googletag.cmd.push(function() { googletag.display('div-gpt-ad-1388181177156-1'); });
</script></div> <!-- HOME_CORP_LOGO_3 --> <div class="sponsors_google_ads_even" id="div-gpt-ad-1388181177156-2"><script type="text/javascript">
googletag.cmd.push(function() { googletag.display('div-gpt-ad-1388181177156-2'); });
</script></div> <!-- HOME_CORP_LOGO_4 --> <div class="sponsors_google_ads_odd" id="div-gpt-ad-1388181177156-3"><script type="text/javascript">
googletag.cmd.push(function() { googletag.display('div-gpt-ad-1388181177156-3'); });
</script></div> <!-- HOME_CORP_LOGO_5 --> <div class="sponsors_google_ads_even" id="div-gpt-ad-1388181177156-4"><script type="text/javascript">
googletag.cmd.push(function() { googletag.display('div-gpt-ad-1388181177156-4'); });
</script></div> <!-- HOME_CORP_LOGO_6 --> <div class="sponsors_google_ads_odd" id="div-gpt-ad-1388181177156-5"><script type="text/javascript">
googletag.cmd.push(function() { googletag.display('div-gpt-ad-1388181177156-5'); });
</script></div>
</div> <div class="grid_12 alpha omega" style="border-top: thin solid #d5c9ba; padding-top: 24px; margin-bottom: 10px; text-align: center;"><p style="font-family: TitilliumText22LRegular,Verdana; text-align: center; font-size: 1.1em;">Support for <span style="letter-spacing: 0.5px;"><strong>MIT OPENCOURSEWARE'S 15th anniversary</strong></span> is provided by <a href="http://www.sapientnitro.com/en-us.html#home"><img style="width: 145px; height: 35px; vertical-align: middle; margin-left: 7px;" alt="SapientNitro logo and nameplate." src="../../../common/images/logo_sapient.png"></a></p></div> <div itemtype="http://schema.org/CollegeOrUniversity" itemscope="" itemprop="publisher" class="grid_12 alpha omega">
<h4 style="border-top: thin solid #d5c9ba; padding-top: 10px; margin-bottom: 10px;" class="footer">About <span itemprop="name">MIT OpenCourseWare</span>
</h4> <p itemprop="description" style="color: #999; font-size: 1em; line-height: 1.5em; margin-top: 10px;">MIT OpenCourseWare makes the materials used in the teaching of almost all of MIT's subjects available on the Web, free of charge. With more than 2,200 courses available, OCW is delivering on the promise of open sharing of knowledge. <a href="http://ocw.mit.edu/about/">Learn more »</a></p>
</div> <div style="border-top: none;" class="grid_12 alpha omega" id="foot-copy">
<a href="http://web.mit.edu"><img style="width: 195; height: 44;" alt="Massachusetts Institute of Technology logo and name." src="../../../common/images/logo_mit.png"></a><a href="http://odl.mit.edu"><img style="width: 289; height: 54; vertical-align: top;" alt="MIT Office of Digital Learning logo and name." src="http://ocw.mit.edu/images/logo_odl.png"></a><a href="http://www.oeconsortium.org/"><img style="width: 219px; height: 59px; vertical-align: top;" alt="Open Education Consortium logo." src="http://ocw.mit.edu/images/logo_oec.png"></a><a itemprop="useRightsUrl" rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img style="width: 126px; height: 44px; margin-right: 0; margin-left: 13px;" alt="Creative Commons logo with terms BY-NC-SA." src="../../../common/images/cc_by-nc-sa.png"></a> <p class="copyright">© 2001–2015<br> Massachusetts Institute of Technology</p> <p style="font-size: 0.9em; margin-bottom: 15px;">Your use of the MIT OpenCourseWare site and materials is subject to our <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/">Creative Commons License</a> and other <a rel="cc:morePermissions" href="../../../common/terms/index.htm">terms of use</a>.</p>
</div>
</div>
</div></div> <!--googleon: index-->
</div>

</div>





                
			</div> <!-- bottom grid end -->
		</div>
<!-- bottom end -->
		
		
   </body>
</html>

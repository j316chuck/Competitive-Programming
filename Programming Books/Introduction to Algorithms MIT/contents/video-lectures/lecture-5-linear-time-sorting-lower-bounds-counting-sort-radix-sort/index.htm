<!DOCTYPE html><html lang="en">
<head>
<meta charset="utf-8">
<meta name="format-detection" content="telephone=no">
<title>Lecture 5: Linear-time Sorting: Lower Bounds, Counting Sort, Radix Sort | Video Lectures | Introduction to Algorithms (SMA 5503) | Electrical Engineering and Computer Science | MIT OpenCourseWare</title>
<!-- Begin Automatic Metadata Insertion --><meta content="6-046j-introduction-to-algorithms-sma-5503-fall-2005" name="WT.cg_n">
<meta content="Lecture 5: Linear-time Sorting: Lower Bounds, Counting Sort, Radix Sort" name="WT.cg_s">
<meta content="" name="Description">
<meta content="Leiserson, Charles" name="Author">
<meta content="Demaine, Erik" name="Author">
<meta content="algorithms,efficient algorithms,sorting,search trees,heaps,hashing,divide-and-conquer,dynamic programming,amortized analysis,graph algorithms,shortest paths,network flow,computational geometry,number-theoretic algorithms,polynomial and matrix calculations,caching,parallel computing,Algorithms and Data Structures" name="keywords">
<meta content="6.046J Introduction to Algorithms (SMA 5503) | Lecture 5: Linear-time Sorting: Lower Bounds, Counting Sort, Radix Sort" name="Search_Display">
<meta content="Algorithms and Data Structures" itemprop="about">
<!-- End Automatic Metadata Insertion --><link title="default" rel="stylesheet" type="text/css" href="../../../common/styles/grid.css">
<link title="default" rel="stylesheet" type="text/css" href="../../../common/styles/base.css">
<link title="default" rel="stylesheet" type="text/css" href="../../../common/styles/menu.css">
<link title="default" rel="stylesheet" type="text/css" href="../../../common/styles/jquery.bubblepopup.css">
<link title="default" rel="stylesheet" type="text/css" href="../../../common/styles/courses.css">
<link title="default" rel="stylesheet" type="text/css" href="../../../common/styles/courses_new.css">
<link title="default" rel="stylesheet" type="text/css" href="../../../common/styles/jquery.jscrollpane.css">
<link title="default" rel="stylesheet" type="text/css" href="../../../common/styles/media_tabs.css">
<link href="http://ocw.mit.edu/xml/ocwcc.rdf" type="application/rdf+xml" rel="metadata">
<link rel="canonical" href="http://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-046j-introduction-to-algorithms-sma-5503-fall-2005/video-lectures/lecture-5-linear-time-sorting-lower-bounds-counting-sort-radix-sort">
<link rel="apple-touch-icon" href="../../../common/images/apple-touch-icon.png">
<script type="text/javascript" src="../../../common/scripts/jquery.js"></script><script type="text/javascript" src="../../../common/scripts/ocw-media-utils-offline.js"></script><script type="text/javascript" src="../../../common/scripts/ocw-offline.js"></script><script type="text/javascript" src="../../../common/scripts/jquery.bubblepopup.min.js"></script><script type="text/javascript" src="../../../common/scripts/jquery-ui.min.js"></script><script type="text/javascript" src="../../../common/scripts/jquery.jscrollpane.min.js"></script><script type="text/javascript" src="../../../common/scripts/bubble-popup-offline.js"></script><script type="text/javascript">
      $(document).ready(function() {
        $("#tabs").tabs();
        IpadScroller();
      });
    </script>
</head>
<body itemscope itemtype="http://schema.org/WebPage">
        
	

        <div id="top">
			<div id="grid">
				
				
					
<div id="portletwrapper-6f63772e746f70706f72746c65746d616e616765720a636f6e746578740a2f506c6f6e650a736974652d686561646572" class="portletWrapper kssattr-portlethash-6f63772e746f70706f72746c65746d616e616765720a636f6e746578740a2f506c6f6e650a736974652d686561646572">
<div class="portletStaticText portlet-static-site-header">
<!--googleoff: index-->
<div class="grid_6 alpha" role="banner" id="banner"><a href="http://ocw.mit.edu/"><img class="logo" alt="MIT OpenCourseWare, Massachusetts Institute of Technology" src="../../../common/images/ocw_mast.png"></a></div>
<div class="grid_6 omega" role="form toolbar" id="subscribe">
<div class="module">
<table class="social"><tbody><tr>
<td class="socialbutton"><a href="http://ocw.mit.edu/subscribe/index.htm?utm_source=header"><img src="../../../common/images/trans.gif" alt="An icon depicting an envelope.">Subscribe to the OCW Newsletter</a></td>
            <td>
<a href="https://plus.google.com/104567381989352550847/posts"><img alt="Click to visit our Google+ page." src="../../../common/images/icon_gp.png"></a><a href="https://www.pinterest.com/mitocw/pins/"><img alt="Click to visit our Pinterest page." src="../../../common/images/icon_pin.png"></a><a href="http://facebook.com/mitocw"><img alt="Click to visit our Facebook page." src="../../../common/images/icon_fb.png"></a><a href="http://twitter.com/mitocw"><img alt="Click to visit our Twitter feed." src="../../../common/images/icon_tw.png"></a>
</td>
        </tr></tbody></table>
</div>
<p class="helplinks"><a href="http://ocw.mit.edu/help">Help</a>   |   <a href="../../../common/jsp/feedback.htm">Contact Us</a></p>
</div>
<div class="clear"> </div>
<!--googleon: index-->
</div>

</div>





<!--googleoff: index-->
<div id="mega" role="navigation" class="grid_8 alpha">        
	<ul id="menu">
<li id="menu_home">
            <a href="http://ocw.mit.edu/"><img src="../../../common/images/top-nav_home.png" class="home_icon" alt="Click for site home page."></a><!-- Begin Home Item -->
        </li>
<!-- End Home Item -->        
        <li class="selected">
            <a href="#" class="drop">Find Courses</a><!-- Begin 5 columns Item -->
            <div class="dropdown_5columns-a mega-courses">                    
                <div class="col_1a">
                    <div class="row_1a">
                        <div class="quart">
                            <h2 class="nav">Find courses by:</h2>
                            <ul class="nav-bullet find_by">
<li><a href="http://ocw.mit.edu/courses/find-by-topic/">Topic</a></li>
                                <li><a href="http://ocw.mit.edu/courses/find-by-number/">MIT Course Number</a></li>
                                <li><a href="http://ocw.mit.edu/courses/find-by-department/">Department</a></li>
                            </ul>
<ul style="margin-top: 88px;" class="nav-bullet find_by">
<li style="font-weight: normal; font-size: 1em;"><a href="http://ocw.mit.edu/courses/">View All Courses</a></li>
							</ul>
</div>
                        <div class="quart">
                            <h2 class="nav">Collections</h2>
                            <ul class="nav-bullet">
<li><a href="http://ocw.mit.edu/courses/audio-video-courses/">Audio/Video Lectures</a></li>
                                <li><a href="http://ocw.mit.edu/courses/online-textbooks/">Online Textbooks</a></li>
                                <li><a href="http://ocw.mit.edu/courses/new-courses/">New Courses</a></li>
                                <li><a href="http://ocw.mit.edu/courses/most-visited-courses/">Most Visited Courses</a></li>
                                <li><a href="http://ocw.mit.edu/courses/ocw-scholar/">OCW Scholar Courses</a></li>
                                <li><a href="http://ocw.mit.edu/courses/this-course-at-mit/">This Course at MIT</a></li>
                                <li><a href="http://ocw.mit.edu/resources/">Supplemental Resources</a></li>
                            </ul>
</div>
                        <div class="clear"> </div>
                    </div>
                    <div class="row_1b">
                        <h2 class="nav">Cross-Disciplinary Topic Lists</h2>
                        <div class="quart">
                        <ul class="nav-bullet">
<li><a href="http://ocw.mit.edu/courses/energy-courses">Energy</a></li>
                            <li><a href="http://ocw.mit.edu/courses/entrepreneurship">Entrepreneurship</a></li>
                            <li><a href="http://ocw.mit.edu/courses/environment-courses">Environment</a></li>
                        </ul>
</div>    
                        <div class="quart">
                        <ul class="nav-bullet">
<li><a href="http://ocw.mit.edu/courses/intro-programming">Introductory Programming</a></li>
                            <li><a href="http://ocw.mit.edu/courses/life-sciences">Life Sciences</a></li>
                            <li><a href="http://ocw.mit.edu/courses/transportation-courses">Transportation</a></li>
                        </ul>
</div>
                        <div class="clear"> </div>
                    </div>
                    <div class="clear"> </div>
                </div>
                <div class="col_1b">
                    <h2 class="nav">Translated Courses</h2>
                    <ul class="nav-bullet">
<li><a href="http://ocw.mit.edu/courses/translated-courses/traditional-chinese">繁體字 / Traditional Chinese</a></li>
                        <li><a href="http://ocw.mit.edu/courses/translated-courses/spanish">Español / Spanish</a></li>
                        <li><a href="http://ocw.mit.edu/courses/translated-courses/portuguese">Português / Portuguese</a></li>
                        <li><a href="http://ocw.mit.edu/courses/translated-courses/persian">فارسی / Persian</a></li>
                        <li><a href="http://ocw.mit.edu/courses/translated-courses/turkish">Türkçe / Turkish</a></li>
                        <li><a href="http://ocw.mit.edu/courses/translated-courses/korean">(비디오)한국 / Korean</a></li>
                        <li><a href="http://ocw.mit.edu/courses/translated-courses">More...</a></li>
                    </ul>
</div>
            </div>
        </li>
        <li>
            <a href="" class="drop">About</a>
            <div class="dropdown_1column-a">
                <div class="col_1">
                    <ul class="nav-bullet mega-div-bottom">
<li><a href="http://ocw.mit.edu/about/">About MIT OpenCourseWare</a></li>
                    </ul>
<ul class="nav-bullet mega-div-bottom">
<li><a href="http://ocw.mit.edu/about/site-statistics/">Site Stats</a></li>
                        <li><a href="http://ocw.mit.edu/about/ocw-stories/">OCW Stories</a></li>                        
                    </ul>
<ul class="nav-bullet">
<li><a href="http://ocw.mit.edu/about/media-coverage/">Media Coverage</a></li>
                        <li><a href="http://ocw.mit.edu/about/newsletter/">Newsletter</a></li>                        
                    </ul>
</div>
            </div>  
        </li>    
        <li>
            <a href="" class="drop">Donate</a>        
            <div class="dropdown_1column-a">
                    <div class="col_1">
                        <ul class="nav-bullet mega-div-bottom">
<li><a href="http://ocw.mit.edu/donate/">Make a Donation</a></li>
                            <li><a href="http://ocw.mit.edu/donate/why-donate/">Why Donate?</a></li>
                            <li><a href="http://ocw.mit.edu/donate/our-supporters/">Our Supporters</a></li>
                            <li><a href="http://ocw.mit.edu/donate/other-ways-to-contribute/">Other Ways to Contribute</a></li>
                            <li><a href="http://ocw.mit.edu/donate/shop-ocw">Shop OCW</a></li>
                        </ul>
<ul class="nav-bullet">
<li><a href="http://ocw.mit.edu/support/">Become a Corporate Sponsor</a></li>
                        </ul>
</div>
            </div>            
        </li>        
        <li>
            <a href="" class="drop">Featured Sites</a>        
            <div class="dropdown_1column-a">
                <div class="col_1">
                    <ul class="nav-bullet mega-div-bottom">
<li><a href="http://ocw.mit.edu/high-school/">Highlights for High School</a></li>
                        <li><a href="http://ocw.mit.edu/educator/">OCW Educator</a></li>
                        <li><a href="http://ocw.mit.edu/courses/crosslinks/">MIT Crosslinks and OCW</a></li>                        
                    </ul>
<ul class="nav-bullet mega-div-top">
<li><a href="http://ocw.mit.edu/ans7870/featured/mitx-courses-on-edx.htm">MITx Courses on edX</a></li>
                        <li><a href="http://teachingexcellence.mit.edu/">Teaching Excellence at MIT</a></li>
						<li><a href="http://www.oeconsortium.org/">Open Education Consortium</a></li>
                    </ul>
</div>
            </div>            
        </li>
    </ul>
</div>
<div id="search" role="search" class="grid_4 omega">
    
    <form method="get" action="../../../common/search/AdvancedSearch.htm">
     	 <table class="search"><tbody><tr>
<td class="black"><input type="text" onblur="fillSearchBox()" onfocus="clearSearchBox()" maxlength="255" value="Search" name="q" class="greytext searchField" id="terms"></td> 			 
                    <td class="black"><input type="image" src="../../../common/images/button_search.png" name="btnG" class="sub_button"></td>			 
                    <td class="text2"><a href="../../../common/search/AdvancedSearch.htm">Advanced<br>Search</a></td>
                </tr></tbody></table>
</form>
</div>
<div class="clear"></div>
<!--googleon: index-->
<!-- *end header* -->  

				
				
			</div>
<!-- top grid end -->
		</div>
<!-- top end -->
			
		<div id="center_media">
      	<div id="grid">
      		<div id="left">
        		<div id="breadcrumb_media">
                	<p>

    <a href="http://ocw.mit.edu/">Home</a>
    
        »
        
    
    
        
            <a href="http://ocw.mit.edu/courses">Courses</a>
            
                »
                
            
            
         
    
    
        
            <a href="http://ocw.mit.edu/courses/electrical-engineering-and-computer-science">Electrical Engineering and Computer Science</a>
            
                »
                
            
            
         
    
    
        
            <a href="../../../contents/index.htm">Introduction to Algorithms (SMA 5503)</a>
            
                »
                
            
            
         
    
    
        
            <a href="../../../contents/video-lectures/index.htm">Video Lectures</a>
            
                »
                
            
            
         
    
    
        
            
            
            Lecture 5: Linear-time Sorting: Lower Bounds, Counting Sort, Radi
         
    
</p>

            	</div>
            	<div class="clear"></div>
        		<div id="media_title">
        		<h1 class="title" itemprop="name" property="dct:title">
        <span class="" id="parent-fieldname-title">
            Lecture 5: Linear-time Sorting: Lower Bounds, Counting Sort, Radix Sort
        </span>
    </h1>
        		</div>
           		<div class="clear"></div>
           		<div id="course_wrapper_media">
           			<div id="course_nav">
           				<script language="javascript" type="text/javascript">
function toggleMenu(objID) {
  if (!document.getElementById) return;
  var ob = document.getElementById(objID);
  ob.className = (ob.className == 'selected')?'': 'selected';
}
function toggleClass(id)
{
  var divtoggleClass= document.getElementById(id);
  divtoggleClass.className = (divtoggleClass.className == 'mO')?'mC': 'mO';
  return false;
}
function changeAlt(id)
{
  id.alt = (id.alt == 'Expand Menu')?'Collapse Menu' : 'Expand Menu';
  id.title = (id.title == 'Expand Menu')?'Collapse Menu' : 'Expand Menu';
}
</script><!--Left Nav Starts --><ul>
<li class="">
			   			<a href="../../../contents/index.htm">
		                  Course Home  			                
	                    </a>
		        </li>
		    
         	
	
	
	    	
	    	    <li class="">
			   			<a href="../../../contents/syllabus/index.htm">
		                  Syllabus  			                
	                    </a>
		        </li>
		    
         	
	
	
	    	
	    	    <li class="">
			   			<a href="../../../contents/calendar/index.htm">
		                  Calendar  			                
	                    </a>
		        </li>
		    
         	
	
	
	    	
	    	    <li class="">
			   			<a href="../../../contents/readings/index.htm">
		                  Readings  			                
	                    </a>
		        </li>
		    
         	
	
	
	    	
	    	    <li class="">
			   			<a href="../../../contents/assignments/index.htm">
		                  Assignments  			                
	                    </a>
		        </li>
		    
         	
	
	
	    	
	    	    <li class="">
			   			<a href="../../../contents/exams/index.htm">
		                  Exams  			                
	                    </a>
		        </li>
		    
         	
	
	
	    	
	    	    <li class="selected">
			   			<a href="../../../contents/video-lectures/index.htm">
		                  Video Lectures  			                
	                    </a>
		        </li>
		    
         	
	
	
	    	
	    	    
		    
         	
	<!--second tal block close-->  
	
</ul>
<!--Left Nav Ends -->
</div>
           			<div id="course_inner_media">
      					 
        <div class="" id="parent-fieldname-text">
            
            
        </div>
    
      					 

<script type="text/javascript">var caption_embed_1 ={'English - US': '/courses/electrical-engineering-and-computer-science/6-046j-introduction-to-algorithms-sma-5503-fall-2005/video-lectures/lecture-5-linear-time-sorting-lower-bounds-counting-sort-radix-sort/0VqawRl3Xzs.srt'}</script><div id="media-embed">
         <div class="attention_message" id="embed_1">
<p>Flash and JavaScript are required for this feature.</p>
<p>Download the video from <a href="https://itunes.apple.com/us/itunes-u/id341597754">iTunes U</a> or the <a href="http://www.archive.org/download/MIT6.046JF05MPEG4/ocw-6.046-26sep2005-220k.mp4">Internet Archive</a>.</p>
</div>
     </div>
    
     <script type="text/javascript">ocw_embed_chapter_media('embed_1', 'http://www.youtube.com/v/0VqawRl3Xzs', 'youtube', '/courses/electrical-engineering-and-computer-science/6-046j-introduction-to-algorithms-sma-5503-fall-2005/video-lectures/lecture-5-linear-time-sorting-lower-bounds-counting-sort-radix-sort', 'http://img.youtube.com/vi/0VqawRl3Xzs/0.jpg',0,0, 'http://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-046j-introduction-to-algorithms-sma-5503-fall-2005/video-lectures/lecture-5-linear-time-sorting-lower-bounds-counting-sort-radix-sort/0VqawRl3Xzs.srt')</script><div id="transcript1"></div>
				 <script type="text/javascript">setThreePlayTranscriptPlugin(2, 703415)</script><script type="text/javascript" src="http://p3.3playmedia.com/p3.js"></script><div id="media_resource_next_prev_nav" style="margin-top: 1em;">
        <p>
        
            <a href="../../../contents/video-lectures/lecture-4-quicksort-randomized-algorithms/index.htm">
                <img src="../../../common/images/btn_previous_resource.png" style="margin: 0 30px 0 50px;" alt="Previous track" title="Previous track"></a>
     	
     	
        
            <a href="../../../contents/video-lectures/lecture-6-order-statistics-median/index.htm"> 
                <img src="../../../common/images/btn_next_resource.png" alt="Next track" title="Next track"></a>
       
       </p>
     </div>
 


<script type="text/javascript">
		window.onload=function(){
		init();
		
		}
		var tabLinks = new Array();
		var contentDivs = new Array();
		function init() {
		  // Grab the tab links and content divs from the page
		  var tabListItems = document.getElementById('tabs').childNodes;
		  for ( var i = 0; i < tabListItems.length; i++ ) {
			if ( tabListItems[i].nodeName == "LI" ) {
			  var tabLink = getFirstChildWithTagName( tabListItems[i], 'A' );
			  var id = getHash( tabLink.getAttribute('href') );
			  tabLinks[id] = tabLink;
			  contentDivs[id] = document.getElementById( id );
			}
		  }
		  // Assign onclick events to the tab links, and
		  // highlight the first tab
		  var i = 0;
		  for ( var id in tabLinks ) {
			tabLinks[id].onclick = showTab;
			tabLinks[id].onfocus = function() { this.blur() };
			if ( i == 0 ) tabLinks[id].className = 'selected';
			i++;
		  }
		  // Hide all content divs except the first
		  var i = 0;
		  for ( var id in contentDivs ) {
			if ( i != 0 ) contentDivs[id].className = 'tabContent hide';
			i++;
		  }
		}
		function showTab() {
		  var selectedId = getHash( this.getAttribute('href') );
		  // Highlight the selected tab, and dim all others.
		  // Also show the selected content div, and hide all others.
		  for ( var id in contentDivs ) {
			if ( id == selectedId ) {
			  tabLinks[id].className = 'selected';
			  contentDivs[id].className = 'tabContent';
			} else {
			  tabLinks[id].className = '';
			  contentDivs[id].className = 'tabContent hide';
			}
		  }
		  // Stop the browser following the link
		  return false;
		}
		function getFirstChildWithTagName( element, tagName ) {
		  for ( var i = 0; i < element.childNodes.length; i++ ) {
			if ( element.childNodes[i].nodeName == tagName ) return element.childNodes[i];
		  }
		}
		function getHash( url ) {
		  var hashPos = url.lastIndexOf ( '#' );
		  return url.substring( hashPos + 1 );
		}
 </script><div id="media_tabs">
     
        <ul id="tabs">
<li class="first">
                <a href="#vid_about" class="selected">About this Video</a>
            </li>
            <li class="">
                <a href="#vid_index" class="">Playlist</a>
            </li>
            <li class="">
                <a href="#vid_playlist" class="">Related Resources</a>
            </li>
            <li class="">
                <a href="#vid_related" class="">Transcript</a>
            </li>
            <li class="">
                <a href="#vid_transcript" class="">Download this Video</a>
            </li>
        </ul>
<div id="vid_about" itemprop="description" class="tabContent">
<p><strong>Topics covered: </strong>Linear-time Sorting: Lower Bounds, Counting Sort, Radix Sort</p>  <p><strong>Instructors: </strong>Prof. Erik Demaine, Prof. Charles Leiserson</p>
</div>
        <div id="vid_index" itemprop="description" class="tabContent hide">
<div class="related-media-thumbnail">
<a href="../../../contents/video-lectures/lecture-1-administrivia-introduction-analysis-of-algorithms-insertion-sort-mergesort/index.htm">
<img src="../../../contents/video-lectures/lecture-1-administrivia-introduction-analysis-of-algorithms-insertion-sort-mergesort/6_046J_lec01_th.jpg" title="Lecture 1: Administrivia; Introduction; Analysis of Algorithms, Insertion Sort, Mergesort" alt="Lecture 1: Administrivia; Introduction; Analysis of Algorithms, Insertion Sort, Mergesort"><p>Lecture 1: Administrivia; I...</p></a>
</div>
<div class="related-media-thumbnail">
<a href="../../../contents/video-lectures/lecture-2-asymptotic-notation-recurrences-substitution-master-method/index.htm">
<img src="../../../contents/video-lectures/lecture-2-asymptotic-notation-recurrences-substitution-master-method/6_046J_lec02_th.jpg" title="Lecture 2: Asymptotic Notation; Recurrences; Substitution, Master Method" alt="Lecture 2: Asymptotic Notation; Recurrences; Substitution, Master Method"><p>Lecture 2: Asymptotic Notat...</p></a>
</div>
<div class="related-media-thumbnail">
<a href="../../../contents/video-lectures/lecture-3-divide-and-conquer-strassen-fibonacci-polynomial-multiplication/index.htm">
<img src="../../../contents/video-lectures/lecture-3-divide-and-conquer-strassen-fibonacci-polynomial-multiplication/6_046J_lec03_th.jpg" title="Lecture 3: Divide-and-Conquer: Strassen, Fibonacci, Polynomial Multiplication" alt="Lecture 3: Divide-and-Conquer: Strassen, Fibonacci, Polynomial Multiplication"><p>Lecture 3: Divide-and-Conqu...</p></a>
</div>
<div class="related-media-thumbnail">
<a href="../../../contents/video-lectures/lecture-4-quicksort-randomized-algorithms/index.htm">
<img src="../../../contents/video-lectures/lecture-4-quicksort-randomized-algorithms/6_046J_lec04_th.jpg" title="Lecture 4: Quicksort, Randomized Algorithms" alt="Lecture 4: Quicksort, Randomized Algorithms"><p>Lecture 4: Quicksort, Rando...</p></a>
</div>
<div class="related-media-thumbnail-nolink">
<div class="now-playing-resource">Now Playing</div>
<img src="../../../contents/video-lectures/lecture-5-linear-time-sorting-lower-bounds-counting-sort-radix-sort/6_046J_lec05_th.jpg" title="Lecture 5: Linear-time Sorting: Lower Bounds, Counting Sort, Radix Sort" alt="Lecture 5: Linear-time Sorting: Lower Bounds, Counting Sort, Radix Sort"><p>Lecture 5: Linear-time Sort...</p>
</div>
<div class="related-media-thumbnail">
<a href="../../../contents/video-lectures/lecture-6-order-statistics-median/index.htm">
<img src="../../../contents/video-lectures/lecture-6-order-statistics-median/6_046J_lec06_th.jpg" title="Lecture 6: Order Statistics, Median" alt="Lecture 6: Order Statistics, Median"><p>Lecture 6: Order Statistics...</p></a>
</div>
<div class="related-media-thumbnail">
<a href="../../../contents/video-lectures/lecture-7-hashing-hash-functions/index.htm">
<img src="../../../contents/video-lectures/lecture-7-hashing-hash-functions/6_046J_lec07_th.jpg" title="Lecture 7: Hashing, Hash Functions" alt="Lecture 7: Hashing, Hash Functions"><p>Lecture 7: Hashing, Hash Fu...</p></a>
</div>
<div class="related-media-thumbnail">
<a href="../../../contents/video-lectures/lecture-8-universal-hashing-perfect-hashing/index.htm">
<img src="../../../contents/video-lectures/lecture-8-universal-hashing-perfect-hashing/6_046J_lec08_th.jpg" title="Lecture 8: Universal Hashing, Perfect Hashing" alt="Lecture 8: Universal Hashing, Perfect Hashing"><p>Lecture 8: Universal Hashin...</p></a>
</div>
<div class="related-media-thumbnail">
<a href="../../../contents/video-lectures/lecture-9-relation-of-bsts-to-quicksort-analysis-of-random-bst/index.htm">
<img src="../../../contents/video-lectures/lecture-9-relation-of-bsts-to-quicksort-analysis-of-random-bst/6_046J_lec09_th.jpg" title="Lecture 9: Relation of BSTs to Quicksort - Analysis of Random BST" alt="Lecture 9: Relation of BSTs to Quicksort - Analysis of Random BST"><p>Lecture 9: Relation of BSTs...</p></a>
</div>
<div class="related-media-thumbnail">
<a href="../../../contents/video-lectures/lecture-10-red-black-trees-rotations-insertions-deletions/index.htm">
<img src="../../../contents/video-lectures/lecture-10-red-black-trees-rotations-insertions-deletions/6_046J_lec10_th.jpg" title="Lecture 10: Red-black Trees, Rotations, Insertions, Deletions" alt="Lecture 10: Red-black Trees, Rotations, Insertions, Deletions"><p>Lecture 10: Red-black Trees...</p></a>
</div>
<div class="related-media-thumbnail">
<a href="../../../contents/video-lectures/lecture-11-augmenting-data-structures-dynamic-order-statistics-interval-trees/index.htm">
<img src="../../../contents/video-lectures/lecture-11-augmenting-data-structures-dynamic-order-statistics-interval-trees/6_046J_lec11_th.jpg" title="Lecture 11: Augmenting Data Structures, Dynamic Order Statistics, Interval Trees" alt="Lecture 11: Augmenting Data Structures, Dynamic Order Statistics, Interval Trees"><p>Lecture 11: Augmenting Data...</p></a>
</div>
<div class="related-media-thumbnail">
<a href="../../../contents/video-lectures/lecture-12-skip-lists/index.htm">
<img src="../../../contents/video-lectures/lecture-12-skip-lists/6_046J_lec12_th.jpg" title="Lecture 12: Skip Lists" alt="Lecture 12: Skip Lists"><p>Lecture 12: Skip Lists</p></a>
</div>
<div class="related-media-thumbnail">
<a href="../../../contents/video-lectures/lecture-13-amortized-algorithms-table-doubling-potential-method/index.htm">
<img src="../../../contents/video-lectures/lecture-13-amortized-algorithms-table-doubling-potential-method/6_046J_lec13_th.jpg" title="Lecture 13: Amortized Algorithms, Table Doubling, Potential Method" alt="Lecture 13: Amortized Algorithms, Table Doubling, Potential Method"><p>Lecture 13: Amortized Algor...</p></a>
</div>
<div class="related-media-thumbnail">
<a href="../../../contents/video-lectures/lecture-14-competitive-analysis-self-organizing-lists/index.htm">
<img src="../../../contents/video-lectures/lecture-14-competitive-analysis-self-organizing-lists/6_046J_lec14_th.jpg" title="Lecture 14: Competitive Analysis: Self-organizing Lists" alt="Lecture 14: Competitive Analysis: Self-organizing Lists"><p>Lecture 14: Competitive Ana...</p></a>
</div>
<div class="related-media-thumbnail">
<a href="../../../contents/video-lectures/lecture-15-dynamic-programming-longest-common-subsequence/index.htm">
<img src="../../../contents/video-lectures/lecture-15-dynamic-programming-longest-common-subsequence/6_046J_lec15_th.jpg" title="Lecture 15: Dynamic Programming, Longest Common Subsequence" alt="Lecture 15: Dynamic Programming, Longest Common Subsequence"><p>Lecture 15: Dynamic Program...</p></a>
</div>
<div class="related-media-thumbnail">
<a href="../../../contents/video-lectures/lecture-16-greedy-algorithms-minimum-spanning-trees/index.htm">
<img src="../../../contents/video-lectures/lecture-16-greedy-algorithms-minimum-spanning-trees/6_046J_lec16_th.jpg" title="Lecture 16: Greedy Algorithms, Minimum Spanning Trees" alt="Lecture 16: Greedy Algorithms, Minimum Spanning Trees"><p>Lecture 16: Greedy Algorith...</p></a>
</div>
<div class="related-media-thumbnail">
<a href="../../../contents/video-lectures/lecture-17-shortest-paths-i-properties-dijkstras-algorithm-breadth-first-search/index.htm">
<img src="../../../contents/video-lectures/lecture-17-shortest-paths-i-properties-dijkstras-algorithm-breadth-first-search/6_046J_lec17_th.jpg" title="Lecture 17: Shortest Paths I: Properties, Dijkstra's Algorithm, Breadth-first Search" alt="Lecture 17: Shortest Paths I: Properties, Dijkstra's Algorithm, Breadth-first Search"><p>Lecture 17: Shortest Paths ...</p></a>
</div>
<div class="related-media-thumbnail">
<a href="../../../contents/video-lectures/lecture-18-shortest-paths-ii-bellman-ford-linear-programming-difference-constraints/index.htm">
<img src="../../../contents/video-lectures/lecture-18-shortest-paths-ii-bellman-ford-linear-programming-difference-constraints/6_046J_lec18_th.jpg" title="Lecture 18: Shortest Paths II: Bellman-Ford, Linear Programming, Difference Constraints" alt="Lecture 18: Shortest Paths II: Bellman-Ford, Linear Programming, Difference Constraints"><p>Lecture 18: Shortest Paths ...</p></a>
</div>
<div class="related-media-thumbnail">
<a href="../../../contents/video-lectures/lecture-19-shortest-paths-iii-all-pairs-shortest-paths-matrix-multiplication-floyd-warshall-johnson/index.htm">
<img src="../../../contents/video-lectures/lecture-19-shortest-paths-iii-all-pairs-shortest-paths-matrix-multiplication-floyd-warshall-johnson/6_046J_lec19_th.jpg" title="Lecture 19: Shortest Paths III: All-pairs Shortest Paths, Matrix Multiplication, Floyd-Warshall, Johnson" alt="Lecture 19: Shortest Paths III: All-pairs Shortest Paths, Matrix Multiplication, Floyd-Warshall, Johnson"><p>Lecture 19: Shortest Paths ...</p></a>
</div>
<div class="related-media-thumbnail">
<a href="../../../contents/video-lectures/lecture-22-advanced-topics/index.htm">
<img src="../../../contents/video-lectures/lecture-22-advanced-topics/6_046J_lec22_th.jpg" title="Lecture 22: Advanced Topics" alt="Lecture 22: Advanced Topics"><p>Lecture 22: Advanced Topics</p></a>
</div>
<div class="related-media-thumbnail">
<a href="../../../contents/video-lectures/lecture-23-advanced-topics-cont./index.htm">
<img src="../../../contents/video-lectures/lecture-23-advanced-topics-cont./6_046J_lec23_th.jpg" title="Lecture 23: Advanced Topics (cont.)" alt="Lecture 23: Advanced Topics (cont.)"><p>Lecture 23: Advanced Topics...</p></a>
</div>
<div class="related-media-thumbnail">
<a href="../../../contents/video-lectures/lecture-24-advanced-topics-cont./index.htm">
<img src="../../../contents/video-lectures/lecture-24-advanced-topics-cont./6_046J_lec24_th.jpg" title="Lecture 24: Advanced Topics (cont.)" alt="Lecture 24: Advanced Topics (cont.)"><p>Lecture 24: Advanced Topics...</p></a>
</div>
<div class="related-media-thumbnail">
<a href="../../../contents/video-lectures/lecture-25-advanced-topics-cont.-discussion-of-follow-on-classes/index.htm">
<img src="../../../contents/video-lectures/lecture-25-advanced-topics-cont.-discussion-of-follow-on-classes/6_046J_lec25_th.jpg" title="Lecture 25: Advanced Topics (cont.) - Discussion of Follow-on Classes" alt="Lecture 25: Advanced Topics (cont.) - Discussion of Follow-on Classes"><p>Lecture 25: Advanced Topics...</p></a>
</div>
</div>
        <div id="vid_playlist" itemprop="description" class="tabContent hide">
<h2 class="subhead">Related Resources</h2>
<p>Lecture Notes (<a target="_blank" href="../../../contents/video-lectures/lecture-5-linear-time-sorting-lower-bounds-counting-sort-radix-sort/lec5.pdf">PDF</a>)<br><a target="_blank" href="../../../contents/assignments/index.htm">Assignments</a><br><a target="_blank" href="../../../contents/exams/index.htm">Exams</a></p>
</div>
        <div id="vid_related" itemprop="description" class="tabContent hide">
<ul><li><a class="transcript-link" title="Open in a new window." alt="Open in a new window." style="text-decoration: none; font-size: 1.0em;" target="_blank" text-decoration: none font-size: href="../../../contents/video-lectures/lecture-5-linear-time-sorting-lower-bounds-counting-sort-radix-sort/0VqawRl3Xzs.pdf"> Download this transcript - PDF (English - US)</a></li></ul>
<p><span m="8000">Today we're going to talk about sorting, which may not come as</span> <span m="12000">such a big surprise. We talked about sorting for a</span> <span m="15000">while, but we're going to talk about it at a somewhat higher</span> <span m="20000">level and question some of the assumptions that we've been</span> <span m="24000">making so far. And we're going to ask the</span> <span m="27000">question how fast can we sort? A pretty natural question.</span> </p>
<p><span m="32000">You may think you know the answer.</span> </p>
<p><span m="35000">Perhaps you do. Any suggestions on what the</span> <span m="40000">answer to this question might be?</span> </p>
<p><span m="43000">There are several possible answers.</span> </p>
<p><span m="46000">Many of them are partially correct.</span> </p>
<p><span m="50000">Let's hear any kinds of answers you'd like and start waking up</span> <span m="56000">this fresh morning. Sorry?</span> </p>
<p><span m="60000">Theta n log n. That's a good answer.</span> </p>
<p><span m="62000">That's often correct. Any other suggestions?</span> </p>
<p><span m="66000">N squared. That's correct if all you're</span> <span m="69000">allowed to do is swap adjacent elements.</span> </p>
<p><span m="72000">Good. That was close.</span> </p>
<p><span m="73000">I will see if I can make every answer correct.</span> </p>
<p><span m="77000">Usually n squared is not the right answer,</span> <span m="80000">but in some models it is. Yeah?</span> </p>
<p><span m="82000">Theta n is also sometimes the right answer.</span> </p>
<p><span m="86000">The real answer is "it depends".</span> </p>
<p><span m="90000">That's the point of today's lecture.</span> </p>
<p><span m="93000">It depends on what we call the computational model,</span> <span m="97000">what you're allowed to do. And, in particular here,</span> <span m="102000">with sorting, what we care about is the order</span> <span m="106000">of the elements, how are you allowed to</span> <span m="109000">manipulate the elements, what are you allowed to do with</span> <span m="114000">them and find out their order. The model is what you can do</span> <span m="120000">with the elements.</span> </p>
<p><span m="134000">Now, we've seen several sorting algorithms.</span> </p>
<p><span m="138000">Do you want to shout some out? I think we've seen four,</span> <span m="143000">but maybe you know even more algorithms.</span> </p>
<p><span m="147000">Quicksort. Keep going.</span> </p>
<p><span m="150000">Heapsort. Merge sort.</span> </p>
<p><span m="152000">You can remember all the way back to Lecture 1.</span> </p>
<p><span m="157000">Any others? Insertion sort.</span> </p>
<p><span m="159000">All right. You're on top of it today.</span> </p>
<p><span m="163000">I don't know exactly why, but these two are single words</span> <span m="169000">and these two are two words. That's the style.</span> </p>
<p><span m="174000">What is the running time of quicksort?</span> </p>
<p><span m="180000">This is a bit tricky. N log n in the average case.</span> </p>
<p><span m="184000">Or, if we randomize quicksort, randomized quicksort runs in n</span> <span m="190000">log n expected for any input sequence.</span> </p>
<p><span m="194000">Let's say n lg n randomized. That's theta.</span> </p>
<p><span m="198000">And the worst-case with plain old quicksort where you just</span> <span m="204000">pick the first element as the partition element.</span> </p>
<p><span m="210000">That's n^2. Heapsort, what's the running</span> <span m="214000">time there? n lg n always.</span> </p>
<p><span m="217000">Merge sort, I hope you can remember that as well,</span> <span m="223000">n lg n. And insertion sort?</span> </p>
<p><span m="226000">n^2. All of these algorithms run no</span> <span m="230000">faster than n lg n, so we might ask,</span> <span m="234000">can we do better than n lg n?</span> </p>
<p><span m="251000">And that is a question, in some sense,</span> <span m="253000">we will answer both yes and no to today.</span> </p>
<p><span m="256000">But all of these algorithms have something in common in</span> <span m="260000">terms of the model of what you're allowed to do with the</span> <span m="265000">elements. Any guesses on what that model</span> <span m="268000">might be? Yeah?</span> </p>
<p><span m="270000">You compare pairs of elements, exactly.</span> </p>
<p><span m="273000">That is indeed the model used by all four of these algorithms.</span> </p>
<p><span m="279000">And in that model n lg n is the best you can do.</span> </p>
<p><span m="283000">We have so far just looked at what are called comparison</span> <span m="288000">sorting algorithms or "comparison sorts".</span> </p>
<p><span m="292000">And this is a model for the sorting problem of what you're</span> <span m="297000">allowed to do. Here all you can do is use</span> <span m="302000">comparisons meaning less than, greater than,</span> <span m="306000">less than or equal to, greater than or equal to,</span> <span m="311000">equals to determine the relative order of elements.</span> </p>
<p><span m="325000">This is a restriction on algorithms.</span> </p>
<p><span m="326000">It is, in some sense, stating what kinds of elements</span> <span m="329000">we're dealing with. They are elements that we can This is a three digit number.</span> <span m="332000">somehow compare. They have a total order,</span> <span m="335000">some are less, some are bigger.</span> </p>
<p><span m="337000">But is also restricts the algorithm.</span> </p>
<p><span m="339000">You could say, well, I'm sorting integers,</span> <span m="342000">but still I'm only allowed to do comparisons with them.</span> </p>
<p><span m="345000">I'm not allowed to multiply the integers or do other weird</span> <span m="349000">things. That's the comparison sorting</span> <span m="351000">model. And this lecture,</span> <span m="352000">in some sense, follows the standard</span> <span m="355000">mathematical progression where you have a theorem, Then we get some 4s,</span> <span m="358000">then you have a proof, then you have a counter</span> <span m="361000">example. It's always a good way to have</span> <span m="365000">a math lecture. We're going to prove the</span> <span m="367000">theorem that no comparison sorting algorithm runs better</span> <span m="371000">than n lg n. Comparisons.</span> </p>
<p><span m="373000">State the theorem, prove that, and then we'll give</span> <span m="377000">a counter example in the sense that if you go outside the</span> <span m="381000">comparison sorting model you can do better, you can get linear</span> <span m="385000">time in some cases, better than n lg n.</span> </p>
<p><span m="388000">So, that is what we're doing today.</span> </p>
<p><span m="392000">But first we're going to stick to this comparison model and try</span> <span m="396000">to understand why we need n lg n comparisons if that's all we're</span> <span m="401000">allowed to do. And for that we're going to</span> <span m="405000">look at something called decision trees,</span> <span m="408000">which in some sense is another model of what you're allowed to</span> <span m="412000">do in an algorithm, but it's more general than the</span> <span m="416000">comparison model. And let's try and example to</span> <span m="421000">get some intuition. Suppose we want to sort three</span> <span m="426000">elements. This is not very challenging,</span> <span m="430000">but we'll get to draw the decision tree that corresponds</span> <span m="435000">to sorting three elements. Here is one solution I claim.</span> </p>
<p></p>
<p><span m="462000">This is, in a certain sense, an algorithm,</span> <span m="465000">but it's drawn as a tree instead of pseudocode.</span> </p>
<p><span m="495000">What this tree means is that each node you're making a</span> <span m="498000">comparison. This says compare a_1 versus</span> <span m="501000">a_2. If a_1 is smaller than a_2 you</span> <span m="504000">go this way, if it is bigger than a_2 you go this way,</span> <span m="507000">and then you proceed. When you get down to a leaf,</span> <span m="512000">this is the answer. Remember, the sorting problem</span> <span m="516000">is you're trying to find a permutation of the inputs that</span> <span m="521000">puts it in sorted order. Let's try it with some sequence</span> <span m="525000">of numbers, say 9, 4 and 6.</span> </p>
<p><span m="528000">We want to sort 9, 4 and 6, so first we compare</span> <span m="531000">the first element with the second element.</span> </p>
<p><span m="535000">9 is bigger than 4 so we go down this way.</span> </p>
<p><span m="540000">Then we compare the first element with the third element,</span> <span m="543000">that's 9 versus 6. 9 is bigger than 6,</span> <span m="545000">so we go this way. And then we compare the second</span> <span m="548000">element with the third element, 4 is less than 6 and,</span> <span m="551000">so we go this way. And the claim is that this is</span> <span m="554000">the correct permutation of the elements.</span> </p>
<p><span m="556000">You take a_2, which is 4, then you take a_3,</span> <span m="559000">which is 6, and then you take a_1, which is 9,</span> <span m="562000">so indeed that works out. And if I wrote this down right,</span> <span m="565000">this is a sorting algorithm in the decision tree model.</span> </p>
<p><span m="570000">In general, let me just say the rules of this game.</span> </p>
<p><span m="576000">In general, we have n elements we want to sort.</span> </p>
<p><span m="583000">And I only drew the n = 3 case because these trees get very big</span> <span m="592000">very quickly. Each internal node,</span> <span m="596000">so every non-leaf node, has a label of the form i :</span> <span m="603000">j where i and j are between 1 and n.</span> </p>
<p><span m="615000">And this means that we compare a_i with a_j.</span> </p>
<p><span m="629000">And we have two subtrees from every such node.</span> </p>
<p><span m="633000">We have the left subtree which tells you what the algorithm</span> <span m="640000">does, what subsequent comparisons it makes if it comes</span> <span m="645000">out less than.</span> </p>
<p><span m="654000">And we have to be a little bit careful because it could also</span> <span m="657000">come out equal. What we will do is the left</span> <span m="659000">subtree corresponds to less than or equal to and the right</span> <span m="663000">subtree corresponds to strictly greater than.</span> </p>
<p><span m="677000">That is a little bit more precise than what we were doing</span> <span m="681000">here. Here all the elements were</span> <span m="683000">distinct so no problem. But, in general,</span> <span m="686000">we care about the equality case too to be general.</span> </p>
<p><span m="690000">So, that was the internal nodes.</span> </p>
<p><span m="692000">And then each leaf node gives you a permutation.</span> </p>
<p><span m="704000">So, in order to be the answer to that sorting problem,</span> <span m="707000">that permutation better have the property that it orders the</span> <span m="712000">elements. This is from the first lecture</span> <span m="714000">when we defined the sorting problem.</span> </p>
<p><span m="718000">Some permutation on n things such that a_pi(1) is less than</span> <span m="725000">or equal to a_pi(2) and so on.</span> </p>
<p><span m="735000">So, that is the definition of a decision tree.</span> </p>
<p><span m="738000">Any binary tree with these kinds of labels satisfies all</span> <span m="741000">these properties. That is, in some sense,</span> <span m="744000">a sorting algorithm. It's a sorting algorithm in the</span> <span m="748000">decision tree model. Now, as you might expect,</span> <span m="751000">this is really not too different than the comparison</span> <span m="755000">model. If I give you a comparison</span> <span m="757000">sorting algorithm, we have these four,</span> <span m="760000">quicksort, heapsort, merge sort and insertion sort.</span> </p>
<p><span m="764000">All of them can be translated into the decision tree model.</span> </p>
<p><span m="768000">It's sort of a graphical representation of what the</span> <span m="772000">algorithm does. It's not a terribly useful one</span> <span m="775000">for writing down an algorithm. Any guesses why?</span> </p>
<p><span m="780000">Why do we not draw these pictures as a definition of</span> <span m="783000">quicksort or a definition of merge sort?</span> </p>
<p><span m="786000">It depends on the size of the input, that's a good point.</span> </p>
<p><span m="789000">This tree is specific to the value of n, so it is,</span> <span m="793000">in some sense, not as generic.</span> </p>
<p><span m="795000">Now, we could try to write down a construction for an arbitrary</span> <span m="799000">value of n of one of these decision trees and that would</span> <span m="802000">give us sort of a real algorithm that works for any input size.</span> </p>
<p><span m="808000">But even then this is not a terribly convenient</span> <span m="811000">representation for writing down an algorithm.</span> </p>
<p><span m="814000">Well, let's write down a transformation that converts a</span> <span m="818000">comparison sorting algorithm to a decision tree and then maybe</span> <span m="822000">you will see why. This is not a useless model,</span> <span m="825000">obviously, I wouldn't be telling you otherwise.</span> </p>
<p><span m="828000">It will be very powerful for proving that we cannot do better</span> <span m="832000">than n lg n, but as writing down an algorithm,</span> <span m="836000">if you were going to implement something, this tree is not so</span> <span m="840000">useful. Even if you had a decision tree</span> <span m="845000">computer, whatever that is. But let's prove this theorem</span> <span m="850000">that decision trees, in some sense,</span> <span m="854000">model comparison sorting algorithms, which we call just</span> <span m="859000">comparison sorts.</span> </p>
<p><span m="869000">This is a transformation. And we're going to build one</span> <span m="873000">tree for each value of n. The decision trees depend on n.</span> </p>
<p><span m="878000">The algorithm hopefully, well, it depends on n,</span> <span m="883000">but it works for all values of n.</span> </p>
<p><span m="886000">And we're just going to think of the algorithm as splitting</span> <span m="891000">into two forks, the left subtree and the right</span> <span m="895000">subtree whenever it makes a comparison.</span> </p>
<p><span m="907000">If we take a comparison sort like merge sort.</span> </p>
<p><span m="909000">And it does lots of stuff. It does index arithmetic,</span> <span m="912000">it does recursion, whatever.</span> </p>
<p><span m="914000">But at some point it makes a comparison and then we say,</span> <span m="918000">OK, there are two halves of the algorithm.</span> </p>
<p><span m="920000">There is what the algorithm would do if the comparison came</span> <span m="924000">out less than or equal to and what the algorithm would do if</span> <span m="927000">the comparison came out greater than.</span> </p>
<p><span m="931000">So, you can build a tree in this way.</span> </p>
<p><span m="933000">In some sense, what this tree is doing is</span> <span m="937000">listing all possible executions of this algorithm considering</span> <span m="942000">what would happen for all possible values of those</span> <span m="946000">comparisons.</span> </p>
<p><span m="959000">We will call these all possible instruction traces.</span> </p>
<p><span m="963000">If you write down all the instructions that are executed</span> <span m="969000">by this algorithm, for all possible input arrays,</span> <span m="973000">a_1 to a_n, see what all the comparisons, how they could come</span> <span m="979000">and what the algorithm does, in the end you will get a tree.</span> </p>
<p><span m="985000">Now, how big will that tree be roughly?</span> </p>
<p><span m="1003000">As a function of n. Yeah?</span> </p>
<p><span m="1015000">Right. If it's got to be able to sort</span> <span m="1017000">every possible list of length n, at the leaves I have to have</span> <span m="1021000">all the permutations of those elements.</span> </p>
<p><span m="1025000">That is a lot. There are a lot of permeations</span> <span m="1027000">on n elements. There's n factorial of them.</span> </p>
<p><span m="1030000">N factorial is exponential, it's really big.</span> </p>
<p><span m="1033000">So, this tree is huge. It's going to be exponential on</span> <span m="1037000">the input size n. That is why we don't write</span> <span m="1039000">algorithms down normally as a decision tree,</span> <span m="1042000">even though in some cases maybe we could.</span> </p>
<p><span m="1045000">It's not a very compact representation.</span> </p>
<p><span m="1049000">These algorithms, you write them down in</span> <span m="1051000">pseudocode, they have constant length.</span> </p>
<p><span m="1053000">It's a very succinct representation of this</span> <span m="1055000">algorithm. Here the length depends on n</span> <span m="1058000">and it depends exponentially on n, which is not useful if you</span> <span m="1061000">wanted to implement the algorithm because writing down</span> <span m="1064000">the algorithm would take a long time.</span> </p>
<p><span m="1066000">But, nonetheless, we can use this as a tool to</span> <span m="1069000">analyze these comparison sorting algorithms.</span> </p>
<p><span m="1071000">We have all of these. Any algorithm can be</span> <span m="1074000">transformed in this way into a decision tree.</span> </p>
<p><span m="1078000">And now we have this observation that the number of</span> <span m="1083000">leaves in this decision tree has to be really big.</span> </p>
<p><span m="1088000">Let me talk about leaves in a second.</span> </p>
<p><span m="1092000">Before we get to leaves, let's talk about the depth of</span> <span m="1098000">the tree.</span> </p>
<p><span m="1106000">This decision tree represents all possible executions of the</span> <span m="1109000">algorithm. If I look at a particular</span> <span m="1111000">execution, which corresponds to some root to leaf path in the</span> <span m="1115000">tree, the running time or the number of comparisons made by</span> <span m="1118000">that execution is just the length of the path.</span> </p>
<p><span m="1127000">And, therefore, the worst-case running time,</span> <span m="1132000">over all possible inputs of length n, is going to be --</span> <span m="1145000">n - 1? Could be.</span> </p>
<p><span m="1146000">Depends on the decision tree. But, as a function of the</span> <span m="1151000">decision tree? The longest path,</span> <span m="1154000">right, which is called the height of the tree.</span> </p>
<p><span m="1164000">So, this is what we want to measure.</span> </p>
<p><span m="1166000">We want to claim that the height of the tree has to be at</span> <span m="1169000">least n lg n with an omega in front.</span> </p>
<p><span m="1172000">That is what we'll prove.</span> </p>
<p><span m="1182000">And the only thing we're going to use is that the number of</span> <span m="1184000">leaves in that tree has to be big, has to be n factorial.</span> </p>
<p><span m="1200000">This is a lower bound on decision tree sorting.</span> </p>
<p><span m="1221000">And the lower bound says that if you have any decision tree</span> <span m="1226000">that sorts n elements then its height has to be at least n lg n</span> <span m="1232000">up to constant factors.</span> </p>
<p><span m="1245000">So, that is the theorem. Now we're going to prove the</span> <span m="1252000">theorem. And we're going to use that the</span> <span m="1257000">number of leaves in that tree must be at least n factorial.</span> </p>
<p><span m="1266000">Because there are n factorial permutations of the inputs.</span> </p>
<p><span m="1270000">All of them could happen. And so, for this algorithm to</span> <span m="1274000">be correct, it has detect every one of those permutations in</span> <span m="1279000">some way. Now, it may do it very quickly.</span> </p>
<p><span m="1282000">We better only need n lg n comparisons because we know</span> <span m="1286000">that's possible. The depth of the tree may not</span> <span m="1291000">be too big, but it has to have a huge number of leaves down</span> <span m="1295000">there. It has to branch enough to get</span> <span m="1297000">n factorial leaves because it has to give the right answer in</span> <span m="1302000">possible inputs. This is, in some sense,</span> <span m="1305000">counting the number of possible inputs that we have to</span> <span m="1309000">distinguish. This is the number of leaves.</span> </p>
<p><span m="1312000">What we care about is the height of the tree.</span> </p>
<p><span m="1315000">Let's call the height of the tree h.</span> </p>
<p><span m="1319000">Now, if I have a tree of height h, how many leaves could it</span> <span m="1322000">have? What's the maximum number of</span> <span m="1324000">leaves it could have?</span> </p>
<p><span m="1339000">2^h, exactly. Because this is binary tree,</span> <span m="1343000">comparison trees always have a branching factor of 2,</span> <span m="1349000">the number of leaves has to be at most 2^h, if I have a height</span> <span m="1355000">h tree. Now, this gives me a relation.</span> </p>
<p><span m="1358000">The number of leaves has to be greater than or equal to n</span> <span m="1361000">factorial and the number of leaves has to be less than or</span> <span m="1364000">equal to 2^h. Therefore, n factorial is less</span> <span m="1367000">than or equal to 2^h, if I got that right.</span> </p>
<p><span m="1378000">Now, again, we care about h in terms of n factorial,</span> <span m="1382000">so we solve this by taking logs.</span> </p>
<p><span m="1384000">And I am also going to flip sides.</span> </p>
<p><span m="1387000">Now h is at least log base 2, because there is a 2 over here,</span> <span m="1392000">of n factorial. There is a property that I'm</span> <span m="1395000">using here in order to derive this inequality from this</span> <span m="1400000">inequality. This is a technical aside,</span> <span m="1403000">but it's important that you realize there is a technical</span> <span m="1407000">issue here.</span> </p>
<p><span m="1420000">The general principle I'm applying is I have some</span> <span m="1423000">inequality, I do the same thing to both sides,</span> <span m="1426000">and hopefully that inequality should still be true.</span> </p>
<p><span m="1429000">But, in order for that to be the case, I need a property</span> <span m="1433000">about that operation that I'm performing.</span> </p>
<p><span m="1436000">It has to be a monotonic transformation.</span> </p>
<p><span m="1440000">Here what I'm using is that log is a monotonically increasing</span> <span m="1444000">function. That is important.</span> </p>
<p><span m="1446000">If I multiply both sides by -1, which is a decreasing function,</span> <span m="1451000">the inequality would have to get flipped.</span> </p>
<p><span m="1454000">The fact that the inequality is not flipping here,</span> <span m="1458000">I need to know that log is monotonically increasing.</span> </p>
<p><span m="1461000">If you see log that's true. We need to be careful here.</span> </p>
<p><span m="1467000">Now we need some approximation of n factorial in order to</span> <span m="1471000">figure out what its log is. Does anyone know a good</span> <span m="1476000">approximation for n factorial? Not necessarily the equation</span> <span m="1481000">but the name. Stirling's formula.</span> </p>
<p><span m="1484000">Good. You all remember Stirling.</span> </p>
<p><span m="1487000">And I just need the highest order term, which I believe is</span> <span m="1492000">that. N factorial is at least</span> <span m="1494000">(n/e)^n. So, that's all we need here.</span> </p>
<p><span m="1499000">Now I can use properties of logs to bring the n outside.</span> </p>
<p><span m="1506000">This is n lg (n/e).</span> </p>
<p><span m="1515000">And then lg (n/e) I can simplify.</span> </p>
<p><span m="1528000">That is just lg n - lg e. So, this is n(lg n - lg e).</span> </p>
<p><span m="1532000">Lg e is a constant, so it's really tiny compared to</span> <span m="1537000">this lg n which is growing within.</span> </p>
<p><span m="1539000">This is Omega(n lg n). All we care about is the</span> <span m="1544000">leading term. It is actually Theta(n lg n),</span> <span m="1547000">but because we have it greater than or equal to all we care</span> <span m="1552000">about is the omega. A theta here wouldn't give us</span> <span m="1557000">anything stronger. Of course, not all algorithms</span> <span m="1561000">have n lg n running time or make n lg n comparisons.</span> </p>
<p><span m="1564000">Some of them do, some of them are worse,</span> <span m="1567000">but this proves that all of them require a height of at</span> <span m="1570000">least n lg n. There you see proof,</span> <span m="1572000">once you observe the fact about the number of leaves,</span> <span m="1575000">and if you remember Stirling's formula.</span> </p>
<p><span m="1578000">So, you should know this proof. You can show that all sorts of</span> <span m="1582000">problems require n lg n time with this kind of technique,</span> <span m="1585000">provided you're in some kind of a decision tree model.</span> </p>
<p><span m="1590000">That's important. We really need that our</span> <span m="1592000">algorithm can be phrased as a decision tree.</span> </p>
<p><span m="1595000">And, in particular, we know from this</span> <span m="1597000">transformation that all comparison sorts can be</span> <span m="1600000">represented as the decision tree.</span> </p>
<p><span m="1602000">But there are some sorting algorithms which cannot be</span> <span m="1605000">represented as a decision tree. And we will turn to that</span> <span m="1608000">momentarily. But before we get there I</span> <span m="1611000">phrased this theorem as a lower bound on decision tree sorting.</span> </p>
<p><span m="1614000">But, of course, we also get a lower bound on</span> <span m="1617000">comparison sorting. And, in particular,</span> <span m="1622000">it tells us that merge sort and heapsort are asymptotically</span> <span m="1628000">optimal. Their dependence on n,</span> <span m="1631000">in terms of asymptotic notation, so ignoring constant</span> <span m="1637000">factors, these algorithms are optimal in terms of growth of n,</span> <span m="1644000">but this is only in the comparison model.</span> </p>
<p><span m="1650000">So, among comparison sorting algorithms, which these are,</span> <span m="1653000">they are asymptotically optimal.</span> </p>
<p><span m="1655000">They use the minimum number of comparisons up to constant</span> <span m="1659000">factors. In fact, their whole running</span> <span m="1661000">time is dominated by the number of comparisons.</span> </p>
<p><span m="1664000">It's all Theta(n lg n). So, this is good news.</span> </p>
<p><span m="1667000">And I should probably mention a little bit about what happens</span> <span m="1671000">with randomized algorithms. What I've described here really</span> <span m="1675000">only applies, in some sense,</span> <span m="1677000">to deterministic algorithms. Does anyone see what would</span> <span m="1682000">change with randomized algorithms or where I've assumed</span> <span m="1686000">that I've had a deterministic comparison sort?</span> </p>
<p><span m="1689000">This is a bit subtle. And I only noticed it reading</span> <span m="1693000">the notes this morning, oh, wait.</span> </p>
<p><span m="1708000">I will give you a hint. It's over here,</span> <span m="1710000">the right-hand side of the world.</span> </p>
<p><span m="1730000">If I have a deterministic algorithm, what the algorithm</span> <span m="1735000">does is completely determinate at each step.</span> </p>
<p><span m="1740000">As long as I know all the comparisons that it made up to</span> <span m="1745000">some point, it's determinate what that algorithm will do.</span> </p>
<p><span m="1751000">But, if I have a randomized algorithm, it also depends on</span> <span m="1757000">the outcomes of some coin flips. Any suggestions of what breaks</span> <span m="1764000">over here? There is more than one tree,</span> <span m="1768000">exactly. So, we had this assumption that</span> <span m="1771000">we only have one tree for each n.</span> </p>
<p><span m="1773000">In fact, what we get is a probability distribution over</span> <span m="1776000">trees. For each value of n,</span> <span m="1778000">if you take all the possible executions of that algorithm,</span> <span m="1781000">all the instruction traces, well, now, in addition to</span> <span m="1784000">branching on comparisons, we also branch on whether a</span> <span m="1787000">coin flip came out heads or tails, or however we're</span> <span m="1790000">generating random numbers it came out with some value between</span> <span m="1793000">1 and n. So, we get a probability</span> <span m="1795000">distribution over trees. This lower bound still applies,</span> <span m="1798000">though. Because, no matter what tree we</span> <span m="1802000">get, I don't really care. I get at least one tree for</span> <span m="1805000">each n. And this proof applies to every</span> <span m="1808000">tree. So, no matter what tree you</span> <span m="1810000">get, if it is a correct tree it has to have height Omega(n lg</span> <span m="1815000">n). This lower bound applies even</span> <span m="1817000">for randomized algorithms. You cannot get better than n lg</span> <span m="1821000">n, because no matter what tree it comes up with,</span> <span m="1824000">no matter how those coin flips come out, this argument still</span> <span m="1829000">applies. Every tree that comes out has</span> <span m="1833000">to be correct, so this is really at least one</span> <span m="1837000">tree.</span> </p>
<p><span m="1843000">And that will now work. We also get the fact that</span> <span m="1847000">randomized quicksort is asymptotically optimal in</span> <span m="1852000">expectation.</span> </p>
<p><span m="1865000">But, in order to say that randomized quicksort is</span> <span m="1869000">asymptotically optimal, we need to know that all</span> <span m="1873000">randomized algorithms require Omega(n lg n) comparisons.</span> </p>
<p><span m="1879000">Now we know that so all is well.</span> </p>
<p><span m="1882000">That is the comparison model. Any questions before we go on?</span> </p>
<p><span m="1887000">Good. The next topic is to burst</span> <span m="1891000">outside of the comparison model and try to sort in linear time.</span> </p>
<p><span m="1903000">It is pretty clear that, as long as you don't have some</span> <span m="1905000">kind of a parallel algorithm or something really fancy,</span> <span m="1908000">you cannot sort any better than linear time because you've at</span> <span m="1911000">least got to look at the data. No matter what you're doing</span> <span m="1914000">with the data, you've got to look at it,</span> <span m="1916000">otherwise you're not sorting it correctly.</span> </p>
<p><span m="1919000">So, linear time is the best we could hope for.</span> </p>
<p><span m="1921000">N lg n is pretty close. How could we sort in linear</span> <span m="1925000">time? Well, we're going to need some</span> <span m="1927000">more powerful assumption. And this is the counter</span> <span m="1930000">example. We're going to have to move</span> <span m="1932000">outside the comparison model and do something else with our</span> <span m="1936000">elements. And what we're going to do is</span> <span m="1938000">assume that they're integers in a particular range,</span> <span m="1941000">and we will use that to sort in linear time.</span> </p>
<p><span m="1944000">We're going to see two algorithms for sorting faster</span> <span m="1947000">than n lg n. The first one is pretty simple,</span> <span m="1952000">and we will use it in the second algorithm.</span> </p>
<p><span m="1955000">It's called counting sort. The input to counting sort is</span> <span m="1960000">an array, as usual, but we're going to assume what</span> <span m="1964000">those array elements look like. Each A[i] is an integer from</span> <span m="1969000">the range of 1 to k. This is a pretty strong</span> <span m="1972000">assumption. And the running time is</span> <span m="1975000">actually going to depend on k. If k is small it is going to be</span> <span m="1981000">a good algorithm. If k is big it's going to be a</span> <span m="1986000">really bad algorithm, worse than n lg n.</span> </p>
<p><span m="1990000">Our goal is to output some sorted version of this array.</span> </p>
<p><span m="1995000">Let's call this sorting of A. It's going to be easier to</span> <span m="2000000">write down the output directly instead of writing down</span> <span m="2005000">permutation for this algorithm. And then we have some auxiliary</span> <span m="2012000">storage. I'm about to write down the</span> <span m="2016000">pseudocode, which is why I'm declaring all my variables here.</span> </p>
<p><span m="2021000">And the auxiliary storage will have length k,</span> <span m="2025000">which is the range on my input values.</span> </p>
<p><span m="2028000">Let's see the algorithm.</span> </p>
<p><span m="2047000">This is counting sort.</span> </p>
<p><span m="2057000">And it takes a little while to write down but it's pretty</span> <span m="2060000">straightforward.</span> </p>
<p><span m="2068000">First we do some initialization.</span> </p>
<p><span m="2072000">Then we do some counting.</span> </p>
<p><span m="2104000">Then we do some summing.</span> </p>
<p><span m="2150000">And then we actually write the output.</span> </p>
<p><span m="2188000">Is that algorithm perfectly clear to everyone?</span> </p>
<p><span m="2190000">No one. Good. This should illustrate how obscure pseudocode can be.</span> </p>
<p><span m="2193000">And when you're solving your problem sets,</span> <span m="2196000">you should keep in mind that it's really hard to understand</span> <span m="2199000">an algorithm just given pseudocode like this.</span> </p>
<p><span m="2201000">You need some kind of English description of what's going on</span> <span m="2205000">because, while you could work through and figure out what this</span> <span m="2208000">means, it could take half an hour to an hour.</span> </p>
<p><span m="2211000">And that's not a good way of expressing yourself.</span> </p>
<p><span m="2213000">And so what I will give you now is the English description,</span> <span m="2217000">but we will refer back to this to understand.</span> </p>
<p><span m="2221000">This is sort of our bible of what the algorithm is supposed</span> <span m="2225000">to do. Let me go over it briefly.</span> </p>
<p><span m="2227000">The first step is just some initialization.</span> </p>
<p><span m="2231000">The C[i]'s are going to count some things, count occurrences</span> <span m="2235000">of values. And so first we set them to</span> <span m="2238000">zero. Then, for every value we see</span> <span m="2240000">A[j], we're going to increment the counter for that value A[j].</span> </p>
<p><span m="2245000">Then the C[i]s will give me the number of elements equal to a</span> <span m="2250000">particular value i. Then I'm going to take prefix</span> <span m="2255000">sums, which will make it so that C[i] gives me the number of</span> <span m="2259000">keys, the number of elements less than or equal to [i]</span> <span m="2262000">instead of equals. And then, finally,</span> <span m="2265000">it turns out that's enough to put all the elements in the</span> <span m="2269000">right place. This I will call distribution.</span> </p>
<p><span m="2272000">This is the distribution step. And it's probably the least</span> <span m="2276000">obvious of all the steps. And let's do an example to make</span> <span m="2281000">it more obvious what's going on.</span> </p>
<p><span m="2292000">Let's take an array A = [4, 1, 3, 4, 3].</span> </p>
<p><span m="2310000">And then I want some array C. And let me add some indices</span> <span m="2316000">here so we can see what the algorithm is really doing.</span> </p>
<p><span m="2323000">Here it turns out that all of my numbers are in the range 1 to</span> <span m="2330000">4, so k = 4. My array C has four values.</span> </p>
<p><span m="2334000">Initially, I set them all to zero.</span> </p>
<p><span m="2340000">That's easy. And now I want to count through</span> <span m="2343000">everything. And let me not cheat here.</span> </p>
<p><span m="2347000">I'm in the second step, so to speak.</span> </p>
<p><span m="2350000">And I look for each element in order.</span> </p>
<p><span m="2353000">I look at the C[i] value. The first element is 4,</span> <span m="2357000">so I look at C4. That is 0.</span> </p>
<p><span m="2360000">I increment it to 1. Then I look at element 1.</span> </p>
<p><span m="2364000">That's 0. I increment it to 1.</span> </p>
<p><span m="2368000">Then I look at 3 and that's here.</span> </p>
<p><span m="2370000">It is also 0. I increment it to 1.</span> </p>
<p><span m="2373000">Not so exciting so far. Now I see 4,</span> <span m="2377000">which I've seen before, how exciting.</span> </p>
<p><span m="2380000">I had value 1 in here, I increment it to 2.</span> </p>
<p><span m="2384000">Then I see value 3, which also had a value of 1.</span> </p>
<p><span m="2388000">I increment that to 2. The result is [1,</span> <span m="2391000">0, 2, 2]. That's what my array C looks</span> <span m="2395000">like at this point in the algorithm.</span> </p>
<p><span m="2400000">Now I do a relatively simple transformation of taking prefix</span> <span m="2404000">sums. I want to know,</span> <span m="2405000">instead of these individual values, the sum of this prefix,</span> <span m="2409000">the sum of this prefix, the sum of this prefix and the</span> <span m="2413000">sum of this prefix. I will call that C prime just</span> <span m="2417000">so we don't get too lost in all these different versions of C.</span> </p>
<p><span m="2421000">This is just 1. And 1 plus 0 is 1.</span> </p>
<p><span m="2423000">1 plus 2 is 3. 3 plus 2 is 5.</span> </p>
<p><span m="2425000">So, these are sort of the running totals.</span> </p>
<p><span m="2430000">There are five elements total, there are three elements less</span> <span m="2433000">than or equal to 3, there is one element less than</span> <span m="2437000">or equal to 2, and so on.</span> </p>
<p><span m="2438000">Now, the fun part, the distribution.</span> </p>
<p><span m="2440000">And this is where we get our array B.</span> </p>
<p><span m="2443000">B better have the same size, every element better appear</span> <span m="2446000">here somewhere and they should come out in sorted order.</span> </p>
<p><span m="2450000">Let's just run the algorithm. j is going to start at the end</span> <span m="2454000">of the array and work its way down to 1, the beginning of the</span> <span m="2458000">array. And what we do is we pick up</span> <span m="2462000">the last element of A, A[n].</span> </p>
<p><span m="2465000">We look at the counter. We look at the C vector for</span> <span m="2471000">that value. Here the value is 3,</span> <span m="2474000">and this is the third column, so that has number 3.</span> </p>
<p><span m="2479000">And the claim is that's where it belongs in B.</span> </p>
<p><span m="2484000">You take this number 3, you put it in index 3 of the</span> <span m="2489000">array B. And then you decrement the</span> <span m="2494000">counter. I'm going to replace 3 here</span> <span m="2497000">with 2. And the idea is these numbers</span> <span m="2500000">tell you where those values should go.</span> </p>
<p><span m="2504000">Anything of value 1 should go at position 1.</span> </p>
<p><span m="2508000">Anything with value 3 should go at position 3 or less.</span> </p>
<p><span m="2513000">This is going to be the last place that a 3 should go.</span> </p>
<p><span m="2519000">And then anything with value 4 should go at position 5 or less,</span> <span m="2522000">definitely should go at the end of the array because 4 is the</span> <span m="2526000">largest value. And this counter will work out</span> <span m="2529000">perfectly because these counts have left enough space in each</span> <span m="2533000">section of the array. Effectively,</span> <span m="2535000">this part is reserved for ones, there are no twos,</span> <span m="2538000">this part is reserved for threes, and this part is</span> <span m="2541000">reserved for fours. You can check if that's really</span> <span m="2544000">what this array means. Let's finish running the</span> <span m="2547000">algorithm. That was the last element.</span> </p>
<p><span m="2551000">I won't cross it off, but we've sort of done that.</span> </p>
<p><span m="2554000">Now I look at the next to last element.</span> </p>
<p><span m="2556000">That's a 4. Fours go in position 5.</span> </p>
<p><span m="2558000">So, I put my 4 here in position 5 and I decrement that counter.</span> </p>
<p><span m="2562000">Next I look at another 3. Threes now go in position 2,</span> <span m="2565000">so that goes there. And then I decrement that</span> <span m="2568000">counter. I won't actually use that</span> <span m="2570000">counter anymore, but let's decrement it because</span> <span m="2573000">that's what the algorithm says. I look at the previous element.</span> </p>
<p><span m="2577000">That's a 1. Ones go in position 1,</span> <span m="2580000">so I put it here and decrement that counter.</span> </p>
<p><span m="2584000">And finally I have another 4. And fours go in position 4 now,</span> <span m="2589000">position 4 is here, and I decrement that counter.</span> </p>
<p><span m="2593000">So, that's counting sort. And you'll notice that all the</span> <span m="2598000">elements appear and they appear in order, so that's the</span> <span m="2603000">algorithm. Now, what's the running time of</span> <span m="2606000">counting sort? kn is an upper bound.</span> </p>
<p><span m="2611000">It's a little bit better than that.</span> </p>
<p><span m="2615000">Actually, quite a bit better. This requires some summing.</span> </p>
<p><span m="2623000">Let's go back to the top of the algorithm.</span> </p>
<p><span m="2629000">How much time does this step take?</span> </p>
<p><span m="2633000">k. How much time does this step</span> <span m="2637000">take? n.</span> </p>
<p><span m="2640000">How much time does this step take?</span> </p>
<p><span m="2645000">k. Each of these operations in the</span> <span m="2650000">for loops is taking constant time, so it is how many</span> <span m="2657000">iterations of that for loop are there?</span> </p>
<p><span m="2662000">And, finally, this step takes n.</span> </p>
<p><span m="2669000">So, the total running time of counting sort is k + n.</span> </p>
<p><span m="2675000">And this is a great algorithm if k is relatively small,</span> <span m="2683000">like at most n. If k is big like n^2 or 2^n or</span> <span m="2689000">whatever, this is not such a good algorithm,</span> <span m="2694000">but if k = O(n) this is great. And we get our linear time</span> <span m="2701000">sorting algorithm. Not only do we need the</span> <span m="2704000">assumption that our numbers are integers, but we need that the</span> <span m="2708000">range of the integers is pretty small for this algorithm to</span> <span m="2712000">work. If all the numbers are between</span> <span m="2714000">1 and order n then we get a linear time algorithm.</span> </p>
<p><span m="2717000">But as soon as they're up to n lg n we're toast.</span> </p>
<p><span m="2720000">We're back to n lg n sorting. It's not so great.</span> </p>
<p><span m="2724000">So, you could write a combination algorithm that says,</span> <span m="2727000">well, if k is bigger than n lg n, then I will just use merge</span> <span m="2731000">sort. And if it's less than n lg n</span> <span m="2735000">I'll use counting sort. And that would work,</span> <span m="2738000">but we can do better than that. How's the time?</span> </p>
<p><span m="2742000">It is worth noting that we've beaten our bound,</span> <span m="2746000">but only assuming that we're outside the comparison model.</span> </p>
<p><span m="2751000">We haven't really contradicted the original theorem,</span> <span m="2755000">we're just changing the model. And it's always good to</span> <span m="2760000">question what you're allowed to do in any problem scenario.</span> </p>
<p><span m="2764000">In, say, some practical scenarios, this would be great</span> <span m="2767000">if the numbers you're dealing with are, say,</span> <span m="2770000">a byte long. Then k is only 2^8,</span> <span m="2772000">which is 256. You need this auxiliary array</span> <span m="2775000">of size 256, and this is really fast.</span> </p>
<p><span m="2777000">256 + n, no matter how big n is it's linear in n.</span> </p>
<p><span m="2781000">If you know your numbers are small, it's great.</span> </p>
<p><span m="2784000">But if you're numbers are bigger, say you still know</span> <span m="2787000">they're integers but they fit in like 32 bit words,</span> <span m="2790000">then life is not so easy. Because k is then 2^32,</span> <span m="2795000">which is 4.2 billion or so, which is pretty big.</span> </p>
<p><span m="2799000">And you would need this auxiliary array of 4.2 billion</span> <span m="2803000">words, which is probably like 16 gigabytes.</span> </p>
<p><span m="2806000">So, you just need to initialize that array before you can even</span> <span m="2811000">get started. Unless n is like much,</span> <span m="2814000">much more than 4 billion and you have 16 gigabytes of storage</span> <span m="2818000">just to throw away, which I don't even have any</span> <span m="2822000">machines with 16 gigabytes of RAM, this is not such a great</span> <span m="2826000">algorithm. Just to get a feel,</span> <span m="2830000">it's good, the numbers are really small.</span> </p>
<p><span m="2833000">What we're going to do next is come up with a fancier algorithm</span> <span m="2838000">that uses this as a subroutine on small numbers and combines</span> <span m="2842000">this algorithm to handle larger numbers.</span> </p>
<p><span m="2845000">That algorithm is called radix sort.</span> </p>
<p><span m="2849000">But we need one important property of counting sort before</span> <span m="2854000">we can go there.</span> </p>
<p><span m="2862000">And that important property is stability.</span> </p>
<p><span m="2870000">A stable sorting algorithm preserves the order of equal</span> <span m="2878000">elements, let's say the relative order.</span> </p>
<p><span m="2899000">This is a bit subtle because usually we think of elements</span> <span m="2901000">just as numbers. And, yeah, we had a couple</span> <span m="2904000">threes and we had a couple fours.</span> </p>
<p><span m="2905000">It turns out, if you look at the order of</span> <span m="2908000">those threes and the order of those fours, we kept them in</span> <span m="2911000">order. Because we took the last three</span> <span m="2913000">and we put it here. Then we took the next to the</span> <span m="2916000">last three and we put it to the left of that where O is</span> <span m="2919000">decrementing our counter and moving from the end of the array</span> <span m="2922000">to the beginning of the array. No matter how we do that,</span> <span m="2925000">the orders of those threes are preserved, the orders of the</span> <span m="2929000">fours are preserved. This may seem like a relatively</span> <span m="2931000">simple thing, but if you look at the other</span> <span m="2934000">four sorting algorithms we've seen, not all of them are</span> <span m="2937000">stable. So, this is an exercise.</span> </p>
<p><span m="2946000">Exercise is figure out which other sorting algorithms that</span> <span m="2951000">we've seen are stable and which are not.</span> </p>
<p><span m="2961000">I encourage you to work that out because this is the sort of</span> <span m="2965000">thing that we ask on quizzes. But for now all we need is that</span> <span m="2969000">counting sort is stable. And I won't prove this,</span> <span m="2973000">but it should be pretty obvious from the algorithm.</span> </p>
<p><span m="2977000">Now we get to talk about radix sort.</span> </p>
<p><span m="2995000">Radix sort is going to work for a much larger range of numbers</span> <span m="3001000">in linear time. Still it has to have an</span> <span m="3004000">assumption about how big those numbers are, but it will be a</span> <span m="3009000">much more lax assumption. Now, to increase suspense even</span> <span m="3013000">further, I am going to tell you some history about radix sort.</span> </p>
<p><span m="3018000">This is one of the oldest sorting algorithms.</span> </p>
<p><span m="3022000">It's probably the oldest implemented sorting algorithm.</span> </p>
<p><span m="3026000">It was implemented around 1890. This is Herman Hollerith.</span> </p>
<p><span m="3032000">Let's say around 1890. Has anyone heard of Hollerith</span> <span m="3035000">before? A couple people.</span> </p>
<p><span m="3037000">Not too many. He is sort of an important guy.</span> </p>
<p><span m="3041000">He was a lecturer at MIT at some point.</span> </p>
<p><span m="3043000">He developed an early version of punch cards.</span> </p>
<p><span m="3047000">Punch card technology. This is before my time so I</span> <span m="3051000">even have to look at my notes to remember.</span> </p>
<p><span m="3054000">Oh, yeah, they're called punch cards.</span> </p>
<p><span m="3057000">You may have seen them. If not they're in the</span> <span m="3062000">PowerPoint lecture notes. There's this big grid.</span> </p>
<p><span m="3066000">These days, if you've used a modern punch card recently,</span> <span m="3071000">they are 80 characters wide and, I don't know,</span> <span m="3076000">I think it's something like 16, I don't remember exactly.</span> </p>
<p><span m="3081000">And then you punch little holes here.</span> </p>
<p><span m="3085000">You have this magic machine. It's like a typewriter.</span> </p>
<p><span m="3090000">You press a letter and that corresponds to some character.</span> </p>
<p><span m="3094000">Maybe it will punch out a hole here, punch out a hole here.</span> </p>
<p><span m="3098000">You can see the website if you want to know exactly how this</span> <span m="3102000">works for historical reasons. You don't see these too often</span> <span m="3106000">anymore, but this is in particular the reason why most</span> <span m="3109000">terminals are 80 characters wide because that was how things</span> <span m="3113000">were. Hollerith actually didn't</span> <span m="3115000">develop these punch cards exactly, although eventually he</span> <span m="3119000">did. In the beginning,</span> <span m="3121000">in 1890, the big deal was the US Census.</span> </p>
<p><span m="3124000">If you watched the news, I guess like a year or two ago,</span> <span m="3127000">the US Census was a big deal because it's really expensive to</span> <span m="3130000">collect all this data from everyone.</span> </p>
<p><span m="3132000">And the Constitution says you've got to collect data about</span> <span m="3135000">everyone every ten years. And it was getting hard.</span> </p>
<p><span m="3138000">In particular, in 1880, they did the census.</span> </p>
<p><span m="3140000">And it took them almost ten years to complete the census.</span> </p>
<p><span m="3144000">The population kept going up, and ten years to do a ten-year</span> <span m="3147000">census, that's going to start getting expensive when they</span> <span m="3150000">overlap with each other. So, for 1890 they wanted to do</span> <span m="3154000">something fancier. And Hollerith said,</span> <span m="3157000">OK, I'm going to build a machine that you take in the</span> <span m="3160000">data. It was a modified punch card</span> <span m="3162000">where you would mark out particular squares depending on</span> <span m="3166000">your status, whether you were single or married or whatever.</span> </p>
<p><span m="3170000">All the things they wanted to know on the census they would</span> <span m="3173000">encode in binary onto this card. And then he built a machine</span> <span m="3177000">that would sort these cards so you could do counting.</span> </p>
<p><span m="3182000">And, in some sense, these are numbers.</span> </p>
<p><span m="3185000">And the numbers aren't too big, but they're big enough that</span> <span m="3190000">counting sort wouldn't work. I mean if there were a hundred</span> <span m="3195000">numbers here, 2^100 is pretty overwhelming,</span> <span m="3198000">so we cannot use counting sort. The first idea was the wrong</span> <span m="3204000">idea. I'm going to think of these as</span> <span m="3207000">numbers. Let's say each of these columns</span> <span m="3210000">is one number. And so there's sort of the most</span> <span m="3214000">significant number out here and there is the least significant</span> <span m="3218000">number out here. The first idea was you sort by</span> <span m="3220000">the most significant digit first.</span> </p>
<p><span m="3230000">That's not such a great algorithm, because if you sort</span> <span m="3233000">by the most significant digit you get a bunch of buckets each</span> <span m="3238000">with a pile of cards. And this was a physical device.</span> </p>
<p><span m="3241000">It wasn't exactly an electronically controlled</span> <span m="3244000">computer. It was a human that would push</span> <span m="3246000">down some kind of reader. It would see which holes in the</span> <span m="3249000">first column are punched. And then it would open a</span> <span m="3252000">physical bin in which the person would sort of swipe it and it</span> <span m="3255000">would just fall into the right bin.</span> </p>
<p><span m="3257000">It was a semi-automated. I mean the computer was the</span> <span m="3260000">human plus the machine, but never mind.</span> </p>
<p><span m="3262000">This was the procedure. You sorted it into bins.</span> </p>
<p><span m="3265000">Then you had to go through and sort each bin by the second</span> <span m="3268000">digit. And pretty soon the number of</span> <span m="3272000">bins gets pretty big. And if you don't have too many</span> <span m="3276000">digits this is OK, but it's not the right thing to</span> <span m="3280000">do. The right idea,</span> <span m="3281000">which is what Hollerith came up with after that,</span> <span m="3285000">was to sort by the least significant digit first.</span> </p>
<p><span m="3300000">And you should also do that using a stable sorting</span> <span m="3303000">algorithm. Now, Hollerith probably didn't</span> <span m="3305000">call it a stable sorting algorithm at the time,</span> <span m="3308000">but we will. And this won Hollerith lots of</span> <span m="3311000">money and good things. He founded this tabulating</span> <span m="3314000">machine company in 1911, and that merged with several</span> <span m="3317000">other companies to form something you may have heard of</span> <span m="3321000">called IBM in 1924. That may be the context in</span> <span m="3324000">which you've heard of Hollerith, or if you've done punch cards</span> <span m="3328000">before. The whole idea is that we're</span> <span m="3332000">doing a digit by digit sort. I should have mentioned that at</span> <span m="3337000">the beginning. And we're going to do it from</span> <span m="3340000">least significant to most significant.</span> </p>
<p><span m="3343000">It turns out that works. And to see that let's do an</span> <span m="3348000">example. I think I'm going to need a</span> <span m="3350000">whole two boards ideally. First we'll see an example.</span> </p>
<p><span m="3355000">Then we'll prove the theorem. The proof is actually pretty</span> <span m="3359000">darn easy. But, nonetheless,</span> <span m="3363000">it's rather counterintuitive this works if you haven't seen</span> <span m="3367000">it before. Certainly, the first time I saw</span> <span m="3370000">it, it was quite a surprise. The nice thing also about this</span> <span m="3374000">algorithm is there are no bins. It's all one big bin at all</span> <span m="3379000">times. Let's take some numbers.</span> </p>
<p></p>
<p><span m="3383000">I'm spacing out the digits so we can see them a little bit</span> <span m="3388000">better.</span> <span m="3390000">657, 839, 436, 720 and 355.</span> </p>
<p><span m="3393000">I'm assuming here we're using decimal numbers.</span> </p>
<p><span m="3398000">Why not? Hopefully this are not yet</span> <span m="3403000">sorted. We'd like to sort them.</span> </p>
<p><span m="3407000">The first thing we do is take the least significant digit,</span> <span m="3414000">sort by the least significant digit.</span> </p>
<p><span m="3420000">And whenever we have equal elements like these two nines,</span> <span m="3424000">we preserve their relative order.</span> </p>
<p><span m="3427000">So, 329 is going to remain above 839.</span> </p>
<p><span m="3431000">It doesn't matter here because we're doing the first sort,</span> <span m="3436000">but in general we're always using a stable sorting</span> <span m="3440000">algorithm. When we sort by this column,</span> <span m="3443000">first we get the zero, so that's 720,</span> <span m="3447000">then we get 5,</span> <span m="3450000">Then we get 6,</span> <span m="3451000">Stop me if I make a mistake. Then we get the 7s,</span> <span m="3456000">and we preserve the order. Here it happens to be the right</span> <span m="3462000">order, but it may not be at this point.</span> </p>
<p><span m="3467000">We haven't even looked at the other digits.</span> </p>
<p><span m="3471000">Then we get 9s, there are two 9s,</span> <span m="3474000">329 and 839. All right so far?</span> </p>
<p><span m="3477000">Good. Now we sort by the middle</span> <span m="3483000">digit, the next least significant.</span> </p>
<p><span m="3487000">And we start out with what looks like the 2s.</span> </p>
<p><span m="3492000">There is a 2 up here and a 2 down here.</span> </p>
<p><span m="3497000">Of course, we write the first 2 first, 720, then 329.</span> </p>
<p><span m="3503000">Then we have the 3s, so we have 436 and 839.</span> </p>
<p><span m="3510000">Then we have a bunch of 5s it looks like.</span> </p>
<p><span m="3513000">Have I missed anyone so far? No.</span> </p>
<p><span m="3516000">Good. We have three 5s,</span> <span m="3518000">355, 457 and 657. I like to check that I haven't</span> <span m="3522000">lost any elements. We have seven here,</span> <span m="3525000">seven here and seven elements here.</span> </p>
<p><span m="3528000">Good. Finally, we sort by the last</span> <span m="3531000">digit. One thing to notice,</span> <span m="3533000">by the way, is before we sorted by the last digit --</span> <span m="3540000">Currently these numbers don't resemble sorted order at all.</span> </p>
<p><span m="3545000">But if you look at everything beyond the digit we haven't yet</span> <span m="3550000">sorted, so these two digits, that's nice and sorted,</span> <span m="3555000">20, 29, 36, 39, 55, 57, 57.</span> </p>
<p><span m="3557000">Pretty cool. Let's finish it off.</span> </p>
<p><span m="3560000">We stably sort by the first digit.</span> </p>
<p><span m="3563000">And the smallest number we get is a 3, so we get 329 and then</span> <span m="3576000">436 and 457, then we get a 6,</span> <span m="3585000">657, then a 7, and then we have an 8.</span> </p>
<p><span m="3595000">And check. I still have seven elements.</span> </p>
<p><span m="3601631">Good. I haven't lost anyone.</span> </p>
<p><span m="3603203">And, indeed, they're now in sorted order.</span> </p>
<p><span m="3605533">And you can start to see why this is working.</span> </p>
<p><span m="3608097">When I have equal elements here, I have already sorted the</span> <span m="3611417">suffix. Let's write down a proof of</span> <span m="3613398">that. What is nice about this</span> <span m="3615029">algorithm is we're not partitioning into bins.</span> </p>
<p><span m="3617650">We always keep the huge batch of elements in one big pile,</span> <span m="3620970">but we're just going through it multiple times.</span> </p>
<p><span m="3623650">In general, we sort of need to go through it multiple times.</span> </p>
<p><span m="3627087">Hopefully not too many times. But let's first argue</span> <span m="3632006">correctness. To analyze the running time is</span> <span m="3636019">a little bit tricky here because it depends how you partition</span> <span m="3641751">into digits. Correctness is easy.</span> </p>
<p><span m="3644808">We just induct on the digit position that we're currently</span> <span m="3650159">sorting, so let's call that t. And we can assume by induction</span> <span m="3655891">that it's sorted beyond digit t. This is our induction</span> <span m="3662656">hypothesis. We assume that we're sorted on</span> <span m="3667841">the low-order t - 1 digits. And then the next thing we do</span> <span m="3674924">is sort on the t-th digit. We just need to check that</span> <span m="3681501">things work. And we restore the induction</span> <span m="3686561">hypothesis for t instead of t -</span> <span m="3692000">When we sort on the t-th digit there are two cases.</span> </p>
<p><span m="3696009">If we look at any two elements, we want to know whether they're</span> <span m="3700981">put in the right order. If two elements are the same,</span> <span m="3705150">let's say they have the same t-th digit --</span> <span m="3718000">This is the tricky case. If they have the same t-th</span> <span m="3722000">digit then their order should not be changed.</span> </p>
<p><span m="3725519">So, by stability, we know that they remain in the</span> <span m="3729360">same order because stability is supposed to preserve things that</span> <span m="3734400">have the same key that we're sorting on.</span> </p>
<p><span m="3737519">And then, by the induction hypothesis, we know that that</span> <span m="3741920">keeps them in sorted order because induction hypothesis</span> <span m="3746239">says that they used to be sorted.</span> </p>
<p><span m="3750000">Adding on this value in the front that's the same in both</span> <span m="3755369">doesn't change anything so they remain sorted.</span> </p>
<p><span m="3759684">And if they have differing t-th digits --</span> <span m="3774000">-- then this sorting step will put them in the right order.</span> </p>
<p><span m="3780000">Because that's what sorting does.</span> </p>
<p><span m="3783189">This is the most significant digit, so you've got to order</span> <span m="3788870">them by the t-th digit if they differ.</span> </p>
<p><span m="3792558">The rest are irrelevant. So, proof here of correctness</span> <span m="3797840">is very simple once you know the algorithm.</span> </p>
<p><span m="3802026">Any questions before we go on? Good.</span> </p>
<p><span m="3805514">We're going to use counting sort.</span> </p>
<p><span m="3810000">We could use any sorting algorithm we want for individual</span> <span m="3810344">digits, but the only algorithm that we know that runs in less</span> <span m="3810713">than n lg n time is counting sort.</span> </p>
<p><span m="3810916">So, we better use that one to sort of bootstrap and get an</span> <span m="3811267">even faster and more general algorithm.</span> </p>
<p><span m="3811501">I just erased the running time. Counting sort runs in order k +</span> <span m="3811883">n time. We need to remember that.</span> </p>
<p><span m="3816003">And the range of the numbers is 1 to k or 0 to k - 1.</span> </p>
<p><span m="3824329">When we sort by a particular digit, we shouldn't use n lg n</span> <span m="3833616">algorithm because then this thing will take n lg n for one</span> <span m="3842743">round and it's going to have multiple rounds.</span> </p>
<p><span m="3849788">That's going to be worse than n lg n.</span> </p>
<p><span m="3855552">We're going to use counting sort for each round.</span> </p>
<p><span m="3872000">We use counting sort for each digit.</span> </p>
<p><span m="3874931">And we know the running time of counting sort here is order k +</span> <span m="3880125">n . But I don't want to assume that</span> <span m="3882973">my integers are split into digits for me.</span> </p>
<p><span m="3886324">That's sort of giving away too much flexibility.</span> </p>
<p><span m="3890261">Because if I have some number written in whatever form it is,</span> <span m="3895287">probably written in binary, I can cluster together some of</span> <span m="3900062">those bits and call that a digit.</span> </p>
<p><span m="3904000">Let's think of our numbers as binary.</span> </p>
<p><span m="3907415">Suppose we have n integers. And they're in some range.</span> </p>
<p><span m="3912442">And we want to know how big a range they can be.</span> </p>
<p><span m="3916901">Let's say, a sort of practical way of thinking,</span> <span m="3921264">you know, we're in a binary world, each integer is b bits</span> <span m="3926577">long. So, in other words,</span> <span m="3929774">the range is from 0 to 2b - 1. I will assume that my numbers</span> <span m="3935283">are non-negative. It doesn't make much difference</span> <span m="3939765">if they're negative, too.</span> </p>
<p><span m="3942006">I want to know how big a b I can handle, but I don't want to</span> <span m="3947515">split into bits as my digits because then I would have b</span> <span m="3952650">digits and I would have to do b rounds of this algorithm.</span> </p>
<p><span m="3959000">The number of rounds of this algorithm is the number of</span> <span m="3962839">digits that I have. And each one costs me,</span> <span m="3965754">let's hope, for linear time. And, indeed,</span> <span m="3968598">if I use a single bit, k = 2.</span> </p>
<p><span m="3970589">And so this is order n. But then the running time would</span> <span m="3974428">be order n per round. And there are b digits,</span> <span m="3977557">if I consider them to be bits, order n times b time.</span> </p>
<p><span m="3981183">And even if b is something small like log n,</span> <span m="3984240">if I have log n bits, then these are numbers between</span> <span m="3987866">0 and n - 1. I already know how to sort</span> <span m="3992549">numbers between 0 and n - 1 in linear time.</span> </p>
<p><span m="3996666">Here I'm spending n lg n time, so that's no good.</span> </p>
<p><span m="4001372">Instead, what we're going to do is take a bunch of bits and call</span> <span m="4007549">that a digit, the most bits we can handle</span> <span m="4011470">with counting sort. The notation will be I split</span> <span m="4016078">each integer into b/r digits. Each r bits long.</span> </p>
<p><span m="4021846">In other words, I think of my number as being</span> <span m="4026630">in base 2^r. And I happen to be writing it</span> <span m="4031086">down in binary, but I cluster together r bits</span> <span m="4035869">and I get a bunch of digits in base 2^r.</span> </p>
<p><span m="4040108">And then there are b/ r digits. This b/r is the number of</span> <span m="4046195">rounds. And this base --</span> <span m="4050000">This is the maximum value I have in one of these digits.</span> </p>
<p><span m="4054104">It's between 0 and 2^r. This is, in some sense,</span> <span m="4057537">k for a run of counting sort.</span> </p>
<p><span m="4069000">What is the running time? Well, I have b/r rounds.</span> </p>
<p><span m="4074673">It's b/r times the running time for a round.</span> </p>
<p><span m="4080000">Which I have n numbers and my value of k is 2^r.</span> </p>
<p><span m="4085830">This is the running time of counting sort,</span> <span m="4090917">n + k, this is the number of rounds, so this is b/r (n+2^r).</span> </p>
<p><span m="4098236">And I am free to choose r however I want.</span> </p>
<p><span m="4103198">What I would like to do is minimize this run time over my</span> <span m="4110145">choices of r. Any suggestions on how I might</span> <span m="4115703">find the minimum running time over all choices of r?</span> </p>
<p><span m="4120303">Techniques, not necessarily solutions.</span> </p>
<p><span m="4133000">We're not used to this because it's asymptomatic,</span> <span m="4135488">but forget the big O here. How do I minimize a function</span> <span m="4138288">with respect to one variable? Take the derivative,</span> <span m="4141336">yeah. I can take the derivative of</span> <span m="4143541">this function by r, differentiate by r,</span> <span m="4146080">set the derivative equal to 0, and that should be a critical</span> <span m="4150022">point in this function. It turns out this function is</span> <span m="4153496">unimodal in r and you will find the minimum.</span> </p>
<p><span m="4156368">We could do that. I'm not going to do it because</span> <span m="4159510">it takes a little bit more work. You should try it at home.</span> </p>
<p><span m="4163385">It will give you the exact minimum, which is good if you</span> <span m="4167059">know what this constant is. Differentiate with respect to r</span> <span m="4172283">and set to 0. I am going to do it a little</span> <span m="4175305">bit more intuitively, in other words less precisely,</span> <span m="4179063">but I will still get the right answer.</span> </p>
<p><span m="4181788">And definitely I will get an upper bound because I can choose</span> <span m="4186210">r to be whatever I want. It turns out this will be the</span> <span m="4190115">right answer. Let's just think about growth</span> <span m="4193210">in terms of r. There are essentially two terms</span> <span m="4196526">here. I have b/r(n) and I have</span> <span m="4200024">b/r(2^r). Now, b/r(n) would like r to be</span> <span m="4203315">as big as possible. The bigger r is the number of</span> <span m="4207364">rounds goes down. This number in front of n,</span> <span m="4210992">this coefficient in front of n goes down, so I would like r to</span> <span m="4216138">be big. So, b/r(n) wants r big.</span> </p>
<p><span m="4218669">However, r cannot be too big. This is saying I want digits</span> <span m="4223478">that have a lot of bits in them. It cannot be too big because</span> <span m="4228540">there's 2^r term out here. If this happens to be bigger</span> <span m="4234465">than n then this will dominate in terms of growth of r.</span> </p>
<p><span m="4239220">This is going to be b times 2 to the r over r.</span> </p>
<p><span m="4243182">2 the r is much, much bigger than r,</span> <span m="4246264">so it's going to grow much faster is what I mean.</span> </p>
<p><span m="4250490">And so I really don't want r to be too big for this other term.</span> </p>
<p><span m="4255949">So, that is b/4(2^r) wants r small.</span> </p>
<p><span m="4260000">Provided that this term is bigger or equal to this term</span> <span m="4266684">then I can set r pretty big for that term.</span> </p>
<p><span m="4271758">What I want is the n to dominate the 2^r.</span> </p>
<p><span m="4276710">Provided I have that then I can set r as large as I want.</span> </p>
<p><span m="4283641">Let's say I want to choose r to be maximum subject to this</span> <span m="4290697">condition that n is greater than or equal to 2^r.</span> </p>
<p><span m="4298000">This is an upper bound to 2^r, and upper bound on r.</span> </p>
<p><span m="4302291">In other words, I want r = lg n.</span> </p>
<p><span m="4304899">This turns out to be the right answer up to constant factors.</span> </p>
<p><span m="4309948">There we go. And definitely choosing r to be</span> <span m="4313566">lg n will give me an upper bound on the best running time I could</span> <span m="4318951">get because I can choose it to be whatever I want.</span> </p>
<p><span m="4324000">If you differentiate you will indeed get the same answer.</span> </p>
<p><span m="4330564">This was not quite a formal argument but close,</span> <span m="4335956">because the big O is all about what grows fastest.</span> </p>
<p><span m="4341699">If we plug in r = lg n we get bn/lg n.</span> </p>
<p><span m="4346036">The n and the 2^r are equal, that's a factor of 2,</span> <span m="4351780">2 times n, not a big deal. It comes out into the O.</span> </p>
<p><span m="4358704">We have bn/lg n which is r. We have to think about what</span> <span m="4364788">this means and translate it in terms of range.</span> </p>
<p><span m="4369859">b was the number of bits in our number, which corresponds to the</span> <span m="4376957">range of the number. I've got 20 minutes under so</span> <span m="4383417">far in lecture so I can go 20 minutes over,</span> <span m="4388543">right? No, I'm kidding.</span> </p>
<p><span m="4391228">Almost done. Let's say that our numbers,</span> <span m="4395988">are integers are in the range, we have 0 to 2^b,</span> <span m="4401724">I'm going to say that it's range 0 to nd.</span> </p>
<p><span m="4406606">This should be a -1 here. If I have numbers that are</span> <span m="4413449">between 0 and n^d - 1 where d is a constant or d is some</span> <span m="4418632">parameter, so this is a polynomial in n,</span> <span m="4422306">then you work out this running time.</span> </p>
<p><span m="4425604">It is order dn. This is the way to think about</span> <span m="4429844">it because now we can compare to counting sort.</span> </p>
<p><span m="4434179">Counting sort could handle 0 up to some constant times d in</span> <span m="4439644">linear time. Now I can handle 0 up to n to</span> <span m="4444501">some constant power in linear time.</span> </p>
<p><span m="4447434">This is if d = order 1 then we get a linear time sorting</span> <span m="4452178">algorithm. And that is cool as long as d</span> <span m="4455543">is at most lg n. As long as your numbers are at</span> <span m="4459511">most n lg n then we have something that beats our n lg n</span> <span m="4464255">sorting algorithms. And this is pretty nice.</span> </p>
<p><span m="4469000">Whenever you know that your numbers are order log end bits</span> <span m="4473099">long we are happy, and you get some smooth</span> <span m="4476048">tradeoff there. For example,</span> <span m="4477990">if we have our 32 bit numbers and we split into let's say</span> <span m="4482018">eight bit chunks then we'll only have to do four rounds each</span> <span m="4486262">linear time and we have just 256 working space.</span> </p>
<p><span m="4489570">We were doing four rounds for 32 bit numbers.</span> </p>
<p><span m="4492735">If you use n lg n algorithm, you're going to be doing lg n</span> <span m="4496835">rounds through your numbers. n is like 2000,</span> <span m="4500941">and that's at least 11 rounds for example.</span> </p>
<p><span m="4503515">You would think this algorithm is going to be much faster for</span> <span m="4507281">small numbers. Unfortunately,</span> <span m="4509038">counting sort is not very good on a cache.</span> </p>
<p><span m="4511612">In practice, rating sort is not that fast an</span> <span m="4514311">algorithm unless your numbers are really small.</span> </p>
<p><span m="4517199">Something like quicksort can do better.</span> </p>
<p><span m="4519584">It's sort of shame, but theoretically this is very</span> <span m="4522660">beautiful. And there are contexts where</span> <span m="4525045">this is really the right way to sort things.</span> </p>
<p><span m="4529000">I will mention finally that if you have arbitrary integers that</span> <span m="4534352">are one word length long. Here we're assuming that there</span> <span m="4539100">are b bits in a word and we have some depends indirectly on b</span> <span m="4544280">here. But, in general,</span> <span m="4546093">if you have a bunch of integers and they're one word length</span> <span m="4551100">long, and you can manipulate a word in constant time,</span> <span m="4555589">then the best algorithm we know for sorting runs in n times</span> <span m="4560597">square root of lg lg n time expected.</span> </p>
<p><span m="4565000">It is a randomized algorithm. We're not going to cover that</span> <span m="4568719">algorithm in this class. It's rather complicated.</span> </p>
<p><span m="4571798">I didn't even cover it in Advanced Algorithms when I</span> <span m="4575068">taught it. If you want something easier,</span> <span m="4577570">you can get n times square root of lg lg n time worst-case.</span> </p>
<p><span m="4581289">And that paper is almost readable.</span> </p>
<p><span m="4583406">I have taught that in Advanced Algorithms.</span> </p>
<p><span m="4586035">If you're interested in this kind of stuff,</span> <span m="4588729">take Advanced Algorithms next fall.</span> </p>
<p><span m="4592000">It's one of the follow-ons to this class.</span> </p>
<p><span m="4594552">These are much more complicated algorithms, but it gives you</span> <span m="4598317">some sense. You can even break out of the</span> <span m="4600870">dependence on b, as long as you know that b is</span> <span m="4603742">at most a word. And I will stop there unless</span> <span m="4606486">there are any questions. Then see you Wednesday.</span> </p>
</div>
        <div id="vid_transcript" itemprop="description" class="tabContent hide">
<h2 class="subhead">Free Downloads</h2>
<h3 class="subsubhead">Video</h3>
<ul>
<li>iTunes U (<a href="https://itunes.apple.com/us/itunes-u/id341597754">MP4 - 161MB</a>)</li>
<li>Internet Archive (<a href="http://www.archive.org/download/MIT6.046JF05MPEG4/ocw-6.046-26sep2005-220k.mp4">MP4 - 316MB</a>)</li>
</ul>
<br><h3 class="subsubhead">Free Streaming</h3>
<ul><li><a href="http://videolectures.net/mit6046jf05_introduction_algorithms/">VideoLectures.net</a></li></ul>
<br><h3 class="subsubhead">Subtitle</h3>
<ul><li>English - US (<a href="../../../contents/video-lectures/lecture-5-linear-time-sorting-lower-bounds-counting-sort-radix-sort/0VqawRl3Xzs.srt">SRT</a>)</li></ul>
</div>
    
   </div>  




      					 
        <div class="" id="parent-fieldname-bottom_html_area">
            
            
        </div>
    
                    </div>
<!--Course_inner_chip tag close -->
           		</div>
<!--Course_wrapper tag close --> 
            </div>
<!--left tag close -->
            <div id="right">
                <!--Begin Right Portion -->
                    <div>
    
<div id="portletwrapper-6f63772e7269676874746f70706f72746c65746d616e616765720a636f6e746578740a2f506c6f6e650a646f6e617465" class="portletWrapper kssattr-portlethash-6f63772e7269676874746f70706f72746c65746d616e616765720a636f6e746578740a2f506c6f6e650a646f6e617465">
<div class="portletStaticText portlet-static-donate"><p class="zero"><a href="http://ocw.mit.edu/donate"><img src="../../../common/images/button_donate-now.png" alt="Donate Now." class="donate"></a></p></div>

</div>




</div>

                	<div>
    



</div>


        <div class="" id="parent-fieldname-rsi_top_html_area">
            
            
        </div>
    

<!-- RSI google ad space-->


<div id="google_ads">    
    <script type="text/javascript" src="http://partner.googleadservices.com/gampad/google_service.js"></script><script type="text/javascript">GS_googleAddAdSenseService("ca-pub-6588555046597237");GS_googleEnableAllServices();</script><script type="text/javascript">GA_googleAddSlot("ca-pub-6588555046597237", "VIDEO_INDIVIDUAL_SLOT_A_DL");GA_googleAddSlot("ca-pub-6588555046597237", "VIDEO_INDIVIDUAL_SLOT_B_DL");GA_googleAddSlot("ca-pub-6588555046597237", "VIDEO_INDIVIDUAL_SLOT_C_DL");</script><script type="text/javascript">GA_googleFetchAds();</script><script language="javascript" type="text/javascript">
GA_googleAddAttr("TYPE","HOUSE");
GA_googleAddAttr("DEPARTMENT","6");
GA_googleAddAttr("CRS_BEG2","04");
GA_googleAddAttr("CRS_END","6J");
GA_googleAddAttr("SESSION","F");
GA_googleAddAttr("YEAR","05");
</script><script type="text/javascript">GA_googleFillSlot("VIDEO_INDIVIDUAL_SLOT_A_DL");</script><script type="text/javascript">GA_googleFillSlot("VIDEO_INDIVIDUAL_SLOT_B_DL");</script><script type="text/javascript">GA_googleFillSlot("VIDEO_INDIVIDUAL_SLOT_C_DL");</script>
</div>

<!-- End RSI ads--> 

<div>
    



</div>

            </div>
<!--Right div close -->
            <div class="clear"></div> 
        </div>
<!--grid tag close --> 
      </div>
		
		<div id="bottom">
			<div id="grid">
				
<div id="portletwrapper-6f63772e626f74746f6d706f72746c65746d616e616765720a636f6e746578740a2f506c6f6e650a736974652d666f6f746572" class="portletWrapper kssattr-portlethash-6f63772e626f74746f6d706f72746c65746d616e616765720a636f6e746578740a2f506c6f6e650a736974652d666f6f746572">
<div class="portletStaticText portlet-static-site-footer">
<!--googleoff: index--> <div id="bottom"><div id="grid">
<!-- *begin footer* --> <div role="navigation sitemap" id="footer">
<div class="grid_2 alpha" id="foot-c1">
<h4 class="footer">Find Courses</h4> <ul class="foot-bullet">
<li><a href="http://ocw.mit.edu/courses/find-by-topic/">Find by Topic</a></li>     <li><a href="http://ocw.mit.edu/courses/find-by-number/">Find by Course Number</a></li>     <li><a href="http://ocw.mit.edu/courses/find-by-department/">Find by Department</a></li>     <li><a href="http://ocw.mit.edu/courses/audio-video-courses/">Audio/Video Courses</a></li>     <li><a href="http://ocw.mit.edu/courses/subtitled/">Courses with Subtitles</a></li>     <li><a href="http://ocw.mit.edu/courses/online-textbooks/">Online Textbooks</a></li>     <li><a href="http://ocw.mit.edu/courses/new-courses/">New Courses</a></li>     <li><a href="http://ocw.mit.edu/courses/most-visited-courses/">Most Visited Courses</a></li>     <li><a href="http://ocw.mit.edu/courses/ocw-scholar/">OCW Scholar Courses</a></li>     <li><a href="http://ocw.mit.edu/courses/this-course-at-mit/">This Course at MIT</a></li>     <li><a href="http://ocw.mit.edu/resources/">Supplemental Resources</a></li>     <li><a href="http://ocw.mit.edu/courses/translated-courses/">Translated Courses</a></li>     <li><a href="http://ocw.mit.edu/courses/">View All Courses</a></li> </ul>
</div> <div class="grid_2" id="foot-c2">
<h4 class="footer">About</h4> <ul class="foot-bullet">
<li><a href="http://ocw.mit.edu/about/">About OpenCourseWare</a></li>     <li><a href="http://ocw.mit.edu/about/site-statistics/">Site Stats</a></li>     <li><a href="http://ocw.mit.edu/about/ocw-stories/">OCW Stories</a></li>     <li><a href="http://ocw.mit.edu/about/media-coverage/">Media Coverage</a></li>     <li><a href="http://ocw.mit.edu/about/newsletter/">Newsletter</a></li>     <li><a href="http://ocw.mit.edu/about/media-coverage/press-releases/">Press Releases</a></li> </ul>
</div> <div class="grid_2" id="foot-c3">
<h4 class="footer">Donate</h4> <ul class="foot-bullet">
<li><a href="http://ocw.mit.edu/donate">Make a Donation</a></li>     <li><a href="http://ocw.mit.edu/donate/why-donate/">Why Donate?</a></li>     <li><a href="http://ocw.mit.edu/donate/our-supporters/">Our Supporters</a></li>     <li><a href="http://ocw.mit.edu/donate/other-ways-to-contribute/">Other Ways to Contribute</a></li>     <li><a href="http://ocw.mit.edu/donate/shop-ocw/">Shop OCW</a></li>     <li><a href="http://ocw.mit.edu/support/">Become a Corporate Sponsor</a></li> </ul>
</div> <div class="grid_2" id="foot-c4">
<h4 class="footer">Featured Sites</h4> <ul class="foot-bullet">
<li><a href="http://ocw.mit.edu/high-school/">Highlights for High School</a></li>     <li><a href="http://ocw.mit.edu/educator/">OCW Educator</a></li>     <li><a href="http://ocw.mit.edu/courses/crosslinks/">MIT Crosslinks and OCW</a></li>     <li><a href="http://ocw.mit.edu/ans7870/featured/mitx-courses-on-edx.htm">MITx Courses on edX</a></li>     <li><a href="http://teachingexcellence.mit.edu/">Teaching Excellence at MIT</a></li>     <li><a href="http://www.oeconsortium.org/">Open Education Consortium</a></li> </ul>
<h4 style="margin-top: 14px;" class="footer">Tools</h4> <ul class="foot-bullet">
<li><a href="http://ocw.mit.edu/help/">Help &amp; FAQs</a></li>     <li><a href="../../../common/jsp/feedback.htm">Contact Us</a></li>     <li><a href="../../../common/search/AdvancedSearch.htm">Advanced Search</a></li>     <li><a href="http://ocw.mit.edu/help/site-map/">Site Map</a></li>     <li><a href="../../../common/terms/index.htm">Privacy &amp; Terms of Use</a></li>     <li><a href="http://ocw.mit.edu/help/rss/">RSS Feeds</a></li> </ul>
</div> <div class="grid_4 omega" id="foot-c5">
<h4 class="footer">Our Corporate Supporters</h4> <!-- HOME_CORP_LOGO_1 --> <div class="sponsors_google_ads_even" id="div-gpt-ad-1388181177156-0"><script type="text/javascript">
googletag.cmd.push(function() { googletag.display('div-gpt-ad-1388181177156-0'); });
</script></div> <!-- HOME_CORP_LOGO_2 --> <div class="sponsors_google_ads_odd" id="div-gpt-ad-1388181177156-1"><script type="text/javascript">
googletag.cmd.push(function() { googletag.display('div-gpt-ad-1388181177156-1'); });
</script></div> <!-- HOME_CORP_LOGO_3 --> <div class="sponsors_google_ads_even" id="div-gpt-ad-1388181177156-2"><script type="text/javascript">
googletag.cmd.push(function() { googletag.display('div-gpt-ad-1388181177156-2'); });
</script></div> <!-- HOME_CORP_LOGO_4 --> <div class="sponsors_google_ads_odd" id="div-gpt-ad-1388181177156-3"><script type="text/javascript">
googletag.cmd.push(function() { googletag.display('div-gpt-ad-1388181177156-3'); });
</script></div> <!-- HOME_CORP_LOGO_5 --> <div class="sponsors_google_ads_even" id="div-gpt-ad-1388181177156-4"><script type="text/javascript">
googletag.cmd.push(function() { googletag.display('div-gpt-ad-1388181177156-4'); });
</script></div> <!-- HOME_CORP_LOGO_6 --> <div class="sponsors_google_ads_odd" id="div-gpt-ad-1388181177156-5"><script type="text/javascript">
googletag.cmd.push(function() { googletag.display('div-gpt-ad-1388181177156-5'); });
</script></div>
</div> <div class="grid_12 alpha omega" style="border-top: thin solid #d5c9ba; padding-top: 24px; margin-bottom: 10px; text-align: center;"><p style="font-family: TitilliumText22LRegular,Verdana; text-align: center; font-size: 1.1em;">Support for <span style="letter-spacing: 0.5px;"><strong>MIT OPENCOURSEWARE'S 15th anniversary</strong></span> is provided by <a href="http://www.sapientnitro.com/en-us.html#home"><img style="width: 145px; height: 35px; vertical-align: middle; margin-left: 7px;" alt="SapientNitro logo and nameplate." src="../../../common/images/logo_sapient.png"></a></p></div> <div itemtype="http://schema.org/CollegeOrUniversity" itemscope="" itemprop="publisher" class="grid_12 alpha omega">
<h4 style="border-top: thin solid #d5c9ba; padding-top: 10px; margin-bottom: 10px;" class="footer">About <span itemprop="name">MIT OpenCourseWare</span>
</h4> <p itemprop="description" style="color: #999; font-size: 1em; line-height: 1.5em; margin-top: 10px;">MIT OpenCourseWare makes the materials used in the teaching of almost all of MIT's subjects available on the Web, free of charge. With more than 2,200 courses available, OCW is delivering on the promise of open sharing of knowledge. <a href="http://ocw.mit.edu/about/">Learn more »</a></p>
</div> <div style="border-top: none;" class="grid_12 alpha omega" id="foot-copy">
<a href="http://web.mit.edu"><img style="width: 195; height: 44;" alt="Massachusetts Institute of Technology logo and name." src="../../../common/images/logo_mit.png"></a><a href="http://odl.mit.edu"><img style="width: 289; height: 54; vertical-align: top;" alt="MIT Office of Digital Learning logo and name." src="http://ocw.mit.edu/images/logo_odl.png"></a><a href="http://www.oeconsortium.org/"><img style="width: 219px; height: 59px; vertical-align: top;" alt="Open Education Consortium logo." src="http://ocw.mit.edu/images/logo_oec.png"></a><a itemprop="useRightsUrl" rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img style="width: 126px; height: 44px; margin-right: 0; margin-left: 13px;" alt="Creative Commons logo with terms BY-NC-SA." src="../../../common/images/cc_by-nc-sa.png"></a> <p class="copyright">© 2001–2015<br> Massachusetts Institute of Technology</p> <p style="font-size: 0.9em; margin-bottom: 15px;">Your use of the MIT OpenCourseWare site and materials is subject to our <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/">Creative Commons License</a> and other <a rel="cc:morePermissions" href="../../../common/terms/index.htm">terms of use</a>.</p>
</div>
</div>
</div></div> <!--googleon: index-->
</div>

</div>





                
			</div> <!-- bottom grid end -->
		</div>
<!-- bottom end -->
		
		
   </body>
</html>

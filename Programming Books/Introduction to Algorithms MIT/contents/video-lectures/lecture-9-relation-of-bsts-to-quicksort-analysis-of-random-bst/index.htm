<!DOCTYPE html><html lang="en">
<head>
<meta charset="utf-8">
<meta name="format-detection" content="telephone=no">
<title>Lecture 9: Relation of BSTs to Quicksort - Analysis of Random BST | Video Lectures | Introduction to Algorithms (SMA 5503) | Electrical Engineering and Computer Science | MIT OpenCourseWare</title>
<!-- Begin Automatic Metadata Insertion --><meta content="6-046j-introduction-to-algorithms-sma-5503-fall-2005" name="WT.cg_n">
<meta content="Lecture 9: Relation of BSTs to Quicksort - Analysis of Random BST" name="WT.cg_s">
<meta content="" name="Description">
<meta content="Leiserson, Charles" name="Author">
<meta content="Demaine, Erik" name="Author">
<meta content="algorithms,efficient algorithms,sorting,search trees,heaps,hashing,divide-and-conquer,dynamic programming,amortized analysis,graph algorithms,shortest paths,network flow,computational geometry,number-theoretic algorithms,polynomial and matrix calculations,caching,parallel computing,Algorithms and Data Structures" name="keywords">
<meta content="6.046J Introduction to Algorithms (SMA 5503) | Lecture 9: Relation of BSTs to Quicksort - Analysis of Random BST" name="Search_Display">
<meta content="Algorithms and Data Structures" itemprop="about">
<!-- End Automatic Metadata Insertion --><link title="default" rel="stylesheet" type="text/css" href="../../../common/styles/grid.css">
<link title="default" rel="stylesheet" type="text/css" href="../../../common/styles/base.css">
<link title="default" rel="stylesheet" type="text/css" href="../../../common/styles/menu.css">
<link title="default" rel="stylesheet" type="text/css" href="../../../common/styles/jquery.bubblepopup.css">
<link title="default" rel="stylesheet" type="text/css" href="../../../common/styles/courses.css">
<link title="default" rel="stylesheet" type="text/css" href="../../../common/styles/courses_new.css">
<link title="default" rel="stylesheet" type="text/css" href="../../../common/styles/jquery.jscrollpane.css">
<link title="default" rel="stylesheet" type="text/css" href="../../../common/styles/media_tabs.css">
<link href="http://ocw.mit.edu/xml/ocwcc.rdf" type="application/rdf+xml" rel="metadata">
<link rel="canonical" href="http://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-046j-introduction-to-algorithms-sma-5503-fall-2005/video-lectures/lecture-9-relation-of-bsts-to-quicksort-analysis-of-random-bst">
<link rel="apple-touch-icon" href="../../../common/images/apple-touch-icon.png">
<script type="text/javascript" src="../../../common/scripts/jquery.js"></script><script type="text/javascript" src="../../../common/scripts/ocw-media-utils-offline.js"></script><script type="text/javascript" src="../../../common/scripts/ocw-offline.js"></script><script type="text/javascript" src="../../../common/scripts/jquery.bubblepopup.min.js"></script><script type="text/javascript" src="../../../common/scripts/jquery-ui.min.js"></script><script type="text/javascript" src="../../../common/scripts/jquery.jscrollpane.min.js"></script><script type="text/javascript" src="../../../common/scripts/bubble-popup-offline.js"></script><script type="text/javascript">
      $(document).ready(function() {
        $("#tabs").tabs();
        IpadScroller();
      });
    </script>
</head>
<body itemscope itemtype="http://schema.org/WebPage">
        
	

        <div id="top">
			<div id="grid">
				
				
					
<div id="portletwrapper-6f63772e746f70706f72746c65746d616e616765720a636f6e746578740a2f506c6f6e650a736974652d686561646572" class="portletWrapper kssattr-portlethash-6f63772e746f70706f72746c65746d616e616765720a636f6e746578740a2f506c6f6e650a736974652d686561646572">
<div class="portletStaticText portlet-static-site-header">
<!--googleoff: index-->
<div class="grid_6 alpha" role="banner" id="banner"><a href="http://ocw.mit.edu/"><img class="logo" alt="MIT OpenCourseWare, Massachusetts Institute of Technology" src="../../../common/images/ocw_mast.png"></a></div>
<div class="grid_6 omega" role="form toolbar" id="subscribe">
<div class="module">
<table class="social"><tbody><tr>
<td class="socialbutton"><a href="http://ocw.mit.edu/subscribe/index.htm?utm_source=header"><img src="../../../common/images/trans.gif" alt="An icon depicting an envelope.">Subscribe to the OCW Newsletter</a></td>
            <td>
<a href="https://plus.google.com/104567381989352550847/posts"><img alt="Click to visit our Google+ page." src="../../../common/images/icon_gp.png"></a><a href="https://www.pinterest.com/mitocw/pins/"><img alt="Click to visit our Pinterest page." src="../../../common/images/icon_pin.png"></a><a href="http://facebook.com/mitocw"><img alt="Click to visit our Facebook page." src="../../../common/images/icon_fb.png"></a><a href="http://twitter.com/mitocw"><img alt="Click to visit our Twitter feed." src="../../../common/images/icon_tw.png"></a>
</td>
        </tr></tbody></table>
</div>
<p class="helplinks"><a href="http://ocw.mit.edu/help">Help</a>   |   <a href="../../../common/jsp/feedback.htm">Contact Us</a></p>
</div>
<div class="clear"> </div>
<!--googleon: index-->
</div>

</div>





<!--googleoff: index-->
<div id="mega" role="navigation" class="grid_8 alpha">        
	<ul id="menu">
<li id="menu_home">
            <a href="http://ocw.mit.edu/"><img src="../../../common/images/top-nav_home.png" class="home_icon" alt="Click for site home page."></a><!-- Begin Home Item -->
        </li>
<!-- End Home Item -->        
        <li class="selected">
            <a href="#" class="drop">Find Courses</a><!-- Begin 5 columns Item -->
            <div class="dropdown_5columns-a mega-courses">                    
                <div class="col_1a">
                    <div class="row_1a">
                        <div class="quart">
                            <h2 class="nav">Find courses by:</h2>
                            <ul class="nav-bullet find_by">
<li><a href="http://ocw.mit.edu/courses/find-by-topic/">Topic</a></li>
                                <li><a href="http://ocw.mit.edu/courses/find-by-number/">MIT Course Number</a></li>
                                <li><a href="http://ocw.mit.edu/courses/find-by-department/">Department</a></li>
                            </ul>
<ul style="margin-top: 88px;" class="nav-bullet find_by">
<li style="font-weight: normal; font-size: 1em;"><a href="http://ocw.mit.edu/courses/">View All Courses</a></li>
							</ul>
</div>
                        <div class="quart">
                            <h2 class="nav">Collections</h2>
                            <ul class="nav-bullet">
<li><a href="http://ocw.mit.edu/courses/audio-video-courses/">Audio/Video Lectures</a></li>
                                <li><a href="http://ocw.mit.edu/courses/online-textbooks/">Online Textbooks</a></li>
                                <li><a href="http://ocw.mit.edu/courses/new-courses/">New Courses</a></li>
                                <li><a href="http://ocw.mit.edu/courses/most-visited-courses/">Most Visited Courses</a></li>
                                <li><a href="http://ocw.mit.edu/courses/ocw-scholar/">OCW Scholar Courses</a></li>
                                <li><a href="http://ocw.mit.edu/courses/this-course-at-mit/">This Course at MIT</a></li>
                                <li><a href="http://ocw.mit.edu/resources/">Supplemental Resources</a></li>
                            </ul>
</div>
                        <div class="clear"> </div>
                    </div>
                    <div class="row_1b">
                        <h2 class="nav">Cross-Disciplinary Topic Lists</h2>
                        <div class="quart">
                        <ul class="nav-bullet">
<li><a href="http://ocw.mit.edu/courses/energy-courses">Energy</a></li>
                            <li><a href="http://ocw.mit.edu/courses/entrepreneurship">Entrepreneurship</a></li>
                            <li><a href="http://ocw.mit.edu/courses/environment-courses">Environment</a></li>
                        </ul>
</div>    
                        <div class="quart">
                        <ul class="nav-bullet">
<li><a href="http://ocw.mit.edu/courses/intro-programming">Introductory Programming</a></li>
                            <li><a href="http://ocw.mit.edu/courses/life-sciences">Life Sciences</a></li>
                            <li><a href="http://ocw.mit.edu/courses/transportation-courses">Transportation</a></li>
                        </ul>
</div>
                        <div class="clear"> </div>
                    </div>
                    <div class="clear"> </div>
                </div>
                <div class="col_1b">
                    <h2 class="nav">Translated Courses</h2>
                    <ul class="nav-bullet">
<li><a href="http://ocw.mit.edu/courses/translated-courses/traditional-chinese">繁體字 / Traditional Chinese</a></li>
                        <li><a href="http://ocw.mit.edu/courses/translated-courses/spanish">Español / Spanish</a></li>
                        <li><a href="http://ocw.mit.edu/courses/translated-courses/portuguese">Português / Portuguese</a></li>
                        <li><a href="http://ocw.mit.edu/courses/translated-courses/persian">فارسی / Persian</a></li>
                        <li><a href="http://ocw.mit.edu/courses/translated-courses/turkish">Türkçe / Turkish</a></li>
                        <li><a href="http://ocw.mit.edu/courses/translated-courses/korean">(비디오)한국 / Korean</a></li>
                        <li><a href="http://ocw.mit.edu/courses/translated-courses">More...</a></li>
                    </ul>
</div>
            </div>
        </li>
        <li>
            <a href="" class="drop">About</a>
            <div class="dropdown_1column-a">
                <div class="col_1">
                    <ul class="nav-bullet mega-div-bottom">
<li><a href="http://ocw.mit.edu/about/">About MIT OpenCourseWare</a></li>
                    </ul>
<ul class="nav-bullet mega-div-bottom">
<li><a href="http://ocw.mit.edu/about/site-statistics/">Site Stats</a></li>
                        <li><a href="http://ocw.mit.edu/about/ocw-stories/">OCW Stories</a></li>                        
                    </ul>
<ul class="nav-bullet">
<li><a href="http://ocw.mit.edu/about/media-coverage/">Media Coverage</a></li>
                        <li><a href="http://ocw.mit.edu/about/newsletter/">Newsletter</a></li>                        
                    </ul>
</div>
            </div>  
        </li>    
        <li>
            <a href="" class="drop">Donate</a>        
            <div class="dropdown_1column-a">
                    <div class="col_1">
                        <ul class="nav-bullet mega-div-bottom">
<li><a href="http://ocw.mit.edu/donate/">Make a Donation</a></li>
                            <li><a href="http://ocw.mit.edu/donate/why-donate/">Why Donate?</a></li>
                            <li><a href="http://ocw.mit.edu/donate/our-supporters/">Our Supporters</a></li>
                            <li><a href="http://ocw.mit.edu/donate/other-ways-to-contribute/">Other Ways to Contribute</a></li>
                            <li><a href="http://ocw.mit.edu/donate/shop-ocw">Shop OCW</a></li>
                        </ul>
<ul class="nav-bullet">
<li><a href="http://ocw.mit.edu/support/">Become a Corporate Sponsor</a></li>
                        </ul>
</div>
            </div>            
        </li>        
        <li>
            <a href="" class="drop">Featured Sites</a>        
            <div class="dropdown_1column-a">
                <div class="col_1">
                    <ul class="nav-bullet mega-div-bottom">
<li><a href="http://ocw.mit.edu/high-school/">Highlights for High School</a></li>
                        <li><a href="http://ocw.mit.edu/educator/">OCW Educator</a></li>
                        <li><a href="http://ocw.mit.edu/courses/crosslinks/">MIT Crosslinks and OCW</a></li>                        
                    </ul>
<ul class="nav-bullet mega-div-top">
<li><a href="http://ocw.mit.edu/ans7870/featured/mitx-courses-on-edx.htm">MITx Courses on edX</a></li>
                        <li><a href="http://teachingexcellence.mit.edu/">Teaching Excellence at MIT</a></li>
						<li><a href="http://www.oeconsortium.org/">Open Education Consortium</a></li>
                    </ul>
</div>
            </div>            
        </li>
    </ul>
</div>
<div id="search" role="search" class="grid_4 omega">
    
    <form method="get" action="../../../common/search/AdvancedSearch.htm">
     	 <table class="search"><tbody><tr>
<td class="black"><input type="text" onblur="fillSearchBox()" onfocus="clearSearchBox()" maxlength="255" value="Search" name="q" class="greytext searchField" id="terms"></td> 			 
                    <td class="black"><input type="image" src="../../../common/images/button_search.png" name="btnG" class="sub_button"></td>			 
                    <td class="text2"><a href="../../../common/search/AdvancedSearch.htm">Advanced<br>Search</a></td>
                </tr></tbody></table>
</form>
</div>
<div class="clear"></div>
<!--googleon: index-->
<!-- *end header* -->  

				
				
			</div>
<!-- top grid end -->
		</div>
<!-- top end -->
			
		<div id="center_media">
      	<div id="grid">
      		<div id="left">
        		<div id="breadcrumb_media">
                	<p>

    <a href="http://ocw.mit.edu/">Home</a>
    
        »
        
    
    
        
            <a href="http://ocw.mit.edu/courses">Courses</a>
            
                »
                
            
            
         
    
    
        
            <a href="http://ocw.mit.edu/courses/electrical-engineering-and-computer-science">Electrical Engineering and Computer Science</a>
            
                »
                
            
            
         
    
    
        
            <a href="../../../contents/index.htm">Introduction to Algorithms (SMA 5503)</a>
            
                »
                
            
            
         
    
    
        
            <a href="../../../contents/video-lectures/index.htm">Video Lectures</a>
            
                »
                
            
            
         
    
    
        
            
            
            Lecture 9: Relation of BSTs to Quicksort - Analysis of Random BST
         
    
</p>

            	</div>
            	<div class="clear"></div>
        		<div id="media_title">
        		<h1 class="title" itemprop="name" property="dct:title">
        <span class="" id="parent-fieldname-title">
            Lecture 9: Relation of BSTs to Quicksort - Analysis of Random BST
        </span>
    </h1>
        		</div>
           		<div class="clear"></div>
           		<div id="course_wrapper_media">
           			<div id="course_nav">
           				<script language="javascript" type="text/javascript">
function toggleMenu(objID) {
  if (!document.getElementById) return;
  var ob = document.getElementById(objID);
  ob.className = (ob.className == 'selected')?'': 'selected';
}
function toggleClass(id)
{
  var divtoggleClass= document.getElementById(id);
  divtoggleClass.className = (divtoggleClass.className == 'mO')?'mC': 'mO';
  return false;
}
function changeAlt(id)
{
  id.alt = (id.alt == 'Expand Menu')?'Collapse Menu' : 'Expand Menu';
  id.title = (id.title == 'Expand Menu')?'Collapse Menu' : 'Expand Menu';
}
</script><!--Left Nav Starts --><ul>
<li class="">
			   			<a href="../../../contents/index.htm">
		                  Course Home  			                
	                    </a>
		        </li>
		    
         	
	
	
	    	
	    	    <li class="">
			   			<a href="../../../contents/syllabus/index.htm">
		                  Syllabus  			                
	                    </a>
		        </li>
		    
         	
	
	
	    	
	    	    <li class="">
			   			<a href="../../../contents/calendar/index.htm">
		                  Calendar  			                
	                    </a>
		        </li>
		    
         	
	
	
	    	
	    	    <li class="">
			   			<a href="../../../contents/readings/index.htm">
		                  Readings  			                
	                    </a>
		        </li>
		    
         	
	
	
	    	
	    	    <li class="">
			   			<a href="../../../contents/assignments/index.htm">
		                  Assignments  			                
	                    </a>
		        </li>
		    
         	
	
	
	    	
	    	    <li class="">
			   			<a href="../../../contents/exams/index.htm">
		                  Exams  			                
	                    </a>
		        </li>
		    
         	
	
	
	    	
	    	    <li class="selected">
			   			<a href="../../../contents/video-lectures/index.htm">
		                  Video Lectures  			                
	                    </a>
		        </li>
		    
         	
	
	
	    	
	    	    
		    
         	
	<!--second tal block close-->  
	
</ul>
<!--Left Nav Ends -->
</div>
           			<div id="course_inner_media">
      					 
        <div class="" id="parent-fieldname-text">
            
            
        </div>
    
      					 

<script type="text/javascript">var caption_embed_1 ={'English - US': '/courses/electrical-engineering-and-computer-science/6-046j-introduction-to-algorithms-sma-5503-fall-2005/video-lectures/lecture-9-relation-of-bsts-to-quicksort-analysis-of-random-bst/vgELyZ9LXX4.srt'}</script><div id="media-embed">
         <div class="attention_message" id="embed_1">
<p>Flash and JavaScript are required for this feature.</p>
<p>Download the video from <a href="https://itunes.apple.com/us/itunes-u/id341597754">iTunes U</a> or the <a href="http://www.archive.org/download/MIT6.046JF05MPEG4/ocw-6.046-17oct2005-220k.mp4">Internet Archive</a>.</p>
</div>
     </div>
    
     <script type="text/javascript">ocw_embed_chapter_media('embed_1', 'http://www.youtube.com/v/vgELyZ9LXX4', 'youtube', '/courses/electrical-engineering-and-computer-science/6-046j-introduction-to-algorithms-sma-5503-fall-2005/video-lectures/lecture-9-relation-of-bsts-to-quicksort-analysis-of-random-bst', 'http://img.youtube.com/vi/vgELyZ9LXX4/0.jpg',0,0, 'http://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-046j-introduction-to-algorithms-sma-5503-fall-2005/video-lectures/lecture-9-relation-of-bsts-to-quicksort-analysis-of-random-bst/vgELyZ9LXX4.srt')</script><div id="transcript1"></div>
				 <script type="text/javascript">setThreePlayTranscriptPlugin(2, 1004247)</script><script type="text/javascript" src="http://p3.3playmedia.com/p3.js"></script><div id="media_resource_next_prev_nav" style="margin-top: 1em;">
        <p>
        
            <a href="../../../contents/video-lectures/lecture-8-universal-hashing-perfect-hashing/index.htm">
                <img src="../../../common/images/btn_previous_resource.png" style="margin: 0 30px 0 50px;" alt="Previous track" title="Previous track"></a>
     	
     	
        
            <a href="../../../contents/video-lectures/lecture-10-red-black-trees-rotations-insertions-deletions/index.htm"> 
                <img src="../../../common/images/btn_next_resource.png" alt="Next track" title="Next track"></a>
       
       </p>
     </div>
 


<script type="text/javascript">
		window.onload=function(){
		init();
		
		}
		var tabLinks = new Array();
		var contentDivs = new Array();
		function init() {
		  // Grab the tab links and content divs from the page
		  var tabListItems = document.getElementById('tabs').childNodes;
		  for ( var i = 0; i < tabListItems.length; i++ ) {
			if ( tabListItems[i].nodeName == "LI" ) {
			  var tabLink = getFirstChildWithTagName( tabListItems[i], 'A' );
			  var id = getHash( tabLink.getAttribute('href') );
			  tabLinks[id] = tabLink;
			  contentDivs[id] = document.getElementById( id );
			}
		  }
		  // Assign onclick events to the tab links, and
		  // highlight the first tab
		  var i = 0;
		  for ( var id in tabLinks ) {
			tabLinks[id].onclick = showTab;
			tabLinks[id].onfocus = function() { this.blur() };
			if ( i == 0 ) tabLinks[id].className = 'selected';
			i++;
		  }
		  // Hide all content divs except the first
		  var i = 0;
		  for ( var id in contentDivs ) {
			if ( i != 0 ) contentDivs[id].className = 'tabContent hide';
			i++;
		  }
		}
		function showTab() {
		  var selectedId = getHash( this.getAttribute('href') );
		  // Highlight the selected tab, and dim all others.
		  // Also show the selected content div, and hide all others.
		  for ( var id in contentDivs ) {
			if ( id == selectedId ) {
			  tabLinks[id].className = 'selected';
			  contentDivs[id].className = 'tabContent';
			} else {
			  tabLinks[id].className = '';
			  contentDivs[id].className = 'tabContent hide';
			}
		  }
		  // Stop the browser following the link
		  return false;
		}
		function getFirstChildWithTagName( element, tagName ) {
		  for ( var i = 0; i < element.childNodes.length; i++ ) {
			if ( element.childNodes[i].nodeName == tagName ) return element.childNodes[i];
		  }
		}
		function getHash( url ) {
		  var hashPos = url.lastIndexOf ( '#' );
		  return url.substring( hashPos + 1 );
		}
 </script><div id="media_tabs">
     
        <ul id="tabs">
<li class="first">
                <a href="#vid_about" class="selected">About this Video</a>
            </li>
            <li class="">
                <a href="#vid_index" class="">Playlist</a>
            </li>
            <li class="">
                <a href="#vid_playlist" class="">Related Resources</a>
            </li>
            <li class="">
                <a href="#vid_related" class="">Transcript</a>
            </li>
            <li class="">
                <a href="#vid_transcript" class="">Download this Video</a>
            </li>
        </ul>
<div id="vid_about" itemprop="description" class="tabContent">
<p><b>Topics covered:</b> Relation of BSTs to Quicksort - Analysis of Random BST</p>
<p><b>Instructors:</b> Prof. Erik Demaine, Prof. Charles Leiserson </p>
</div>
        <div id="vid_index" itemprop="description" class="tabContent hide">
<div class="related-media-thumbnail">
<a href="../../../contents/video-lectures/lecture-1-administrivia-introduction-analysis-of-algorithms-insertion-sort-mergesort/index.htm">
<img src="../../../contents/video-lectures/lecture-1-administrivia-introduction-analysis-of-algorithms-insertion-sort-mergesort/6_046J_lec01_th.jpg" title="Lecture 1: Administrivia; Introduction; Analysis of Algorithms, Insertion Sort, Mergesort" alt="Lecture 1: Administrivia; Introduction; Analysis of Algorithms, Insertion Sort, Mergesort"><p>Lecture 1: Administrivia; I...</p></a>
</div>
<div class="related-media-thumbnail">
<a href="../../../contents/video-lectures/lecture-2-asymptotic-notation-recurrences-substitution-master-method/index.htm">
<img src="../../../contents/video-lectures/lecture-2-asymptotic-notation-recurrences-substitution-master-method/6_046J_lec02_th.jpg" title="Lecture 2: Asymptotic Notation; Recurrences; Substitution, Master Method" alt="Lecture 2: Asymptotic Notation; Recurrences; Substitution, Master Method"><p>Lecture 2: Asymptotic Notat...</p></a>
</div>
<div class="related-media-thumbnail">
<a href="../../../contents/video-lectures/lecture-3-divide-and-conquer-strassen-fibonacci-polynomial-multiplication/index.htm">
<img src="../../../contents/video-lectures/lecture-3-divide-and-conquer-strassen-fibonacci-polynomial-multiplication/6_046J_lec03_th.jpg" title="Lecture 3: Divide-and-Conquer: Strassen, Fibonacci, Polynomial Multiplication" alt="Lecture 3: Divide-and-Conquer: Strassen, Fibonacci, Polynomial Multiplication"><p>Lecture 3: Divide-and-Conqu...</p></a>
</div>
<div class="related-media-thumbnail">
<a href="../../../contents/video-lectures/lecture-4-quicksort-randomized-algorithms/index.htm">
<img src="../../../contents/video-lectures/lecture-4-quicksort-randomized-algorithms/6_046J_lec04_th.jpg" title="Lecture 4: Quicksort, Randomized Algorithms" alt="Lecture 4: Quicksort, Randomized Algorithms"><p>Lecture 4: Quicksort, Rando...</p></a>
</div>
<div class="related-media-thumbnail">
<a href="../../../contents/video-lectures/lecture-5-linear-time-sorting-lower-bounds-counting-sort-radix-sort/index.htm">
<img src="../../../contents/video-lectures/lecture-5-linear-time-sorting-lower-bounds-counting-sort-radix-sort/6_046J_lec05_th.jpg" title="Lecture 5: Linear-time Sorting: Lower Bounds, Counting Sort, Radix Sort" alt="Lecture 5: Linear-time Sorting: Lower Bounds, Counting Sort, Radix Sort"><p>Lecture 5: Linear-time Sort...</p></a>
</div>
<div class="related-media-thumbnail">
<a href="../../../contents/video-lectures/lecture-6-order-statistics-median/index.htm">
<img src="../../../contents/video-lectures/lecture-6-order-statistics-median/6_046J_lec06_th.jpg" title="Lecture 6: Order Statistics, Median" alt="Lecture 6: Order Statistics, Median"><p>Lecture 6: Order Statistics...</p></a>
</div>
<div class="related-media-thumbnail">
<a href="../../../contents/video-lectures/lecture-7-hashing-hash-functions/index.htm">
<img src="../../../contents/video-lectures/lecture-7-hashing-hash-functions/6_046J_lec07_th.jpg" title="Lecture 7: Hashing, Hash Functions" alt="Lecture 7: Hashing, Hash Functions"><p>Lecture 7: Hashing, Hash Fu...</p></a>
</div>
<div class="related-media-thumbnail">
<a href="../../../contents/video-lectures/lecture-8-universal-hashing-perfect-hashing/index.htm">
<img src="../../../contents/video-lectures/lecture-8-universal-hashing-perfect-hashing/6_046J_lec08_th.jpg" title="Lecture 8: Universal Hashing, Perfect Hashing" alt="Lecture 8: Universal Hashing, Perfect Hashing"><p>Lecture 8: Universal Hashin...</p></a>
</div>
<div class="related-media-thumbnail-nolink">
<div class="now-playing-resource">Now Playing</div>
<img src="../../../contents/video-lectures/lecture-9-relation-of-bsts-to-quicksort-analysis-of-random-bst/6_046J_lec09_th.jpg" title="Lecture 9: Relation of BSTs to Quicksort - Analysis of Random BST" alt="Lecture 9: Relation of BSTs to Quicksort - Analysis of Random BST"><p>Lecture 9: Relation of BSTs...</p>
</div>
<div class="related-media-thumbnail">
<a href="../../../contents/video-lectures/lecture-10-red-black-trees-rotations-insertions-deletions/index.htm">
<img src="../../../contents/video-lectures/lecture-10-red-black-trees-rotations-insertions-deletions/6_046J_lec10_th.jpg" title="Lecture 10: Red-black Trees, Rotations, Insertions, Deletions" alt="Lecture 10: Red-black Trees, Rotations, Insertions, Deletions"><p>Lecture 10: Red-black Trees...</p></a>
</div>
<div class="related-media-thumbnail">
<a href="../../../contents/video-lectures/lecture-11-augmenting-data-structures-dynamic-order-statistics-interval-trees/index.htm">
<img src="../../../contents/video-lectures/lecture-11-augmenting-data-structures-dynamic-order-statistics-interval-trees/6_046J_lec11_th.jpg" title="Lecture 11: Augmenting Data Structures, Dynamic Order Statistics, Interval Trees" alt="Lecture 11: Augmenting Data Structures, Dynamic Order Statistics, Interval Trees"><p>Lecture 11: Augmenting Data...</p></a>
</div>
<div class="related-media-thumbnail">
<a href="../../../contents/video-lectures/lecture-12-skip-lists/index.htm">
<img src="../../../contents/video-lectures/lecture-12-skip-lists/6_046J_lec12_th.jpg" title="Lecture 12: Skip Lists" alt="Lecture 12: Skip Lists"><p>Lecture 12: Skip Lists</p></a>
</div>
<div class="related-media-thumbnail">
<a href="../../../contents/video-lectures/lecture-13-amortized-algorithms-table-doubling-potential-method/index.htm">
<img src="../../../contents/video-lectures/lecture-13-amortized-algorithms-table-doubling-potential-method/6_046J_lec13_th.jpg" title="Lecture 13: Amortized Algorithms, Table Doubling, Potential Method" alt="Lecture 13: Amortized Algorithms, Table Doubling, Potential Method"><p>Lecture 13: Amortized Algor...</p></a>
</div>
<div class="related-media-thumbnail">
<a href="../../../contents/video-lectures/lecture-14-competitive-analysis-self-organizing-lists/index.htm">
<img src="../../../contents/video-lectures/lecture-14-competitive-analysis-self-organizing-lists/6_046J_lec14_th.jpg" title="Lecture 14: Competitive Analysis: Self-organizing Lists" alt="Lecture 14: Competitive Analysis: Self-organizing Lists"><p>Lecture 14: Competitive Ana...</p></a>
</div>
<div class="related-media-thumbnail">
<a href="../../../contents/video-lectures/lecture-15-dynamic-programming-longest-common-subsequence/index.htm">
<img src="../../../contents/video-lectures/lecture-15-dynamic-programming-longest-common-subsequence/6_046J_lec15_th.jpg" title="Lecture 15: Dynamic Programming, Longest Common Subsequence" alt="Lecture 15: Dynamic Programming, Longest Common Subsequence"><p>Lecture 15: Dynamic Program...</p></a>
</div>
<div class="related-media-thumbnail">
<a href="../../../contents/video-lectures/lecture-16-greedy-algorithms-minimum-spanning-trees/index.htm">
<img src="../../../contents/video-lectures/lecture-16-greedy-algorithms-minimum-spanning-trees/6_046J_lec16_th.jpg" title="Lecture 16: Greedy Algorithms, Minimum Spanning Trees" alt="Lecture 16: Greedy Algorithms, Minimum Spanning Trees"><p>Lecture 16: Greedy Algorith...</p></a>
</div>
<div class="related-media-thumbnail">
<a href="../../../contents/video-lectures/lecture-17-shortest-paths-i-properties-dijkstras-algorithm-breadth-first-search/index.htm">
<img src="../../../contents/video-lectures/lecture-17-shortest-paths-i-properties-dijkstras-algorithm-breadth-first-search/6_046J_lec17_th.jpg" title="Lecture 17: Shortest Paths I: Properties, Dijkstra's Algorithm, Breadth-first Search" alt="Lecture 17: Shortest Paths I: Properties, Dijkstra's Algorithm, Breadth-first Search"><p>Lecture 17: Shortest Paths ...</p></a>
</div>
<div class="related-media-thumbnail">
<a href="../../../contents/video-lectures/lecture-18-shortest-paths-ii-bellman-ford-linear-programming-difference-constraints/index.htm">
<img src="../../../contents/video-lectures/lecture-18-shortest-paths-ii-bellman-ford-linear-programming-difference-constraints/6_046J_lec18_th.jpg" title="Lecture 18: Shortest Paths II: Bellman-Ford, Linear Programming, Difference Constraints" alt="Lecture 18: Shortest Paths II: Bellman-Ford, Linear Programming, Difference Constraints"><p>Lecture 18: Shortest Paths ...</p></a>
</div>
<div class="related-media-thumbnail">
<a href="../../../contents/video-lectures/lecture-19-shortest-paths-iii-all-pairs-shortest-paths-matrix-multiplication-floyd-warshall-johnson/index.htm">
<img src="../../../contents/video-lectures/lecture-19-shortest-paths-iii-all-pairs-shortest-paths-matrix-multiplication-floyd-warshall-johnson/6_046J_lec19_th.jpg" title="Lecture 19: Shortest Paths III: All-pairs Shortest Paths, Matrix Multiplication, Floyd-Warshall, Johnson" alt="Lecture 19: Shortest Paths III: All-pairs Shortest Paths, Matrix Multiplication, Floyd-Warshall, Johnson"><p>Lecture 19: Shortest Paths ...</p></a>
</div>
<div class="related-media-thumbnail">
<a href="../../../contents/video-lectures/lecture-22-advanced-topics/index.htm">
<img src="../../../contents/video-lectures/lecture-22-advanced-topics/6_046J_lec22_th.jpg" title="Lecture 22: Advanced Topics" alt="Lecture 22: Advanced Topics"><p>Lecture 22: Advanced Topics</p></a>
</div>
<div class="related-media-thumbnail">
<a href="../../../contents/video-lectures/lecture-23-advanced-topics-cont./index.htm">
<img src="../../../contents/video-lectures/lecture-23-advanced-topics-cont./6_046J_lec23_th.jpg" title="Lecture 23: Advanced Topics (cont.)" alt="Lecture 23: Advanced Topics (cont.)"><p>Lecture 23: Advanced Topics...</p></a>
</div>
<div class="related-media-thumbnail">
<a href="../../../contents/video-lectures/lecture-24-advanced-topics-cont./index.htm">
<img src="../../../contents/video-lectures/lecture-24-advanced-topics-cont./6_046J_lec24_th.jpg" title="Lecture 24: Advanced Topics (cont.)" alt="Lecture 24: Advanced Topics (cont.)"><p>Lecture 24: Advanced Topics...</p></a>
</div>
<div class="related-media-thumbnail">
<a href="../../../contents/video-lectures/lecture-25-advanced-topics-cont.-discussion-of-follow-on-classes/index.htm">
<img src="../../../contents/video-lectures/lecture-25-advanced-topics-cont.-discussion-of-follow-on-classes/6_046J_lec25_th.jpg" title="Lecture 25: Advanced Topics (cont.) - Discussion of Follow-on Classes" alt="Lecture 25: Advanced Topics (cont.) - Discussion of Follow-on Classes"><p>Lecture 25: Advanced Topics...</p></a>
</div>
</div>
        <div id="vid_playlist" itemprop="description" class="tabContent hide">
<h2 class="subhead">Related Resources</h2>
<p>Lecture Notes (<a target="_blank" href="../../../contents/video-lectures/lecture-9-relation-of-bsts-to-quicksort-analysis-of-random-bst/lec9.pdf">PDF</a>)<br><a target="_blank" href="../../../contents/assignments/index.htm">Assignments</a><br><a target="_blank" href="../../../contents/exams/index.htm">Exams</a></p>
</div>
        <div id="vid_related" itemprop="description" class="tabContent hide">
<ul><li><a class="transcript-link" title="Open in a new window." alt="Open in a new window." style="text-decoration: none; font-size: 1.0em;" target="_blank" text-decoration: none font-size: href="../../../contents/video-lectures/lecture-9-relation-of-bsts-to-quicksort-analysis-of-random-bst/vgELyZ9LXX4.pdf"> Download this transcript - PDF (English - US)</a></li></ul>
<p><span m="11000"> So, we're going to talk today about binary search trees.</span> <span m="17000">It's something called randomly built binary search trees.</span> <span m="23000">And, I'll abbreviate binary search trees as BST's throughout</span> <span m="29000">the lecture. And, you of all seen binary</span> <span m="33000">search trees in one place or another, in particular,</span> <span m="39000">recitation on Friday. So, we're going to build up the</span> <span m="45000">basic ideas presented there, and talk about how to randomize</span> <span m="49000">them, and make them good. So, you know that there are</span> <span m="54000">good binary search trees, which are relatively balanced,</span> <span m="58000">something like this. The height is log n.</span> <span m="62000">We called unbalanced, and that's good.</span> <span m="64000">Anything order log n will be fine.</span> <span m="66000">In terms of searching, it will then cost order log n.</span> <span m="70000">And, there are bad binary search trees which have really</span> <span m="74000">large height, possibly as big as n.</span> <span m="76000">So, this is good, and this is bad.</span> <span m="79000">We'd sort of like to know, we'd like to build binary</span> <span m="82000">search trees in such a way that they are good all the time,</span> <span m="86000">or at least most of the time. There are lots of ways to do</span> <span m="91000">this, and in the next couple of weeks, we will see four of them,</span> <span m="96000">if you count the problem set, I believe.</span> <span m="99000">Today, we are going to use randomization to make them</span> <span m="102000">balanced most of the time in a certain sense.</span> <span m="105000">And then, in your problem set, you will make that in a broader</span> <span m="109000">sense. But, one way to motivate this</span> <span m="112000">topic, so I'm not going to define randomly built binary</span> <span m="116000">search trees for a little bit. One way to motivate the topic</span> <span m="120000">is through sorting, our good friend.</span> <span m="124000">So, there's a natural way to sort n numbers using binary</span> <span m="129000">search trees. So, if I give you an array,</span> <span m="133000">A, how would you sort that array using binary search tree</span> <span m="138000">operations as a black box? Build the binary search tree,</span> <span m="143000">and then traverse it in order. Exactly.</span> <span m="147000">So, let's say we have some initial tree,</span> <span m="150000">which is empty, and then for each element of</span> <span m="155000">the array, we insert it into the tree.</span> <span m="160000">That's what you meant by building the search tree.</span> <span m="166000">So, we insert AI into the tree. This is the binary search tree</span> <span m="173000">insertion, standard insertion. And then, we do an in order</span> <span m="180000">traversal, which in the book is called in order tree walk.</span> <span m="189000">OK, you should know these algorithms are,</span> <span m="191000">but just for very quick reminder, tree insert basically</span> <span m="194000">searches for that element AI until it finds the place where</span> <span m="198000">it should have been if it was in the tree already,</span> <span m="201000">and then adds a new leaf there to insert that value.</span> <span m="204000">Tree walk recursively walks the left subtree,</span> <span m="207000">then prints out the root, and then recursively walks the</span> <span m="210000">right subtree. And, by the binary search tree</span> <span m="213000">property, that will print the elements out in sorted order.</span> <span m="218000">So, let's do a quick example because this turns out to be</span> <span m="223000">related to another sorting algorithm we've seen already.</span> <span m="228000">So, while the example is probably pretty trivial,</span> <span m="232000">the connection is pretty surprising.</span> <span m="235000">At least, it was to me the first time I taught this class.</span> <span m="242000">So, my array is three, one, eight, two,</span> <span m="244000">six, seven, five. And, I'm going to visit these</span> <span m="248000">elements in order from left to right, and just build a tree.</span> <span m="252000">So, the first element I see is three.</span> <span m="255000">So, I insert three into an empty tree.</span> <span m="258000">That requires no comparisons. Then I insert one.</span> <span m="261000">I see, is one bigger or less than three?</span> <span m="264000">It's smaller. So, I put it over here.</span> <span m="267000">Then I insert eight. That's bigger than three,</span> <span m="271000">so it get's a new leaf over here.</span> <span m="275000">Then I insert two. That sits between one and</span> <span m="278000">three. And so, it would fall off this</span> <span m="281000">right child of one. So, I add two there.</span> <span m="284000">Six is bigger than three, and less than eight.</span> <span m="288000">So, it goes here. Seven is bigger than three,</span> <span m="291000">and less than eight, bigger than six.</span> <span m="294000">So, it goes here, and five fits in between three</span> <span m="298000">and five, three and six rather. And so, that's the binary</span> <span m="303000">search tree that again. Then I run an in order</span> <span m="306000">traversal, which will print one, two, three, five,</span> <span m="310000">six, seven, eight. OK, I can run I quickly in my</span> <span m="313000">head because I've got a big stack.</span> <span m="315000">I've got to be a little bit careful.</span> <span m="318000">Of course, you should check that they come out in sorted</span> <span m="322000">order: one, two, three, five,</span> <span m="324000">six, seven, eight. And, if you don't have a big</span> <span m="327000">stack, you can go and buy one. That's always useful.</span> <span m="332000">Memory costs are going up a bit these days, or going down.</span> <span m="336000">They should be because of politics, but price-fixing,</span> <span m="340000">or whatever. So, the question is,</span> <span m="343000">what's the running time of the algorithm?</span> <span m="346000">Here, this is one of those answers where it depends.</span> <span m="350000">The parts that are easy to analyze are, well,</span> <span m="353000">initialization. The in order tree walk,</span> <span m="356000">how long does that take? n, good.</span> <span m="360000">So, it's order n for the walk, and for the initialization,</span> <span m="365000">which is constant. The question is,</span> <span m="368000">how long does it take me to do n tree inserts?</span> <span m="381000">Anyone want to guess any kind of answer to that question,</span> <span m="386000">other than it depends? I've already stolen the thunder</span> <span m="392000">there. Yeah?</span> <span m="394000">Big Omega of n log n, that's good.</span> <span m="398000">It's at least n log n. Why?</span> <span m="416000">Right. So, you gave two reasons.</span> <span m="418000">The first one is because of the decision tree lower bound.</span> <span m="422000">That doesn't actually prove this.</span> <span m="424000">You have to be a little bit careful.</span> <span m="427000">This is a claim that it's omega n log n all the time.</span> <span m="430000">It's certainly omega n log n in the worst case.</span> <span m="434000">Every comparison-based sorting algorithm is omega n log n in</span> <span m="438000">the worst case. It's also n log n every single</span> <span m="441000">time, omega n log n because of the second reason you gave,</span> <span m="445000">which is the best thing that could happen is we have a</span> <span m="449000">perfectly balanced tree. So, this is the figure that I</span> <span m="453000">have drawn the most on a blackboard in my life,</span> <span m="456000">the perfect tree on 15 nodes, I guess.</span> <span m="461000">So, if we're lucky, we have this.</span> <span m="462000">And if you add up all the depths of the nodes here,</span> <span m="465000">which gives you the search tree cost, in particular,</span> <span m="468000">these n over two nodes in the bottom, each have depth log n.</span> <span m="472000">And, therefore, you're going to have to pay it</span> <span m="474000">least n log n for those. And, if you're less balanced,</span> <span m="477000">it's going to be even worse. That takes some proving,</span> <span m="482000">but it's true. So, it's actually omega n log n</span> <span m="488000">all the time. OK, there are some cases,</span> <span m="493000">like you do know that the elements are almost already in</span> <span m="499000">order, you can do it in linear number comparisons.</span> <span m="505000">But here, you can't. Any other guesses at an answer</span> <span m="512000">to this question? Yeah?</span> <span m="514000">Big O n^2? Good, why?</span> <span m="519000">Right. We are doing n things,</span> <span m="521000">and each node has depth, at most, n.</span> <span m="524000">So, the number of comparisons we're making per element we</span> <span m="529000">insert, is, at most, n.</span> <span m="531000">So that's, at most, n^2.</span> <span m="533000">Any other answers? Is it possible for this</span> <span m="536000">algorithm to take n^2 time? Are there instances where it</span> <span m="543000">takes theta n^2? If it's already sorted,</span> <span m="548000">that would be pretty bad. So, if it's already sorted or</span> <span m="554000">if it's reverse sorted, you are in bad shape because</span> <span m="561000">then you get a tree like this. This is the sorted case.</span> <span m="567000">And, you compute. So, the total cost,</span> <span m="572000">the time in general is going to be the sum of the depths of the</span> <span m="578000">nodes for each node, X, in the tree.</span> <span m="581000">And in this case, it's one plus two plus three</span> <span m="585000">plus four, this arithmetic series.</span> <span m="588000">There's n of them, so this is theta n squared.</span> <span m="592000">It's like n^2 over two. So, that's bad news.</span> <span m="596000">The worst-case running time of this algorithm is n^2.</span> <span m="603000">Does that sound familiar at all, and algorithms worst-case</span> <span m="608000">running time is n^2, in particular,</span> <span m="611000">in the already-sorted case? But if we're lucky,</span> <span m="616000">at the lucky case, as we said, it's a balanced</span> <span m="620000">tree. Wouldn't that be great?</span> <span m="623000">Anything with omega log n height would give us a sorting</span> <span m="628000">algorithm that runs in n log n. So, in the lucky case,</span> <span m="636000">we are n log n. But in the unlucky case,</span> <span m="643000">we are n^2 and unlucky use sorted.</span> <span m="648000">Does it remind you of any algorithm we've seen before?</span> <span m="657000">Quicksort. It turns out the running time</span> <span m="662000">of this algorithm is the same as the running time of quicksort in</span> <span m="669000">a very strong sense. It turns out the comparisons</span> <span m="673000">that this algorithm makes are exactly the same comparisons</span> <span m="679000">that quicksort makes. It makes them in a different</span> <span m="684000">order, but it's really the same algorithm in disguise.</span> <span m="689000">That's the surprise here. So, in particular,</span> <span m="694000">we've already analyzed quicksort.</span> <span m="696000">We should get something for free out of that analysis.</span> <span m="714000">So, the relation is, BST sort and quicksort make the</span> <span m="725000">same comparisons but in a different order.</span> <span m="745000">So, let me walk through the same example we did before:</span> <span m="749000">three, one, eight, two, six, seven,</span> <span m="753000">five. So, there is an array.</span> <span m="755000">We are going to run a particular version of quicksort.</span> <span m="760000">I have to be a little bit careful here.</span> <span m="763000">It's sort of the obvious version of quicksort.</span> <span m="767000">Remember, our standard, boring quicksort is you take</span> <span m="772000">the first element as the partition element.</span> <span m="776000">So, I'll take three here. And, I split into the elements</span> <span m="781000">less than three, which is one and two.</span> <span m="784000">And, the elements bigger than three, which is eight,</span> <span m="787000">six, seven, five. And, in this version of</span> <span m="789000">quicksort, I don't change the order of the elements,</span> <span m="792000">eight, six, seven, five.</span> <span m="793000">So, let's say the order is preserved because only then will</span> <span m="797000">this equivalence hold. So, this is sort of a stable</span> <span m="800000">partition algorithm. It's easy enough to do.</span> <span m="802000">It's a particular version of quicksort.</span> <span m="805000">And soon, we're going to randomize it.</span> <span m="807000">And after we randomize, this difference doesn't matter.</span> <span m="812000">OK, then on the left recursion, we split in the partition</span> <span m="815000">element. There is things less than one,</span> <span m="818000">which is nothing, things bigger than one,</span> <span m="821000">which is two. And then, that's our partition</span> <span m="824000">element. We are done.</span> <span m="825000">Over here, we partition on eight.</span> <span m="828000">Everything is less than eight. So, we get six,</span> <span m="831000">seven, five, nothing on the right.</span> <span m="833000">Then we partition at six. We get things less than six,</span> <span m="837000">mainly five, things bigger than six,</span> <span m="839000">mainly seven. And, those are sort of</span> <span m="843000">partition elements in a trivial way.</span> <span m="846000">Now, this tree that we get on the partition elements looks an</span> <span m="851000">awful lot like this tree. OK, it should be exactly the</span> <span m="856000">same tree. And, you can walk through,</span> <span m="859000">what comparisons does quicksort make?</span> <span m="862000">Well, first, it compares everything to</span> <span m="865000">three, OK, except three itself. Now, if you look over here,</span> <span m="870000">what happens when we are inserting elements?</span> <span m="872000">Well, each time we insert an element, the first thing we do</span> <span m="875000">is compare with three. If it's less than,</span> <span m="877000">we go to the left branch. If it's greater than,</span> <span m="880000">we go to the right branch. So, we are making all these</span> <span m="883000">comparisons with three in both cases.</span> <span m="884000">Then, if we have an element less than three,</span> <span m="887000">it's either one or two. If it's one,</span> <span m="889000">we're done. No comparisons happen here one</span> <span m="891000">to one. But, we compare two to one.</span> <span m="892000">And indeed, when we insert two over there after comparing it to</span> <span m="896000">three, we compare it to one. And then we figure out that it</span> <span m="899000">happens here. Same thing happens in</span> <span m="901000">quicksort. For elements greater than</span> <span m="904000">three, we compare everyone to eight here because we are</span> <span m="908000">partitioning with respect to eight, and here because that's</span> <span m="912000">the next node after three. As soon as eight is inserted,</span> <span m="916000">we compare everything with eight to see in fact that's less</span> <span m="920000">than eight, and so on: so, all of the same</span> <span m="923000">comparisons, just in a different order.</span> <span m="925000">So, we turn 90∞. Kind of cool.</span> <span m="929000">So, this has various consequences in the analysis.</span> <span m="950000">So, in particular, the worst-case running time is</span> <span m="954000">theta n^2, which is not so exciting.</span> <span m="958000">What we really care about is the randomized version because</span> <span m="964000">that's what performs well. So, randomized BST sort is just</span> <span m="970000">like randomized quicksort. So, the first thing you do is</span> <span m="976000">randomly permute the array uniformly, picking all</span> <span m="981000">permutations with equal probability.</span> <span m="984000">And then, we call BST sort. OK, this is basically what</span> <span m="991000">randomized quicksort could be formulated as.</span> <span m="995000">And then, randomized BST sort is going to make exactly the</span> <span m="1000000">same comparisons as randomized quicksort.</span> <span m="1003000">Here, we are picking the root essentially randomly.</span> <span m="1008000">And here in quicksort, you are picking the partition</span> <span m="1012000">elements randomly. It's the same difference.</span> <span m="1016000">OK, so the time of this algorithm equals the time of</span> <span m="1020000">randomized quicksort because we are making the same comparisons.</span> <span m="1028000">So, the number of comparisons is equal.</span> <span m="1030000">And this is true as random variables.</span> <span m="1031000">The random variable, the running time,</span> <span m="1033000">this algorithm is equal to the random variable of this</span> <span m="1036000">algorithm. In particular,</span> <span m="1037000">the expectations are the same.</span> <span m="1053000">OK, and we know that the expected running time of</span> <span m="1057000">randomized quicksort on n elements is?</span> <span m="1060000">Oh boy. n log n.</span> <span m="1062000">Good. I was a little worried there.</span> <span m="1065000">OK, so in particular, the expected running time of</span> <span m="1069000">BST sort is n log n. Obviously, this is not too</span> <span m="1073000">exciting from a sorting point of view.</span> <span m="1077000">Sorting was just sort of to see this connection.</span> <span m="1083000">What we actually care about, and the reason I've introduced</span> <span m="1085000">this BST sort is what the tree looks like.</span> <span m="1088000">What we really want is that search tree.</span> <span m="1090000">The search tree can do more than sort.</span> <span m="1091000">n order traversals are a pretty boring thing to do with the</span> <span m="1094000">search tree. You can search in a search</span> <span m="1096000">tree. So, OK, that's still not so</span> <span m="1098000">exciting. You could sort the elements and</span> <span m="1100000">then put them in an array and do binary search.</span> <span m="1102000">But, the point of binary search trees, instead of binary search</span> <span m="1106000">arrays, is that you can update them dynamically.</span> <span m="1108000">We won't be updating them dynamically in this lecture,</span> <span m="1111000">and we will in Wednesday and on your problem set.</span> <span m="1115000">For now, it's just sort of warm-up.</span> <span m="1116000">Let's say that the elements aren't changing.</span> <span m="1119000">We are building one tree from the beginning.</span> <span m="1121000">We have all n elements ahead of time.</span> <span m="1123000">We are going to build it randomly.</span> <span m="1125000">We randomly permute that array. Then we throw all the elements</span> <span m="1129000">into a binary search tree. That's what BST sort does.</span> <span m="1132000">Then it calls n order traversal.</span> <span m="1134000">I don't really care about n order traversal.</span> <span m="1136000">What I want, because we've just analyzed it.</span> <span m="1140000">It would be a short lecture if I were done.</span> <span m="1144000">What we want is this randomly built BST, which is what we get</span> <span m="1151000">out of this algorithm. So, this is the tree resulting</span> <span m="1158000">from randomized BST sort, OK, resulting from randomly</span> <span m="1164000">permute in the array of just inserting those elements using</span> <span m="1170000">the simple tree insert algorithm.</span> <span m="1176000">The question is, what does that tree look like?</span> <span m="1180000">And in particular, is there anything we can</span> <span m="1185000">conclude out of this fact? The expected running time of</span> <span m="1190000">BST sort is n log n. OK, I've mentioned cursorily</span> <span m="1195000">what the running time of BST sort is, several times.</span> <span m="1202000">It was the sum. So, this is the time of BST</span> <span m="1206000">sort on n elements. It's the sum over all nodes,</span> <span m="1211000">X, of the depth of that node. OK, depth starts at zero and</span> <span m="1217000">works its way down because the root element,</span> <span m="1221000">you don't make any comparisons beyond that, you are making</span> <span m="1227000">whatever the depth is comparisons.</span> <span m="1232000">OK, so we know that this thing is, in expectation we know that</span> <span m="1240000">this is n log n. What does that tell us about</span> <span m="1247000">the tree? This is for all nodes,</span> <span m="1252000">X, in the tree. Does it tell us anything about</span> <span m="1258000">the height of the tree, for example?</span> <span m="1263000">Yeah? Right, intuitively,</span> <span m="1267000">it says that the height of the tree is theta log n,</span> <span m="1271000">and not n. But, in fact,</span> <span m="1273000">it doesn't show that. And that's why if you feel that</span> <span m="1277000">that's just intuition, but it may not be quite right.</span> <span m="1281000">Indeed it's not. Let me tell you what it does</span> <span m="1284000">say. So, if we take expectation of</span> <span m="1287000">both sides, here we get n log n. So, the expected value of that</span> <span m="1291000">is n log n. So, over here,</span> <span m="1295000">well, we get the expected total depth, which is not so exciting.</span> <span m="1301000">Let's look at the expected average depth.</span> <span m="1305000">So, if I look at one over n, the sum over all n nodes in the</span> <span m="1311000">tree of the depth of X, that would be the average depth</span> <span m="1317000">over all the nodes. And what I should get is theta</span> <span m="1322000">n log n over n because I divided n on both sides.</span> <span m="1326000">And, I'm using, here, linearity of expectation,</span> <span m="1330000">which is log n. So, what this fact about the</span> <span m="1334000">expected running time tells me is that the average depth in the</span> <span m="1339000">tree is log n, which is not quite the height</span> <span m="1343000">of the tree being log n.</span> <span m="1355000">OK, remember the height of the tree is the maximum depth of any</span> <span m="1359000">node. Here, we are just bounding the</span> <span m="1361000">average depth.</span> <span m="1384000">Let's look at an example of a tree.</span> <span m="1388000">I'll draw my favorite picture. So, here we have a nice</span> <span m="1394000">balanced tree, let's say, on half of the nodes</span> <span m="1400000">or a little more. And then, I have one really</span> <span m="1405000">long path hanging off one particular leaf.</span> <span m="1410000">It doesn't matter which one. And, I'm going to say that this</span> <span m="1417000">path has length, with a total height here,</span> <span m="1421000">I want to make root n, which is a lot bigger than log</span> <span m="1425000">n. This is roughly log n.</span> <span m="1427000">It's going to be log of n minus root n, or so,</span> <span m="1431000">roughly. So, most of the nodes have</span> <span m="1434000">logarithmic height and, sorry, logarithmic depth.</span> <span m="1438000">If you compute the average depth in this particular tree,</span> <span m="1443000">for most of the nodes, let's say it's,</span> <span m="1446000">at most, n of the nodes have height log n.</span> <span m="1452000">And then, there are root n nodes, at most,</span> <span m="1455000">down here, which have depth, at most, root n.</span> <span m="1459000">So, it's, at most, root n times root n.</span> <span m="1462000">In fact, it's like half that, but not a big deal.</span> <span m="1466000">So, this is n. So, this is n log n,</span> <span m="1469000">or, sorry, average depth: I have to divide everything by</span> <span m="1474000">n. n log n would be rather large</span> <span m="1478000">for an average height, average depth.</span> <span m="1482000">So, the average depth here is log n, but the height of the</span> <span m="1488000">tree is square root of n. So, this is not enough.</span> <span m="1493000">Just to know that the average depth is log n doesn't mean that</span> <span m="1499000">the height is log n. OK, but the claim is this</span> <span m="1504000">theorem for today is that the expected height of a randomly</span> <span m="1510000">built binary search tree is indeed log n.</span> <span m="1516000">BST is order log n. This is what we like to know</span> <span m="1521000">because that tells us, if we just build a binary</span> <span m="1526000">search tree randomly, then we can search in it in log</span> <span m="1531000">n time. OK, for sorting,</span> <span m="1534000">it's not as big a deal. We just care about the expected</span> <span m="1538000">running time of creating the thing.</span> <span m="1541000">Here, now we know that once we prove this theorem,</span> <span m="1544000">we know that we can search quickly in expectation,</span> <span m="1548000">in fact, most of the time. So, the rest of today's lecture</span> <span m="1553000">will be proving this theorem. It's quite tricky,</span> <span m="1556000">as you might imagine. It's another big probability</span> <span m="1560000">analysis along the lines of quicksort and everything.</span> <span m="1582000">So, I'm going to start with an outline of the proof,</span> <span m="1586000">unless there are any questions about the theorem.</span> <span m="1591000">It should be pretty clear what we want to prove.</span> <span m="1595000">This is even weirder than most of the analyses we've seen.</span> <span m="1600000">It's going to use a fancy trick, which is exponentiating a</span> <span m="1605000">random variable. And to do that we need a tool</span> <span m="1610000">called Jenson's inequality. We are going to prove that</span> <span m="1614000">tool. Usually, we don't prove</span> <span m="1617000">probability tools. But this one we are going to</span> <span m="1621000">prove. It's not too hard.</span> <span m="1623000">It's also basic analysis. So, the lemma,</span> <span m="1629000">says that if we have what's called to a convex function,</span> <span m="1633000">f, and you should all know what that means, but I'll define it</span> <span m="1637000">soon in case you have forgotten. If you have a convex function,</span> <span m="1641000">f, and you have a random variable, X, you take f of the</span> <span m="1645000">expectation. That's, at most,</span> <span m="1647000">the expectation of f of that random variable.</span> <span m="1652000">Think about it enough and draw a convex function that is fairly</span> <span m="1660000">intuitive, I guess. But we will prove it.</span> <span m="1666000">What that allows us to do is instead of analyzing the random</span> <span m="1674000">variable that tells us the height of a tree,</span> <span m="1680000">so, X_n I'll call the random variable, RV,</span> <span m="1686000">of the height of a BST, randomly constructed BST on n</span> <span m="1693000">nodes we will analyze. Well, instead of analyzing this</span> <span m="1701000">desired random variable, X_n, sorry, this should have</span> <span m="1707000">been in capital X. We can analyze any convex</span> <span m="1712000">function of X_n. And, we're going to analyze the</span> <span m="1715000">exponentiation. So, I'm going to define Y_n to</span> <span m="1719000">be two to the power of X_n. OK, the big question here is</span> <span m="1723000">why bother doing this? The answer is because it works</span> <span m="1727000">and it wouldn't work if we analyze X_n.</span> <span m="1730000">We will see some intuition of that later on,</span> <span m="1734000">but it's not very intuitive. This is our analysis where you</span> <span m="1739000">need this extra trick. So, we're going to bound the</span> <span m="1743000">expectation of Y_n, and from that,</span> <span m="1745000">and using Jensen's inequality, we're going to get a bound on</span> <span m="1749000">the expectation of X_n, a pretty tight bound,</span> <span m="1752000">actually, because if we can bound the exponent up to</span> <span m="1756000">constant factors, the exponentiation up to</span> <span m="1758000">constant factors, we can bound X_n even better</span> <span m="1761000">because you take logs to get X_n.</span> <span m="1763000">So, we will even figure out what the constant is.</span> <span m="1768000">So, what we will prove, this is the heart of the proof,</span> <span m="1773000">is that the expected value of Y_n is order n^3.</span> <span m="1777000">Here, we won't really know what the constant is.</span> <span m="1782000">We don't need to. And then, we put these pieces</span> <span m="1786000">together. So, let's do that.</span> <span m="1789000">What we really care about is the expectation of X_n,</span> <span m="1794000">which is the height of our tree.</span> <span m="1797000">What we find out about is this fact.</span> <span m="1802000">So, leave some horizontal space here.</span> <span m="1805000">We get the expectation of two to the X_n.</span> <span m="1809000">That's the expectation of Y_n. So, we learned that that's</span> <span m="1814000">order n^3. And, Jensen's inequality tells</span> <span m="1818000">us that if we take this function, two to the X,</span> <span m="1823000">we plug it in here, that on the left-hand side we</span> <span m="1827000">get two to the E of X. So, we get two to the E of X_n</span> <span m="1833000">is at most E of two to the X_n. So, that's where we use</span> <span m="1838000">Jensen's inequality, because what we care about is E</span> <span m="1843000">of X_n. So now, we have a bound.</span> <span m="1846000">We say, well, two to the E of X_n is,</span> <span m="1850000">at most, n^3. So, if we take the log of both</span> <span m="1854000">sides, we get E of X_n is, at most, the log of n^3.</span> <span m="1860000">OK, I will write it in this funny way, log of order n^3,</span> <span m="1865000">which will actually tell us the constant.</span> <span m="1869000">This is three log n plus order one.</span> <span m="1872000">So, we will prove that the expected height of a randomly</span> <span m="1878000">constructed binary search tree on n nodes is roughly three log</span> <span m="1884000">n, at most. OK, I will say more about that</span> <span m="1888000">later. So, you've now seen the end of</span> <span m="1891000">the proof. That's the foreshadowing.</span> <span m="1895000">And now, this is the top-down approach.</span> <span m="1898000">So, you sort of see what the steps are.</span> <span m="1901000">Now, we just have to do the steps.</span> <span m="1904000">OK, step one: take a bit of work,</span> <span m="1906000">but it's easy because it's pretty basic stuff.</span> <span m="1910000">Step two is just a definition and we are done.</span> <span m="1914000">Step three is probably the hardest part.</span> <span m="1917000">Step four, we've already done. So, let's start with step one.</span> <span m="1936000">So, the first thing I need to do is define a convex function</span> <span m="1942000">because we are going to manipulate the definition a fair</span> <span m="1949000">amount. So, this is a notion from real</span> <span m="1953000">analysis. Analysis is a fancy word for</span> <span m="1956000">calculus if you haven't taken the proper analysis class.</span> <span m="1960000">You should have seen convexity in any calculus class.</span> <span m="1964000">A convex function is one that looks like this.</span> <span m="1967000">OK, good. One way to formalize that</span> <span m="1970000">notion is to consider any two points on this curve.</span> <span m="1973000">So, I'm only interested in functions from reals to reals.</span> <span m="1977000">So, it looks like this. This is f of something.</span> <span m="1981000">And, this is the something. If I take two points on this</span> <span m="1985000">curve, and I draw a line segment connecting them,</span> <span m="1988000">that line segment is always above the curve.</span> <span m="1991000">That's the meaning of convexity.</span> <span m="1993000">It has a geometric notion, which is basically the same.</span> <span m="1996000">But for functions, this line segment should stay</span> <span m="1999000">above the curve. The line does not stay above</span> <span m="2002000">the curve. If I extended it farther,</span> <span m="2004000">it goes beneath the curve, of course.</span> <span m="2006000">But, that segment should. So, I'm going to formalize that</span> <span m="2011000">a little bit. I'll call this x,</span> <span m="2013000">and then this is f of x. And, I'll call this y,</span> <span m="2017000">and this is f of y. So, the claim is that I take</span> <span m="2021000">any number between x and y, and I look up,</span> <span m="2024000">and I say, OK, here's the point on the curve.</span> <span m="2028000">Here's the point on the line segment.</span> <span m="2030000">The value of that point on the y value, here,</span> <span m="2034000">should be greater than or equal to the y value here,</span> <span m="2038000">OK? To figure out what the point</span> <span m="2041000">is, we need some, I would call it geometry.</span> <span m="2046000">I'm sure it's an analysis concept, too.</span> <span m="2048000">But, I'm a geometer, so I get to call it geometry.</span> <span m="2052000">If you have two points, p and q, and you want to</span> <span m="2056000">parameterize this line segment between them,</span> <span m="2059000">so, I want to parameterize some points here, the way to do it is</span> <span m="2064000">to take a linear combination. And, if you should have taken</span> <span m="2069000">some linear algebra, linear combination look</span> <span m="2072000">something like this. And, in fact,</span> <span m="2075000">we're going to take something called an affine combination</span> <span m="2079000">where alpha plus beta equals one.</span> <span m="2081000">It turns out, if you take all such points,</span> <span m="2083000">some number, alpha, times the point,</span> <span m="2085000">p, plus some number, beta times the point,</span> <span m="2088000">q, where alpha plus beta equals one.</span> <span m="2090000">If you take all those points, you get the entire line here,</span> <span m="2093000">which is nifty. But, we don't want the entire</span> <span m="2096000">line. If you also constrained alpha</span> <span m="2098000">and beta to be nonnegative, you just get this line segment.</span> <span m="2101000">So, this forces alpha and beta to be between zero and one</span> <span m="2105000">because they have to sum to one, and they are nonnegative.</span> <span m="2110000">So, what we are going to do here is take alpha times x plus</span> <span m="2114000">beta times y. That's going to be our point</span> <span m="2117000">between with these constraints: alpha plus beta equals one.</span> <span m="2122000">Alpha and beta are greater than or equal to zero.</span> <span m="2126000">Then, this point is f of that. This is f of alpha x plus beta,</span> <span m="2131000">y. And, this point is the linear</span> <span m="2134000">interpolation between f of x and f of y, the same one.</span> <span m="2138000">So, it's alpha times f of x plus beta times f of y.</span> <span m="2142000">OK, that's the intuition. If you didn't follow it,</span> <span m="2146000">it's not too big a deal because all we care about are the</span> <span m="2151000">symbolic answer for proving things.</span> <span m="2154000">But, that's where this comes from.</span> <span m="2156000">So, here's the definition. Its function is convex.</span> <span m="2163000">If, for all x and y, and all alpha and beta are</span> <span m="2169000">greater than or equal to zero, whose sum is one,</span> <span m="2176000">we have f of alpha x plus beta y is less than or equal to alpha</span> <span m="2185000">f of x plus beta f of y. So, that's just saying that</span> <span m="2192000">this y coordinate here is less than or equal to this y</span> <span m="2198000">coordinate. OK, but that's the symbolism</span> <span m="2201000">behind that picture. OK, so now we want to prove</span> <span m="2206000">Jensen's inequality. OK, we're not quite there yet.</span> <span m="2211000">We are going to prove a simple lemma, from which it will be</span> <span m="2217000">easy to derive Jenson's equality.</span> <span m="2222000">So, this is the theorem we are proving.</span> <span m="2227000">So, here's a lemma about convex functions.</span> <span m="2233000">You may have seen it before. It will be crucial to Jensen's</span> <span m="2242000">inequality. So, suppose,</span> <span m="2245000">this is a statement about affine combinations of n things</span> <span m="2254000">instead of two things. So, this will say that</span> <span m="2261000">convexity can be generalized to taking n things.</span> <span m="2266000">So, suppose we have n real numbers, and we have n values</span> <span m="2272000">alpha i, alpha one up to alpha n.</span> <span m="2275000">They are all nonnegative. And, their sum is one.</span> <span m="2280000">So, the sum of alpha k, I guess, k equals one to n,</span> <span m="2286000">is one. So, those are the assumptions.</span> <span m="2291000">The conclusion is the same thing, but summing over all k.</span> <span m="2298000">So, k equals one to n, alpha_k * x_k.</span> <span m="2302000">Take f of that versus taking the sum of the alphas times the</span> <span m="2309000">f's. k equals one to n.</span> <span m="2312000">So, the definition of convexity is exactly that statement,</span> <span m="2317000">but where n equals two. OK, alpha one and alpha two are</span> <span m="2322000">alpha and beta. This is just a statement for</span> <span m="2326000">general n. And, you can interpret this in</span> <span m="2330000">some funnier way, which I won't get into.</span> <span m="2333000">Oh, sure, why not? I'm a geometer.</span> <span m="2336000">So, this is saying you take several points on this curve.</span> <span m="2343000">You take the polygon that they define.</span> <span m="2345000">So, these are straight-line segments.</span> <span m="2347000">You take the interior. If you take an affine</span> <span m="2350000">combination like that, you will get a point inside</span> <span m="2353000">that polygon, or possibly on the boundary.</span> <span m="2356000">The claim is that all those points are above the curve.</span> <span m="2360000">Again, intuitively: true if you draw a nice,</span> <span m="2363000">canonical convex curve, but in fact,</span> <span m="2365000">it's true algebraically, too.</span> <span m="2367000">It's always a good thing. Any suggestions on how we might</span> <span m="2373000">prove this theorem, this lemma?</span> <span m="2376000">It's pretty easy. So, what technique might we use</span> <span m="2380000">to prove it? One word: induction.</span> <span m="2384000">Always a good answer, yeah.</span> <span m="2386000">Induction should shout out at you here because we already know</span> <span m="2392000">that this is true by definition of convexity for n equals two.</span> <span m="2400000">So, the base case is clear. In fact, there's an even</span> <span m="2404000">simpler base case, which is when n equals one.</span> <span m="2408000">If n equals one, then you have one number that</span> <span m="2413000">sums to one. So, alpha one is one.</span> <span m="2416000">And so, nothing is going on here.</span> <span m="2419000">This is just saying that f of one times x_1 is,</span> <span m="2423000">at most, one times f of x_1: so, not terribly exciting</span> <span m="2428000">because that holds with the quality.</span> <span m="2433000">OK, so we don't even need the n equals two base case.</span> <span m="2437000">So, the interesting part, although still not terribly</span> <span m="2442000">interesting, is the induction step.</span> <span m="2445000">This is good practice in induction.</span> <span m="2448000">So, what we care about is this f of this linear combination,</span> <span m="2453000">f on combination, x_k times x_k summed over all</span> <span m="2457000">k. Now, what I would like to do is</span> <span m="2461000">apply induction. What I know about inductively,</span> <span m="2465000">is say f of this sum, if it's summed only up to n</span> <span m="2469000">minus one instead of all the way up to n.</span> <span m="2472000">Any smaller sum I can deal with by induction.</span> <span m="2476000">So, I'm going to try and get rid of the nth term.</span> <span m="2480000">I want to separate it out. And, this is fairly natural if</span> <span m="2484000">you've played with affine combinations before.</span> <span m="2488000">But it's just some algebra. So, I want to separate out the</span> <span m="2495000">alpha_n*x_n term. And, I'd also like to make it</span> <span m="2500000">an affine combination. This is the trick.</span> <span m="2505000">Sorry, no f here. If I just removed the last</span> <span m="2510000">term, the alpha k's from one up to n minus one wouldn't sum to</span> <span m="2517000">one anymore. They'd sum to something</span> <span m="2522000">smaller. So, I can't just take out this</span> <span m="2525000">term. I'm going to have to do some</span> <span m="2528000">trickery here, x_k plus the f.</span> <span m="2530000">Good. So, you should see why this is</span> <span m="2533000">true, because the one minus alpha n's cancel.</span> <span m="2537000">And then, I'm just getting the sum of alpha_k*x_k,</span> <span m="2542000">k equals one to n minus one, plus the alpha_n*x_n term.</span> <span m="2548000">So, I haven't done anything here.</span> <span m="2550000">These are equal. But now, I have this nifty</span> <span m="2552000">feature, that on the one hand, these two numbers,</span> <span m="2556000">alpha n and one minus alpha n sum to one.</span> <span m="2558000">And on the other hand, if I did it right,</span> <span m="2561000">these numbers should sum up to one just going from one up to n</span> <span m="2565000">minus one. Why do they sum up to one?</span> <span m="2567000">Well, these numbers summed up to one minus alpha n.</span> <span m="2571000">And so, I'm dividing everything by one minus alpha n.</span> <span m="2574000">So, they will sum to one. So now, I have two affine</span> <span m="2577000">combinations. I just apply the two things</span> <span m="2582000">that I know. I know this affine combination</span> <span m="2587000">will work because, well, why?</span> <span m="2590000">Why can I say that this is alpha n f of x_n plus one minus</span> <span m="2596000">alpha n f of this crazy sum?</span> <span m="2615000">Shout it out. There are two possible answers.</span> <span m="2621000">One is correct, and one is incorrect.</span> <span m="2627000">So, which will it be? This should have been less than</span> <span m="2635000">or equal to. That's important.</span> <span m="2641000">It's on the board. It can't be too difficult.</span> <span m="2657000">So, I'm treating this as just one big X value.</span> <span m="2661000">So, I have some x_n, and I have some crazy X.</span> <span m="2666000">I want f of the affine combination of those two X</span> <span m="2671000">values is, at most, the affine combinations of the</span> <span m="2676000">f's of those X values. This is?</span> <span m="2680000">It is the inductive hypothesis where n equals two.</span> <span m="2683000">Unfortunately, we didn't prove the n equals</span> <span m="2685000">two case is a special base case. So, we can't use induction here</span> <span m="2689000">the way that I've stated the base case.</span> <span m="2692000">If you did n equals two base case, you can do that.</span> <span m="2695000">Here, we can't. So, the other answer is by</span> <span m="2698000">convexity, good. That's right here.</span> <span m="2702000">So, f is convex. We know that this is true for</span> <span m="2708000">any two X values, and provided these two sum to</span> <span m="2715000">one. So, we know that this is true.</span> <span m="2720000">Now is when we apply induction. So, now we are going to</span> <span m="2728000">manipulate this right term by induction.</span> <span m="2735000">See, before we didn't necessarily know that n was</span> <span m="2740000">bigger than two. But, we know that n is bigger</span> <span m="2744000">than n minus one. That much, I can be sure of.</span> <span m="2749000">So, this is one minus alpha n times the sum,</span> <span m="2753000">k equals one to n minus one of alpha k over one minus alpha n</span> <span m="2760000">times f of x_k, if I got that right.</span> <span m="2765000">This is by induction, the induction hypothesis,</span> <span m="2769000">because these alpha k's over one minus alpha n sum to one.</span> <span m="2776000">Now, these one minus alpha n's cancel, and we just get what we</span> <span m="2782000">want. This is sum k equals one to n</span> <span m="2786000">of alpha k, f of x_k. So, we get f of the sum is,</span> <span m="2791000">at most, sum of the f's. That proves the lemma.</span> <span m="2797000">OK, a bit tedious, but each step is pretty</span> <span m="2803000">straightforward. Do you agree?</span> <span m="2806000">Now, it turns out to be relatively straightforward to</span> <span m="2813000">prove Jensen's inequality. That's the magic.</span> <span m="2820000">And then, we get to do the expectation analysis.</span> <span m="2824000">So, we use our good friends, indicator random variables.</span> <span m="2829000">OK, but for now, we just want to prove this</span> <span m="2833000">statement. If we have a convex function,</span> <span m="2836000">f of the expectation is, at most, expectation of f of</span> <span m="2841000">that random variable. OK, this is a random variable,</span> <span m="2846000">right? If you want to sample from this</span> <span m="2849000">random variable, you sample from X,</span> <span m="2853000">and then you apply f to it. That's the meaning of this</span> <span m="2859000">notation, f of X because X is a random variable.</span> <span m="2865000">We get to use that f is convex. OK, it turns out this is not</span> <span m="2871000">hard, if you remember the definition of expectation,</span> <span m="2877000">oh, I want to make one more assumption here,</span> <span m="2881000">which is that X is integral. So, it's an integer random</span> <span m="2888000">variable, meaning it takes integer values.</span> <span m="2891000">OK, that's all we care about because we're looking at running</span> <span m="2896000">times. This statement is true for</span> <span m="2899000">continuous random variables, too, but I would like to do the</span> <span m="2904000">discrete case because then I get to write down what U of X is.</span> <span m="2909000">So, what is the definition of E of X?</span> <span m="2914000">X only takes on integer values. This is easy,</span> <span m="2920000">but you have to remember it. It's a good drill.</span> <span m="2927000">I don't really know much about X except that it takes on</span> <span m="2935000">integer values. Any suggestions on how I should</span> <span m="2942000">expand the expectation of X? How many people know this by</span> <span m="2950000">heart? OK, it's not too easy then.</span> <span m="2954000">Well, expectation has something to do with probability,</span> <span m="2960000">right? So, I should be looking at</span> <span m="2963000">something like the probability that X equals some value,</span> <span m="2969000">x. That would seem like a good</span> <span m="2972000">thing to do. What else goes here?</span> <span m="2976000">A sum, yeah. The sum, well,</span> <span m="2979000">X could be somewhere between minus infinity and infinity.</span> <span m="2984000">That's certainly true. And, we have some more.</span> <span m="2989000">There's something missing here. What is this sum?</span> <span m="2994000">What does it come out to for any random variable,</span> <span m="2998000">X, that takes on integer values?</span> <span m="3003000">One, good. So, I need to add in something</span> <span m="3006000">here, namely X. OK, that's the definition of</span> <span m="3010000">the expectation. Now, f of a sum of things,</span> <span m="3013000">where these coefficients sum to one looks an awful lot like the</span> <span m="3018000">lemma that we just proved. OK, we proved it in the finite</span> <span m="3023000">case. It turns out,</span> <span m="3025000">it holds just as well if you take all integers.</span> <span m="3030000">So, I'm just going to assume that.</span> <span m="3033000">So, I have these probabilities, these alpha values sum to one.</span> <span m="3039000">Therefore, I can use this inequality, that this is,</span> <span m="3044000">at most, let me get this right, I have the alphas,</span> <span m="3049000">so I have a sum, x equals minus infinity to</span> <span m="3053000">infinity of the alphas, which are a probability;</span> <span m="3058000">capital X equals little x times f of the value,</span> <span m="3063000">f of little x. OK, so there it is.</span> <span m="3069000">I've used the lemma. So, maybe now I'll erase the</span> <span m="3076000">lemma. OK, I cheated by using the</span> <span m="3081000">countable version of the lemma while only proving the finite</span> <span m="3091000">case. It's all I can do in lecture.</span> <span m="3096000">So, this is by a lemma. Now, what I'd like to prove and</span> <span m="3102000">leave some blank space here is this is, at most,</span> <span m="3107000">E of f of X, so that this summation is,</span> <span m="3111000">at most, E of f of X. Actually, it's equal to E of f</span> <span m="3116000">of X. And, it really looks kind of</span> <span m="3120000">equal, right? You've got sum of some</span> <span m="3125000">probabilities times f of X. It almost looks like the</span> <span m="3129000">definition of E of f of X, but it isn't.</span> <span m="3133000">You've got to be a little bit careful because E of f of X</span> <span m="3138000">should talk about the probability that f of X equals a</span> <span m="3143000">particular value. We can relate these as follows.</span> <span m="3148000">It's not too hard. You can look at each value that</span> <span m="3152000">f takes on, and then look at all the values, k,</span> <span m="3157000">that map to that value, x.</span> <span m="3161000">So all the k's where f of X equals x, the probability that X</span> <span m="3168000">equals k, OK, this is another way of writing</span> <span m="3174000">the probability that f of X equals x.</span> <span m="3180000">OK, so, in other words, I'm grouping the terms in a</span> <span m="3184000">particular way. I'm saying, well,</span> <span m="3187000">f of X takes on various values. Clever me to switch.</span> <span m="3192000">I used to use k's unannounced, so I better call this something</span> <span m="3198000">else. Let's call this Y,</span> <span m="3200000">sorry, switch notation here. It makes sense.</span> <span m="3205000">I should look at the probability that X equals x.</span> <span m="3211000">So, what I really care about is what this f of X value takes on.</span> <span m="3215000">Let's just call it Y, look at all the values,</span> <span m="3218000">Y, that f could take on. That's the range of f.</span> <span m="3221000">And then, I'll look at all the different values of X where f of</span> <span m="3226000">X equals Y. If I add up those</span> <span m="3227000">probabilities, because these are different</span> <span m="3230000">values of X. Those are sort of independent</span> <span m="3233000">events. So, this summation will be the</span> <span m="3236000">probability that f of X equals Y.</span> <span m="3238000">This is capital X. This is little y.</span> <span m="3242000">And then, if I multiply that by y, I'm getting the expectation</span> <span m="3249000">of f of X. So, think about this,</span> <span m="3252000">these two inequalities hold. This may be a bit bizarre here</span> <span m="3258000">because these sums are potentially infinite.</span> <span m="3262000">But, it's true. OK, this proves Jensen's</span> <span m="3266000">inequality. So, it wasn't very hard,</span> <span m="3270000">just a couple of boards, once we had this powerful</span> <span m="3275000">convexity lemma. So, we just used convexity.</span> <span m="3281000">We used the definition of E of X.</span> <span m="3283000">We used convexity. That lets us put the f's</span> <span m="3287000">inside. Then we do this regrouping of</span> <span m="3290000">terms, and we figure out, oh, that's just E of f of X.</span> <span m="3294000">So, the only inequality here is coming from convexity.</span> <span m="3298000">All right, now comes the algorithms.</span> <span m="3301000">So, this was just some basic probability stuff,</span> <span m="3305000">which is good to practice. OK, we could see in the quiz,</span> <span m="3310000">which is not surprising. This is the case for me,</span> <span m="3313000">too. You have a lot of intuition</span> <span m="3315000">with algorithms. Whenever it's algorithmic,</span> <span m="3317000">it makes a lot of sense because you're sort of grounded in some</span> <span m="3321000">things that you know because you are computer scientists,</span> <span m="3324000">or something of that ilk. For the purposes of this class,</span> <span m="3327000">you are computer scientists. But, with sort of the basic</span> <span m="3332000">probability, unless you happen to be a mathematician,</span> <span m="3336000">it's less intuitive, and therefore harder to get</span> <span m="3340000">fast. And, in quiz one,</span> <span m="3342000">speed is pretty important. On the final,</span> <span m="3345000">speed will also be important. The take home certainly doesn't</span> <span m="3350000">hurt. So, the take home is more</span> <span m="3353000">interesting because it requires being clever.</span> <span m="3356000">You have to actually be creative.</span> <span m="3361000">And, that really tests algorithmic design.</span> <span m="3363000">So far, we've mainly tested analysis, and just,</span> <span m="3366000">can you work through probability?</span> <span m="3369000">Can you figure out what the, can you remember what your</span> <span m="3372000">running time of randomized quicksort is,</span> <span m="3375000">and so on? Quiz two will actually test</span> <span m="3377000">creativity because you have more time.</span> <span m="3380000">It's hard to be creative in two hours.</span> <span m="3382000">OK, so we want to analyze the expected height of a randomly</span> <span m="3386000">constructed binary search tree. So, I've defined this before,</span> <span m="3392000">but let me repeat it because it was a while ago almost at the</span> <span m="3398000">beginning of lecture. I'm going to take the random</span> <span m="3402000">variable of the height of a randomly built binary search</span> <span m="3408000">tree on n nodes. So, that was randomized,</span> <span m="3411000">the n values. Take a random permutation,</span> <span m="3415000">insert them one by one from left to right with tree insert.</span> <span m="3422000">What is the height of the tree that you get?</span> <span m="3425000">What is the maximum depth of any node?</span> <span m="3428000">I'm not going to look so much at X_n.</span> <span m="3431000">I'm going to look at the exponentiation of X_n.</span> <span m="3434000">And, still we have no intuition why.</span> <span m="3437000">But, two to the X is a convex function.</span> <span m="3440000">OK, it looks like that. It's very sharp.</span> <span m="3443000">That's the best I can do for drawing, two to the X.</span> <span m="3447000">You saw how I drew my histogram.</span> <span m="3451000">So, we want to somehow write this random variable as</span> <span m="3454000">something, OK, in some algebra.</span> <span m="3456000">The main thing here is to split into cases.</span> <span m="3459000">That's how we usually go because there's lots of</span> <span m="3462000">different scenarios on what happens.</span> <span m="3465000">So, I mean, how do we construct a tree from the beginning?</span> <span m="3468000">First thing we do is we take the first node.</span> <span m="3471000">We throw it in, make it the root.</span> <span m="3474000">OK, so whatever the first value happens to be in the array,</span> <span m="3478000">which we don't really know how that falls into sorted order,</span> <span m="3482000">we put it at the root. And, it stays the root.</span> <span m="3486000">We never change the root from then on.</span> <span m="3488000">Now, of all the remaining elements, some of them are less</span> <span m="3492000">than this value, and they go over here.</span> <span m="3494000">So, let's call this r at the root.</span> <span m="3497000">And, some of them are greater than r.</span> <span m="3499000">So, they go over here. Maybe there's more over here.</span> <span m="3502000">Maybe there's more over here. Who knows?</span> <span m="3505000">Arbitrary partition, in fact, uniformly random</span> <span m="3508000">partition, which should sound familiar, whether there are k</span> <span m="3511000">elements over here, and n minus k minus one</span> <span m="3514000">elements over here, for any value of k,</span> <span m="3516000">that's equally likely because this is chosen uniformly.</span> <span m="3522000">The root is chosen uniformly. It's the first element in a</span> <span m="3524000">random permutation. So, what I'm going to do is</span> <span m="3527000">parameterize by that. How many elements are over</span> <span m="3529000">here, and how many elements are over here?</span> <span m="3531000">Because this thing is, again, a randomly built binary</span> <span m="3534000">search tree on however many nodes are in there because after</span> <span m="3537000">I pick r, it's determined who is to the left and who is to the</span> <span m="3540000">right. And so, I can just partition.</span> <span m="3543000">It's like running quicksort. I partition the elements left</span> <span m="3547000">of r, the elements right of r, and I'm sort of recursively</span> <span m="3551000">constructing a randomly built binary search tree on those two</span> <span m="3555000">sub-permutations because sub-permutations of uniform</span> <span m="3558000">permutations are uniform. OK, so these are essentially</span> <span m="3562000">recursive problems. And, we know how to analyze</span> <span m="3565000">recursive problems. All we need to know is that</span> <span m="3568000">there are k minus one elements over here, and n minus k</span> <span m="3571000">elements over here. And, that would mean that r has</span> <span m="3578000">rank k, remember, rank in the sense of the index</span> <span m="3585000">in assorted order. So, where should I go?</span> <span m="3608000">So, if the root, r, has rank,</span> <span m="3611034">k, so if this is a statement about condition on this event,</span> <span m="3617318">which is a random event, then what we have is X_n equals</span> <span m="3623278">one plus the max of X_(k minus one), X_(n minus k) because the</span> <span m="3629888">height of this tree is the max of the heights of the two</span> <span m="3635848">subtrees plus one because we have one more level up top.</span> <span m="3643000">OK, so that's the natural thing to do.</span> <span m="3646728">What we are trying to analyze, though, is Y_n.</span> <span m="3651263">So, for Y_n, we have to take two to this</span> <span m="3655193">power. So, it's two times the max of</span> <span m="3658720">two to the X_(k minus one), which is Y_(k minus one),</span> <span m="3663961">and two to this, which is Y_(n minus k).</span> <span m="3669000">And, now you start to see, maybe, why we are interested in</span> <span m="3672536">Y's instead of X's in the sense that it's what we know how to</span> <span m="3676260">do. When we solve a recursion,</span> <span m="3678059">when we solve, like, the expected running</span> <span m="3680541">time, we haven't taken expectations,</span> <span m="3682713">yet, here. But, when we compute the</span> <span m="3684823">expected running time of quicksort, we have something</span> <span m="3688050">like two times, I mean, we have a couple of</span> <span m="3690656">recursive subproblems, which are being added together.</span> <span m="3695000">OK, here, we have a factor of two.</span> <span m="3697015">Here, we have a max. But, intuitively,</span> <span m="3699276">we know how to multiply random variables by a constant because</span> <span m="3703002">that's, like, there's two recursive</span> <span m="3705079">subproblems of the size is equal to the max of these two,</span> <span m="3708500">which we don't happen to know here.</span> <span m="3710576">But, there it is, whereas one plus,</span> <span m="3712653">we don't know how to handle so well.</span> <span m="3714791">And, indeed, our techniques are really good</span> <span m="3717357">at solving recurrences, except up to the constant</span> <span m="3720289">factors. And, this one plus really</span> <span m="3723355">doesn't affect the constant factor too much,</span> <span m="3725685">it would seem. OK, but it's a big deal.</span> <span m="3727745">In exponentiation, it's a factor of two.</span> <span m="3729859">So here, it's really hard to see what this one plus is doing.</span> <span m="3733112">And, our analysis, if we tried it,</span> <span m="3734900">and it's a good idea to try it at home and see what happens,</span> <span m="3738099">if you tried to do what I'm about to do with X_n,</span> <span m="3740700">the one plus will sort of get lost, and you won't get a bound.</span> <span m="3744007">You just can't prove anything. With a factor of two,</span> <span m="3746771">we're in good shape. We sort of know how to deal</span> <span m="3749319">with that. We'll say more when we've</span> <span m="3753980">actually done the proof about why we use Y_n instead of X_n.</span> <span m="3761015">But for now, we're using Y_n.</span> <span m="3764353">So, this is sort of a recursion, except it's</span> <span m="3769480">conditioned on this event. So, how do I turn this into a</span> <span m="3776038">statement that holds all the time?</span> <span m="3779973">Sorry? Divide by the probability of</span> <span m="3784896">the event? More or less.</span> <span m="3787275">Indeed, these events are independent.</span> <span m="3791000">Or, they're all equally likely, I should say.</span> <span m="3795551">They're not independent. In fact, one determines all the</span> <span m="3801241">others. So, how do I generally</span> <span m="3804241">represent an event in algebra? Indicator random variables:</span> <span m="3810137">good. Remember your friends,</span> <span m="3814995">indicator random variables. All of these analyses use</span> <span m="3822076">indicator random variables. So, they will just represent</span> <span m="3829565">this event, and we'll call it Z_nk.</span> <span m="3834195">It's going to be one if the root has rank,</span> <span m="3839778">k, and zero otherwise. So, in particular,</span> <span m="3845415">the probability of, these things are all equally</span> <span m="3849110">likely for, a particular value of n if you try all the values</span> <span m="3853828">of k. The probability that this</span> <span m="3856186">equals one, which is also the expectation of that indicator</span> <span m="3860746">random variable, which you should know,</span> <span m="3863734">is it only takes values one or zero.</span> <span m="3866486">The zero doesn't matter in the expectation.</span> <span m="3869788">So, this is going to be, hopefully, one over n if I got</span> <span m="3874034">right.</span> <span m="3876000">So, there are n possibility of what the rank of the root could</span> <span m="3883013">be. Each of them are equally likely</span> <span m="3886922">because we have a uniform permutation.</span> <span m="3891176">So, now, I can rewrite this condition statement as a</span> <span m="3897040">summation where the Z_nk's will let me choose what case I'm in.</span> <span m="3904168">So, we have Y_n is the sum, k equals one to n of Z_nk times</span> <span m="3910836">two times the max of X, sorry, Y, k minus one,</span> <span m="3916010">Y_n minus k. So, now we have our good</span> <span m="3920478">friend, the recurrence. We need to solve it.</span> <span m="3923126">OK, we can't really solve it because this is a random</span> <span m="3926329">variable, and it's talking about recursive random variables.</span> <span m="3929963">So, we first take the expectation of both sides.</span> <span m="3932858">That's the only thing we can really bound.</span> <span m="3936000">Y_n could be n^2 in an unlucky case, sorry, not n^2.</span> <span m="3940074">It could be n^2. It could be two to the,</span> <span m="3943190">boy, two to the n if you are unlucky because X_n could be as</span> <span m="3947903">big as n, the height of the tree.</span> <span m="3950460">And, Y_n is two to that. So, it could be two to the n.</span> <span m="3954694">What we want to prove is that it's polynomial in n.</span> <span m="3958688">If it's n to some constant, and we take logs,</span> <span m="3962203">it'll be order log n. OK, so we'll take the</span> <span m="3967341">expectation, and hopefully that will guarantee that this holds.</span> <span m="3974254">OK, so we have expectation of this summation of random</span> <span m="3980163">variables times recursive random variables.</span> <span m="3984846">So, what is the first, woops, I forgot a bracket.</span> <span m="3990198">What is the first thing that we do in this analysis?</span> <span m="3997000">This should, yeah, linearity of expectation.</span> <span m="4001300">That one's easy to remember. OK, we have a sum.</span> <span m="4005900">So, let's put the E inside.</span> <span m="4024000">OK, now we have the expectation of our product.</span> <span m="4028842">What should we use? Independence.</span> <span m="4032210">Hopefully, things are independent.</span> <span m="4035684">And then, we could write this. Then, it would be the</span> <span m="4041052">expectation of the product. And, heck, let's put the two</span> <span m="4046842">outside, because it's not, no sense in keeping it in here.</span> <span m="4054000">Y is there starting to look like X's?</span> <span m="4057956">I can't even read them. Sorry about that.</span> <span m="4062351">This should all be Y's. OK, very wise,</span> <span m="4066417">random variables. So.</span> <span m="4068615">Why are these independent? So, here we are looking at the</span> <span m="4074769">choice of what the root is, what rank the root has in a</span> <span m="4080703">problem of size n. In here, we're looking at what</span> <span m="4085608">the root, I mean, there are various choices of</span> <span m="4088020">what the search tree looks like in the stuff left of the root,</span> <span m="4091290">and in the stuff right of the root.</span> <span m="4093112">Those are independent choices because everything is uniform</span> <span m="4096220">here. So, the choice of this guy was</span> <span m="4098096">uniform. And then, that determines who</span> <span m="4100081">partitions in the left and the right.</span> <span m="4102011">Those are completely independent recursive choices of</span> <span m="4104798">who's the root in the left subtree?</span> <span m="4106621">Who's the root in the left of the left subtree,</span> <span m="4109086">and so on? So, this is a little trickier</span> <span m="4111176">than usual. Before, it was random choices</span> <span m="4116385">in the algorithm. Now, it's in some construction</span> <span m="4121871">where we choose the random numbers ahead of time.</span> <span m="4127474">It's a bit funny, but this is still independent.</span> <span m="4132961">So, we get this just like we did in quicksort,</span> <span m="4138214">and so on. OK.</span> <span m="4139731">Now, we continue. And, now it's time to be a bit</span> <span m="4145374">sloppy. Well, one of these things we</span> <span m="4148143">know. OK, E of ZNK,</span> <span m="4149568">that, we wrote over here. It's one over n.</span> <span m="4152812">So, that's cool. So, we get a two over n</span> <span m="4155899">outside, and we get this sum of the expectation of a max of</span> <span m="4160488">these two things. Normally, we would write,</span> <span m="4163812">well, I think sometimes you write T of max,</span> <span m="4167136">or Y of the max of the two things here.</span> <span m="4170143">You've got to write it as the max of these two variables.</span> <span m="4176000">And, the trick, I mean, it's not too much of a</span> <span m="4181547">trick, is that the max is, at most, the sum.</span> <span m="4186849">So, we have nonnegative things. So, we have two over n,</span> <span m="4193506">sum k equals one to n of the expectation of the sum instead</span> <span m="4200657">of the max. OK, this is,</span> <span m="4203943">in some sense, the key step where we are</span> <span m="4207014">losing something in our bound. So far, we've been exact.</span> <span m="4211344">Now, we're being pretty sloppy. It's true the max is,</span> <span m="4215437">at most, the sum. But, it's a pretty loose upper</span> <span m="4219137">bound as things go. We'll keep that in mind for</span> <span m="4222758">later. What else can we do with the</span> <span m="4225434">summation? This should,</span> <span m="4227166">again, look familiar. Now that we have a sum of a sum</span> <span m="4233470">of two things, I'm trying to like it to be a</span> <span m="4238283">sum of one thing. Sorry?</span> <span m="4240858">You can use linearity of expectation, good.</span> <span m="4245559">So, that's the first thing I should do.</span> <span m="4249813">So, linearity of expectation lets me separate that.</span> <span m="4255410">Now I have a sum of 2n things. Right, I could break that into</span> <span m="4262079">the sum of these guys, and the sum of these guys.</span> <span m="4265405">Do you know anything about those two sums?</span> <span m="4268247">Do we know anything about those two sums?</span> <span m="4271019">They're the same. In fact, every term here is</span> <span m="4274068">appearing exactly twice. One says a k minus one.</span> <span m="4277326">One says an n minus k, and that even works if it's</span> <span m="4280722">odd, I think. So, in fact,</span> <span m="4282455">we can just take one of the sums and multiply it by two.</span> <span m="4286267">So, this is four over n times the sum, and I'll rewrite it a</span> <span m="4290356">little bit from zero to n minus one of E of Y_k.</span> <span m="4295000">Just check the number of times each Y_k appears from zero up to</span> <span m="4300425">n minus one is exactly two. So, now I have a recurrence.</span> <span m="4305237">I have E of Y_n is, at most, this thing.</span> <span m="4308649">Let's just write that for our memory.</span> <span m="4311800">So, how's that? Cool.</span> <span m="4313550">Now, I just have to solve the recurrence.</span> <span m="4317050">How should I solve an ugly, hairy, recurrence like this?</span> <span m="4323000">Substitution: yea!</span> <span m="4325125">Not the master method. OK, it's a pretty nasty</span> <span m="4330750">recurrence. So, I'm going to make a guess,</span> <span m="4335875">and I've already told you the guess, that it's n^3.</span> <span m="4342125">I think n^3 is pretty much exactly where this proof will be</span> <span m="4349375">obtainable. So, substitution method,</span> <span m="4354239">substitution method is just a proof by induction.</span> <span m="4358720">And, there are two things every proof by induction should have,</span> <span m="4364506">well, almost every proof by induction, unless you're being</span> <span m="4369826">fancy. It should have a base case,</span> <span m="4372906">and the base case here is n equals order one.</span> <span m="4377013">I didn't write it, but, of course,</span> <span m="4380093">if you have a constant size tree, it has constant height.</span> <span m="4385318">So, this thing will be true as long as we set true if c is</span> <span m="4390640">sufficiently large. OK, so, don't forget that.</span> <span m="4395684">A lot of people forgot it on the quiz.</span> <span m="4398080">We even mentioned the base case.</span> <span m="4400089">Usually, we don't even mention the base case.</span> <span m="4402939">And, you should assume that there's one there.</span> <span m="4405854">And, you have to say this in any proof by substitution.</span> <span m="4410000">OK, now, we have the induction step.</span> <span m="4413107">So, I claim that E of Y_n is, at most, Ccof n^3,</span> <span m="4417279">assuming that it's true for smaller n.</span> <span m="4420563">You should write the induction hypothesis here,</span> <span m="4424647">but I'm going to skip it because I'm running out of time.</span> <span m="4429618">Now, we have this recurrence that E of Y_n is,</span> <span m="4433613">at most, this thing. So, E of Y_n is,</span> <span m="4436809">at most, four over n, sum k equals zero to n minus</span> <span m="4441159">one of E of Y_k. Now, notice that k is always</span> <span m="4447223">smaller than n. So, we can apply induction.</span> <span m="4452059">So, this is, at most, four over n,</span> <span m="4455858">sum k equals zero to n minus one of c times k^3.</span> <span m="4461269">That's the induction hypothesis.</span> <span m="4464838">Cool. Now, I need an upper bound on</span> <span m="4468753">this sum, if you have a good memory, then you know a closed</span> <span m="4475430">form for this sum. But, I don't have such a good</span> <span m="4480801">memory as I used to. I never memorized this sum when</span> <span m="4483970">I was a kid, so I don't remember everything when I memorize when</span> <span m="4487884">I was less than 12 years old. I still remember all the digits</span> <span m="4491612">of pi, whatever. But, anything I try to memorize</span> <span m="4494532">now just doesn't quite stick the same way.</span> <span m="4497079">So, I don't happen to know this sum.</span> <span m="4500000">What's a good way to approximate this sum?</span> <span m="4503169">Integral: good. So, in fact,</span> <span m="4505256">I'm going to take the c outside.</span> <span m="4507653">So, this is 4c over n. The sum is, at most,</span> <span m="4510900">the integral. If you get the range right,</span> <span m="4513992">so, you have to go one larger. Instead of n minus one,</span> <span m="4518089">you go up to n. This is in the textbook.</span> <span m="4521104">It's intuitive, too, as long as you have a</span> <span m="4524274">monotone function. That's key.</span> <span m="4526516">So, you have something that's like this.</span> <span m="4531000">And, you know, the sum is taking each of these</span> <span m="4534075">and weighting them with a value of one.</span> <span m="4536671">The integral is computing the area under this curve.</span> <span m="4540157">So, in particular, if you look at this</span> <span m="4542684">approximation of the integral, then, I mean,</span> <span m="4545624">this thing is certainly, this would be the sum if you go</span> <span m="4549382">one larger at the end, and that's, at most,</span> <span m="4552252">the integral. So, that's proof by picture.</span> <span m="4555054">But, you can see this in the book.</span> <span m="4557309">You should know it from 042 I guess.</span> <span m="4561000">Now, integrals, hopefully, you can solve.</span> <span m="4564448">Integral of x^3 is x^4 over four.</span> <span m="4567206">I got it right. And then, we're valuing that at</span> <span m="4571172">n. And, it's zero.</span> <span m="4572637">Subtracting the zero doesn't matter because zero to the</span> <span m="4577293">fourth power is zero. So, it's just n^4 over four.</span> <span m="4581517">So, this is 4c over n times n^4 over four.</span> <span m="4585051">And, conveniently, this four cancels with this</span> <span m="4588931">four. The four turns into a three</span> <span m="4591689">because of this, and we get n^3.</span> <span m="4596000">We get cn^3. Damn convenient,</span> <span m="4598159">because that's what we wanted to prove.</span> <span m="4601089">OK, so this proof is just barely snaking by:</span> <span m="4604404">no residual term. We've been sloppy all over the</span> <span m="4608028">place, and yet we were really lucky.</span> <span m="4610727">And, we were just sloppy in the right places.</span> <span m="4614120">So, this is a very tricky proof.</span> <span m="4616510">If you just tried to do it by hand, it's pretty easy to be too</span> <span m="4621214">sloppy, and not get quite the right answer.</span> <span m="4624452">But, this just barely works. So, let me say a couple of</span> <span m="4629869">things about it in my remaining one minute.</span> <span m="4632890">So, we can do the conclusion, again.</span> <span m="4635407">I won't write it because I don't have time,</span> <span m="4638428">but here it is. We just proved a bound on Y_n,</span> <span m="4641664">which was two to the power X_n. What we cared about was X_n.</span> <span m="4645907">So, we used Jensen's inequality.</span> <span m="4649000">We get the two to the E of X_n is, at most, E of two to the</span> <span m="4652350">X_n. This is what we know about</span> <span m="4654083">because that's Y_n. So, we know E of Y_n is now</span> <span m="4656740">order n^3. OK, we had to set this constant</span> <span m="4659108">sufficiently large for the base case.</span> <span m="4661187">We didn't really figure out what the constant was here.</span> <span m="4664306">It didn't matter because now we're taking the logs of both</span> <span m="4667599">sides. We get E of X_n is,</span> <span m="4669043">at most, log of order n^3. This constant is a</span> <span m="4671584">multiplicative constant. So, you take the logs.</span> <span m="4674241">It becomes additive. This constant is an exponent.</span> <span m="4677072">So, it would take logs. It becomes a multiple.</span> <span m="4681000">Three log n plus order one. This is a pretty damn tight</span> <span m="4687361">bound on the height of a randomly built binary search</span> <span m="4693486">tree, the expected height, I should say.</span> <span m="4698081">In fact, the expected height of X_n is equal to,</span> <span m="4703617">well, roughly, I'll just say it's roughly,</span> <span m="4708447">I don't want to be too precise here, 2.9882 times log n.</span> <span m="4714925">This is the result by a friend of mine, Luke Devroy,</span> <span m="4720934">if I spell it right, in 1986.</span> <span m="4726000">He's a professor at McGill University in Montreal.</span> <span m="4729572">So, we're pretty close, three to 2.98.</span> <span m="4732270">And, I won't prove this here. The hard part here is actually</span> <span m="4736572">the lower bound, but it's only that much.</span> <span m="4740000">I should say a little bit more about why we use Y_n instead of</span> <span m="4744273">X_n. And, it's all about the</span> <span m="4746166">sloppiness. And, in particular,</span> <span m="4748268">this step, where we said that the max of these two random</span> <span m="4752193">variables is, at most, the sum.</span> <span m="4754295">And, while that's true for X just as well as it is true for</span> <span m="4758359">Y, it's more true for Y. OK, this is a bit weird</span> <span m="4761653">because, remember, what we're analyzing here is</span> <span m="4764876">all possible values of k. This has to work no matter what</span> <span m="4768800">k is, in some sense. I mean, we're bounding all of</span> <span m="4772234">those cases simultaneously, the sum of them all.</span> <span m="4777000">So, here we're looking at k minus one versus n minus k.</span> <span m="4781576">And, in fact, here, there's a polynomial</span> <span m="4784881">version. But, so, if you take two values</span> <span m="4788186">a and b, and you say, well, max of ab is,</span> <span m="4791576">at most, a plus b. And, on the other hand you say,</span> <span m="4795728">well, max of two to the a and two to the b is,</span> <span m="4799541">at most, two to the a plus two to the b.</span> <span m="4802847">Doesn't this feel better than that?</span> <span m="4807000">Well, they are, of course, the same.</span> <span m="4809820">But, if you look at a minus b, as that grows,</span> <span m="4813367">this becomes a tighter bound faster than this becomes a</span> <span m="4817719">tighter bound because here we're looking at absolute difference</span> <span m="4822716">between a minus b. So, that's why this is pretty</span> <span m="4826504">good and this is pretty bad. We're still really bad if a and</span> <span m="4831259">b are almost the same. But, we're trying to solve this</span> <span m="4835812">for all partitions into k minus one and n minus k.</span> <span m="4838677">So, it's OK if we get a few of the cases wrong in the middle</span> <span m="4842127">where it evenly partitions. But, as soon as we get some</span> <span m="4845284">skew, this will be very close to this, whereas this will be still</span> <span m="4849026">pretty far from this. You have to get pretty close to</span> <span m="4852066">the edge before you're not losing much here,</span> <span m="4854580">whereas pretty quickly you're not losing much here.</span> <span m="4857504">That's the intuition. Try it, and see what happens</span> <span m="4860368">with X_n, and it won't work. See you Wednesday.</span> </p>
</div>
        <div id="vid_transcript" itemprop="description" class="tabContent hide">
<h2 class="subhead">Free Downloads</h2>
<h3 class="subsubhead">Video</h3>
<ul>
<li>iTunes U (<a href="https://itunes.apple.com/us/itunes-u/id341597754">MP4 - 170MB</a>)</li>
<li>Internet Archive (<a href="http://www.archive.org/download/MIT6.046JF05MPEG4/ocw-6.046-17oct2005-220k.mp4">MP4 - 334MB</a>)</li>
</ul>
<br><h3 class="subsubhead">Free Streaming</h3>
<ul><li><a href="http://videolectures.net/mit6046jf05_introduction_algorithms/">VideoLectures.net</a></li></ul>
<br><h3 class="subsubhead">Subtitle</h3>
<ul><li>English - US (<a href="../../../contents/video-lectures/lecture-9-relation-of-bsts-to-quicksort-analysis-of-random-bst/vgELyZ9LXX4.srt">SRT</a>)</li></ul>
</div>
    
   </div>  




      					 
        <div class="" id="parent-fieldname-bottom_html_area">
            
            
        </div>
    
                    </div>
<!--Course_inner_chip tag close -->
           		</div>
<!--Course_wrapper tag close --> 
            </div>
<!--left tag close -->
            <div id="right">
                <!--Begin Right Portion -->
                    <div>
    
<div id="portletwrapper-6f63772e7269676874746f70706f72746c65746d616e616765720a636f6e746578740a2f506c6f6e650a646f6e617465" class="portletWrapper kssattr-portlethash-6f63772e7269676874746f70706f72746c65746d616e616765720a636f6e746578740a2f506c6f6e650a646f6e617465">
<div class="portletStaticText portlet-static-donate"><p class="zero"><a href="http://ocw.mit.edu/donate"><img src="../../../common/images/button_donate-now.png" alt="Donate Now." class="donate"></a></p></div>

</div>




</div>

                	<div>
    



</div>


        <div class="" id="parent-fieldname-rsi_top_html_area">
            
            
        </div>
    

<!-- RSI google ad space-->


<div id="google_ads">    
    <script type="text/javascript" src="http://partner.googleadservices.com/gampad/google_service.js"></script><script type="text/javascript">GS_googleAddAdSenseService("ca-pub-6588555046597237");GS_googleEnableAllServices();</script><script type="text/javascript">GA_googleAddSlot("ca-pub-6588555046597237", "VIDEO_INDIVIDUAL_SLOT_A_DL");GA_googleAddSlot("ca-pub-6588555046597237", "VIDEO_INDIVIDUAL_SLOT_B_DL");GA_googleAddSlot("ca-pub-6588555046597237", "VIDEO_INDIVIDUAL_SLOT_C_DL");</script><script type="text/javascript">GA_googleFetchAds();</script><script language="javascript" type="text/javascript">
GA_googleAddAttr("TYPE","HOUSE");
GA_googleAddAttr("DEPARTMENT","6");
GA_googleAddAttr("CRS_BEG2","04");
GA_googleAddAttr("CRS_END","6J");
GA_googleAddAttr("SESSION","F");
GA_googleAddAttr("YEAR","05");
</script><script type="text/javascript">GA_googleFillSlot("VIDEO_INDIVIDUAL_SLOT_A_DL");</script><script type="text/javascript">GA_googleFillSlot("VIDEO_INDIVIDUAL_SLOT_B_DL");</script><script type="text/javascript">GA_googleFillSlot("VIDEO_INDIVIDUAL_SLOT_C_DL");</script>
</div>

<!-- End RSI ads--> 

<div>
    



</div>

            </div>
<!--Right div close -->
            <div class="clear"></div> 
        </div>
<!--grid tag close --> 
      </div>
		
		<div id="bottom">
			<div id="grid">
				
<div id="portletwrapper-6f63772e626f74746f6d706f72746c65746d616e616765720a636f6e746578740a2f506c6f6e650a736974652d666f6f746572" class="portletWrapper kssattr-portlethash-6f63772e626f74746f6d706f72746c65746d616e616765720a636f6e746578740a2f506c6f6e650a736974652d666f6f746572">
<div class="portletStaticText portlet-static-site-footer">
<!--googleoff: index--> <div id="bottom"><div id="grid">
<!-- *begin footer* --> <div role="navigation sitemap" id="footer">
<div class="grid_2 alpha" id="foot-c1">
<h4 class="footer">Find Courses</h4> <ul class="foot-bullet">
<li><a href="http://ocw.mit.edu/courses/find-by-topic/">Find by Topic</a></li>     <li><a href="http://ocw.mit.edu/courses/find-by-number/">Find by Course Number</a></li>     <li><a href="http://ocw.mit.edu/courses/find-by-department/">Find by Department</a></li>     <li><a href="http://ocw.mit.edu/courses/audio-video-courses/">Audio/Video Courses</a></li>     <li><a href="http://ocw.mit.edu/courses/subtitled/">Courses with Subtitles</a></li>     <li><a href="http://ocw.mit.edu/courses/online-textbooks/">Online Textbooks</a></li>     <li><a href="http://ocw.mit.edu/courses/new-courses/">New Courses</a></li>     <li><a href="http://ocw.mit.edu/courses/most-visited-courses/">Most Visited Courses</a></li>     <li><a href="http://ocw.mit.edu/courses/ocw-scholar/">OCW Scholar Courses</a></li>     <li><a href="http://ocw.mit.edu/courses/this-course-at-mit/">This Course at MIT</a></li>     <li><a href="http://ocw.mit.edu/resources/">Supplemental Resources</a></li>     <li><a href="http://ocw.mit.edu/courses/translated-courses/">Translated Courses</a></li>     <li><a href="http://ocw.mit.edu/courses/">View All Courses</a></li> </ul>
</div> <div class="grid_2" id="foot-c2">
<h4 class="footer">About</h4> <ul class="foot-bullet">
<li><a href="http://ocw.mit.edu/about/">About OpenCourseWare</a></li>     <li><a href="http://ocw.mit.edu/about/site-statistics/">Site Stats</a></li>     <li><a href="http://ocw.mit.edu/about/ocw-stories/">OCW Stories</a></li>     <li><a href="http://ocw.mit.edu/about/media-coverage/">Media Coverage</a></li>     <li><a href="http://ocw.mit.edu/about/newsletter/">Newsletter</a></li>     <li><a href="http://ocw.mit.edu/about/media-coverage/press-releases/">Press Releases</a></li> </ul>
</div> <div class="grid_2" id="foot-c3">
<h4 class="footer">Donate</h4> <ul class="foot-bullet">
<li><a href="http://ocw.mit.edu/donate">Make a Donation</a></li>     <li><a href="http://ocw.mit.edu/donate/why-donate/">Why Donate?</a></li>     <li><a href="http://ocw.mit.edu/donate/our-supporters/">Our Supporters</a></li>     <li><a href="http://ocw.mit.edu/donate/other-ways-to-contribute/">Other Ways to Contribute</a></li>     <li><a href="http://ocw.mit.edu/donate/shop-ocw/">Shop OCW</a></li>     <li><a href="http://ocw.mit.edu/support/">Become a Corporate Sponsor</a></li> </ul>
</div> <div class="grid_2" id="foot-c4">
<h4 class="footer">Featured Sites</h4> <ul class="foot-bullet">
<li><a href="http://ocw.mit.edu/high-school/">Highlights for High School</a></li>     <li><a href="http://ocw.mit.edu/educator/">OCW Educator</a></li>     <li><a href="http://ocw.mit.edu/courses/crosslinks/">MIT Crosslinks and OCW</a></li>     <li><a href="http://ocw.mit.edu/ans7870/featured/mitx-courses-on-edx.htm">MITx Courses on edX</a></li>     <li><a href="http://teachingexcellence.mit.edu/">Teaching Excellence at MIT</a></li>     <li><a href="http://www.oeconsortium.org/">Open Education Consortium</a></li> </ul>
<h4 style="margin-top: 14px;" class="footer">Tools</h4> <ul class="foot-bullet">
<li><a href="http://ocw.mit.edu/help/">Help &amp; FAQs</a></li>     <li><a href="../../../common/jsp/feedback.htm">Contact Us</a></li>     <li><a href="../../../common/search/AdvancedSearch.htm">Advanced Search</a></li>     <li><a href="http://ocw.mit.edu/help/site-map/">Site Map</a></li>     <li><a href="../../../common/terms/index.htm">Privacy &amp; Terms of Use</a></li>     <li><a href="http://ocw.mit.edu/help/rss/">RSS Feeds</a></li> </ul>
</div> <div class="grid_4 omega" id="foot-c5">
<h4 class="footer">Our Corporate Supporters</h4> <!-- HOME_CORP_LOGO_1 --> <div class="sponsors_google_ads_even" id="div-gpt-ad-1388181177156-0"><script type="text/javascript">
googletag.cmd.push(function() { googletag.display('div-gpt-ad-1388181177156-0'); });
</script></div> <!-- HOME_CORP_LOGO_2 --> <div class="sponsors_google_ads_odd" id="div-gpt-ad-1388181177156-1"><script type="text/javascript">
googletag.cmd.push(function() { googletag.display('div-gpt-ad-1388181177156-1'); });
</script></div> <!-- HOME_CORP_LOGO_3 --> <div class="sponsors_google_ads_even" id="div-gpt-ad-1388181177156-2"><script type="text/javascript">
googletag.cmd.push(function() { googletag.display('div-gpt-ad-1388181177156-2'); });
</script></div> <!-- HOME_CORP_LOGO_4 --> <div class="sponsors_google_ads_odd" id="div-gpt-ad-1388181177156-3"><script type="text/javascript">
googletag.cmd.push(function() { googletag.display('div-gpt-ad-1388181177156-3'); });
</script></div> <!-- HOME_CORP_LOGO_5 --> <div class="sponsors_google_ads_even" id="div-gpt-ad-1388181177156-4"><script type="text/javascript">
googletag.cmd.push(function() { googletag.display('div-gpt-ad-1388181177156-4'); });
</script></div> <!-- HOME_CORP_LOGO_6 --> <div class="sponsors_google_ads_odd" id="div-gpt-ad-1388181177156-5"><script type="text/javascript">
googletag.cmd.push(function() { googletag.display('div-gpt-ad-1388181177156-5'); });
</script></div>
</div> <div class="grid_12 alpha omega" style="border-top: thin solid #d5c9ba; padding-top: 24px; margin-bottom: 10px; text-align: center;"><p style="font-family: TitilliumText22LRegular,Verdana; text-align: center; font-size: 1.1em;">Support for <span style="letter-spacing: 0.5px;"><strong>MIT OPENCOURSEWARE'S 15th anniversary</strong></span> is provided by <a href="http://www.sapientnitro.com/en-us.html#home"><img style="width: 145px; height: 35px; vertical-align: middle; margin-left: 7px;" alt="SapientNitro logo and nameplate." src="../../../common/images/logo_sapient.png"></a></p></div> <div itemtype="http://schema.org/CollegeOrUniversity" itemscope="" itemprop="publisher" class="grid_12 alpha omega">
<h4 style="border-top: thin solid #d5c9ba; padding-top: 10px; margin-bottom: 10px;" class="footer">About <span itemprop="name">MIT OpenCourseWare</span>
</h4> <p itemprop="description" style="color: #999; font-size: 1em; line-height: 1.5em; margin-top: 10px;">MIT OpenCourseWare makes the materials used in the teaching of almost all of MIT's subjects available on the Web, free of charge. With more than 2,200 courses available, OCW is delivering on the promise of open sharing of knowledge. <a href="http://ocw.mit.edu/about/">Learn more »</a></p>
</div> <div style="border-top: none;" class="grid_12 alpha omega" id="foot-copy">
<a href="http://web.mit.edu"><img style="width: 195; height: 44;" alt="Massachusetts Institute of Technology logo and name." src="../../../common/images/logo_mit.png"></a><a href="http://odl.mit.edu"><img style="width: 289; height: 54; vertical-align: top;" alt="MIT Office of Digital Learning logo and name." src="http://ocw.mit.edu/images/logo_odl.png"></a><a href="http://www.oeconsortium.org/"><img style="width: 219px; height: 59px; vertical-align: top;" alt="Open Education Consortium logo." src="http://ocw.mit.edu/images/logo_oec.png"></a><a itemprop="useRightsUrl" rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img style="width: 126px; height: 44px; margin-right: 0; margin-left: 13px;" alt="Creative Commons logo with terms BY-NC-SA." src="../../../common/images/cc_by-nc-sa.png"></a> <p class="copyright">© 2001–2015<br> Massachusetts Institute of Technology</p> <p style="font-size: 0.9em; margin-bottom: 15px;">Your use of the MIT OpenCourseWare site and materials is subject to our <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/">Creative Commons License</a> and other <a rel="cc:morePermissions" href="../../../common/terms/index.htm">terms of use</a>.</p>
</div>
</div>
</div></div> <!--googleon: index-->
</div>

</div>





                
			</div> <!-- bottom grid end -->
		</div>
<!-- bottom end -->
		
		
   </body>
</html>
